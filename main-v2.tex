\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=scriptsize,labelfont=sf,textfont=rm]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
% \usepackage{tabularx}
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{makecell}

\usepackage{dsfont}
\usepackage{amssymb}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{ragged2e}
\usepackage{latexsym, amssymb, verbatim, amsmath}
\usepackage{amsmath,bm}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{subeqnarray}
\usepackage{cases}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{color}
\usepackage{cite}
\usepackage[]{chapterbib}
\usepackage{enumerate}
\usepackage{threeparttable}


\usepackage[dvipsnames, svgnames, x11names]{xcolor}
\usepackage{algorithm,algpseudocode,float}
\makeatletter
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
\begin{document}

\title{SecFFT: Safeguarding Federated Fine-tuning for Large Vision Language Models against Covert Backdoor Attacks in IoRT Networks}
 
\author{Zan Zhou, %~\IEEEmembership{Student Member,~IEEE}, 
  Changqiao Xu, Bo Wang, Tengfei Li, Sizhe Huang, Shujie Yang$^{\ast}$\thanks{*Corresponding authors}, Su Yao$^{\ast}$
% <-this % stops a space
\thanks{Z. Zhou, B. Wang, T. Li, S. Huang, C. Xu, and S. Yang are with the State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, P.R. China. E-mail: \{zan.zhou, cqxu, bowang, tf, swhsz, sjyang\}@bupt.edu.cn. 
	}  % <-this % stops a space
%\thanks{Y. Zhuang is with the Research Institute of China Telecom, Ave Zhongshan, Guangzhou 510630, China. E-mail: 13316094433@chinatelecom.cn.}% <-this % stops a space
% \thanks{L. Zhong is with the Information Engineering College, Capital Normal University, Beijing 100048, China. E-mail: zhonglj@cnu.edu.cn (Corresponding author).}% <-this % stops a space
\thanks{Su Yao is with the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing 100190, China. E-mail: yaosu@tsinghua.edu.cn}% <-this % stops a space
%\thanks{This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.}% <-this % stops a space
%\thanks{Manuscript received April 19, 2021; revised August 16, 2021.}
}

% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
%随着大模型与具身智能机器人网络的迅速发展，以及在智慧城市、电网、工厂、交通运输等领域的应用，视觉感知理解成为了突破具身智能节点性能瓶颈的基础性要素之一。而由于通用的预训练模型并不能很好应对特定任务，联邦微调技术由于其能够最大限度利用离散节点数据、算力的优势，成为了提升视觉感知模型能力的热带技术。然而，随着多种针对性高级持续性威胁的涌现，现有的污染防治方案，并不能有效应对这一新场景下的隐蔽后门攻击。本文因此提出SecFFT方法，其核心在于针对攻击隐蔽性高与攻击策略复杂的问题，分别设计了基于频域分布一致性提取的瞬时攻击行为识别，和基于隐藏攻击意图检测的长效安全聚合机制。从最终目的出发，有效限缩了智能化攻击者通过隐藏自身行为来绕过防御方案的可行域。在公共数据集上的实验表明，我们所提出的方法能够显著提升面对后门攻击时的防御成功率、模型性能和识别精度，尤其是面对具有多轮次复杂策略的高隐蔽后门范式。
As the large vision language models and embodied intelligent robotic networks continue to advance at a remarkable pace, particularly in applications spanning smart cities, power grids, factories, and transportation, visual perception and understanding have emerged as foundational elements to overcoming performance limitations in such intelligent systems. However, since general pre-trained models are not well-suited to specific tasks, federated fine-tuning (FFT) has gained attention as a promising technique for enhancing the performance of vision-based perception models by leveraging data and computational power distributed across nodes. The rise of advanced persistent threats has revealed significant vulnerabilities in existing defense mechanisms, which struggle to mitigate sophisticated backdoor attacks toward FFT for LVLMs. To address these challenges, this paper proposes the SecFFT method, which tackles both the stealthiness and complexity of backdoor strategies. The approach incorporates instantaneous attack behavior detection based on frequency-domain distribution consistency and introduces a long-term secure aggregation mechanism aimed at identifying hidden attack intentions. These strategies effectively limit the feasibility of adversaries attempting to bypass defense measures by concealing their behaviors. Experiments conducted on public datasets demonstrate that SecFFT significantly improves defense success rates, model performance, and detection accuracy, particularly in response to highly covert, multi-round backdoor attacks.



\end{abstract}

\begin{IEEEkeywords}
Vision Language Model, Federated learning, Fine-tuning, Security, Backdoor, Internet of Robotic Things.
\end{IEEEkeywords}

\section{Introduction}
%\IEEEPARstart{T}{his} file is intended to serve as a ``sample article file'' for IEEE journal papers produced under \LaTeX\ using IEEEtran.cls version 1.8b and later. The most common elements are covered in the simplified and updated instructions in ``New\_IEEEtran\_how-to.pdf''. For less common elements you can refer back to the original ``IEEEtran\_HOWTO.pdf''. It is assumed that the reader has a basic working knowledge of \LaTeX. Those who are new to \LaTeX \ are encouraged to read Tobias Oetiker's ``The Not So Short Introduction to \LaTeX ,'' available at: \url{http://tug.ctan.org/info/lshort/english/lshort.pdf} which provides an overview of working with \LaTeX.
%FFL很重要
%作为的一种，

%随着具身智能技术的迅猛进步和在智慧城市、智能交通、无人机等领域的广泛应用，机器人节点从执行等单一任务的agent，逐步向集合了感知交互和自主决策的智能体进行了演进，这也成为了未来IORT网络的重要发展趋势之一。而视觉大模型作为一种新兴热门的图像感知和物体识别技术，能够成为支撑智能机器人对周围环境进行认识和理解不可或缺的基础。
With the rapid advancements of embodied intelligence technology and its widespread application in multiple areas such as smart cities, intelligent transportation, and unmanned aerial vehicles, robotic nodes have evolved from agents performing singular tasks to intelligent entities that integrate perception, interaction, and autonomous decision-making. This evolution has become one of the critical developmental trends for Internet of Robotic Things (IoRT) networks\cite{andronie2023big}. Meanwhile, the Large Vision Language Model (LVLM)\cite{liu2024survey}, as an emerging and popular image perception and object recognition technology, has the potential to support intelligent robots in understanding and interpreting their surrounding environments. 

%视觉大模型极大地增强了机器人的视觉语义理解能力，使其能够对多模态任务进行更加智能化的决策响应，然而在真实应用环境中，仍存在以下问题：1）由于真实世界的多样性和异构性，通用大模型在特定任务上往往无法较好迁移通用知识，需要进行微调才能显著提升识别精度（例如，针对动目标检测任务，交通机器人主要针对车辆、行人，而工厂机器人则主要针对机床，两者轮廓、行为模式范围均存在较大差异）；2）此外，将来自不同源头的离散化、碎片化分布的海量数据进行传输并汇聚于主服务器，将会导致巨大的通信开销和时间延迟，无法满足具身智能业务的需求，且存在潜在的隐私风险。
Although LVLMs significantly enhance the visual semantic understanding capabilities of robots, enabling them to make more intelligent decisions in multi-modal tasks, there are still challenges in real-world applications: (1) Due to the diversity and heterogeneity of the real world\cite{dai2023tackling}, general foundation models often cannot effectively transfer their general knowledge to specific tasks, necessitating fine-tuning\cite{fu2023effectiveness} to significantly improve recognition accuracy (for example, traffic robots primarily focus on vehicles and pedestrians for moving object detection tasks, while factory robots mainly target machine tools, with significant differences in their contours and behavioral patterns); (2) Additionally, transmitting and aggregating massive amounts of discretized and fragmented data from different sources to a central server can result in significant communication overhead and latency\cite{zhao2023towards}, failing to meet the demands of embodied intelligence applications and posing potential privacy risks\cite{wen2023survey, khan2023federated}. 

%因此，如图1所示，在pretrained的通用视觉大模型的基础上，不同于核心节点汇聚所有数据而后训练垂域模型的集中式微调，通过联邦微调技术，驱使大量机器人节点利用私有数据和算力计算微调梯度而后聚合，能够在不交互原始数据的前提下，充分利用整个IORT网络中各个节点的知识和算力资源，成为了一种非常具有前景的解决方案。
As illustrated in Figure \ref{fig1:scene}, a promising solution is to employ federated fine-tuning (FFT) technology rather than adopting a centralized fine-tuning approach where core nodes aggregate all data before training domain-specific models. This approach drives numerous robotic nodes to compute fine-tuning gradients using private data and computational resources and then aggregate these gradients, effectively leveraging the knowledge and computational resources of each node in the IoRT network without exchanging raw data.

%不幸的是，FFT的分布式特性为多种后门攻击提供了存续的空间。尽管多种防御手段相继提出，但是尽我们所知，目前尚未有针对LVM的FFT过程进行污染防治的后门对抗技术提出。现有技术大多是针对普通联邦学习场景或集中式的VLM训练进行设计，这暴露出两大核心问题：（1）高隐蔽的攻击行为感知困难：攻击者在设计攻击行为时，尽量在行为特征上拟合正常用户，perception的区分度越来越narrow；(2)复杂攻击策略的检测困难：为了规避防御，攻击者可能采用限制角度、大小、符号等方式，将原有单次攻击转化为多轮次长时间尺度的持续性威胁，攻击识别更加困难。
Unfortunately, the distributed nature of FFT provides a persistent space for various backdoor attacks. While several defense strategies have been proposed, to the best of our knowledge, no countermeasures specifically address backdoor attacks in the FFT process for LLVMs. Most existing techniques are designed for conventional federated learning scenarios or centralized VLM training, exposing two critical issues: (1) \textbf{The high stealthy nature of attack behavior:} Attackers increasingly design their actions to mimic normal users, narrowing the perception’s distinguishing capability\cite{xu2024shadowcast, zhang2024a3fl}; and (2) \textbf{The complexity of detecting sophisticated attack strategies:} To evade defenses, attackers may employ techniques such as limiting angle, magnitude, or sign, transforming a single attack into a multi-round, long-term threat, further complicating attack detection\cite{geisler2024attacking, chen2024optimal, sagliano2024powered, dong2023adaptive,wan2023average}.

% 因此，在本文中，我们针对LVLM的FFT过程，提出了一种新型的抗backdoor防御方案。针对攻击行为感知难题，我们创新地从频域分布一致性入手，将隐性的梯度更新分布差异而非显性的更新离群性作为新的鉴别角度，从而实现对高隐蔽攻击的感知；在此基础上，进一步针对智能化攻击者可能采取的复杂多轮次策略，我们创新地提出了基于意图识别的长效评估架构，有效分离高级持续性威胁，并据此设计安全聚合方法。
% 主要包括以下几方面贡献：
Therefore, in this paper, we propose a novel backdoor defense scheme tailored for the FFT process of LVLMs. To address the challenge of detecting attack behaviors, we introduce a groundbreaking approach based on consistency in frequency domain distributions. Rather than focusing on explicit gradient outliers, we leverage the implicit differences in gradient update distributions as a new identification criterion, enabling the detection of highly covert attacks. Building on this, we further address the issue of complex multi-round strategies employed by intelligent attackers by proposing an innovative long-term evaluation framework based on intent recognition. This framework effectively isolates advanced persistent threats and informs the design of a secure aggregation method.

The main contributions of this scheme include:
\begin{enumerate}
    \item Based on an in-depth analysis of emerging covert backdoor attacks, we first define two core challenges: detecting highly covert attack behaviors and identifying complex attack strategies. We then provide a case study of these issues within the FFT process of large vision models. To the best of our knowledge, this is the first framework capable of recognizing deep-level attack intentions during the fine-tuning process in IoRT networks, effectively defending against covert attacks.
    \item In response to the potential threat of intelligent attackers fragmenting their behaviors to evade detection, we propose an innovative method for constructing attack intentions based on historical behavior sequences. By building an approximate minimal covering hypersphere from these behaviors, the malicious intent hidden behind seemingly disordered, benign actions is fully exposed. 
    \item SecFFT also adopts a novel nonlinear defense strategy, dynamically adjusting aggregation weights using local outlier factors while ensuring fairness for benign nodes and effectively eliminating malicious ones. A series of experiments on public datasets demonstrate that our approach significantly improves model integrity, effectively suppresses covert backdoor attacks, and maintains a low false positive rate.
\end{enumerate}
% 基于对现有新型隐蔽后门攻击的分析，我们首先定义了高隐蔽攻击行为感知和复杂攻击策略识别这两大核心问题，并基于视觉大模型的FFT过程进行实例分析。据我们所知，这是首个在IORT网络中能够实现对微调过程中深层次攻击目的识别，从而抵御高隐蔽攻击的方案。
% 针对智能攻击者可能将攻击行为切片化拆解从而规避防御检测的潜在威胁，我们创新地设计了基于历史行为序列进行攻击意图构建的方法。通过构建历史行为的近似最小覆盖超球，将智能攻击者隐藏在看似杂乱无序、良性无害的攻击行为背后的恶意意图充分暴露。
% 基于意图识别架构，SecFFT能够设计一种非线性的新型防御策略，利用局部离群因子动态调整聚合权重，同时保障良性用户公平性和恶意用户的消除。公有数据集上的系列实验表明，我们的方法能够显著提升模型完整性，有效遏制隐蔽后门攻击，并同时保证极低的误判率。

The remainder of this paper is organized as follows: Section \uppercase\expandafter{\romannumeral2} reviews related works. Section \uppercase\expandafter{\romannumeral3} and \uppercase\expandafter{\romannumeral4} present the system and threat models, respectively. Section \uppercase\expandafter{\romannumeral6} elaborates on the design philosophy of the proposed SecFFT solution, providing comprehensive details on the availability, security, and integrity of FFT in IoRT networks. Section \uppercase\expandafter{\romannumeral7} presents the experimental results. Finally, Section \uppercase\expandafter{\romannumeral8} concludes this paper and briefly explores future directions.

%攻击识别
% Alongside the conti
% Spectral Distribution
% Consistency Verification
% Poisoning with 
% Detection

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/SecFFT-scenario.pdf}
    \caption{FFT process for large vision language models in IoRT network}
    \label{fig1:scene}
    %\vspace{-0.7cm}
\end{figure}

\section{Related Works}
\subsection{Covert backdoor attacks}
%后门攻击对深度学习模型构成了严重的安全威胁，它旨在通过对模型输入添加特殊扰动来诱导目标模型产生不当行为，例如图像分类器中的错误分类等。我们将现有针对模型的后门攻击分为两种，即空间隐蔽性后门攻击和时间隐蔽性后门攻击。
Backdoor attacks pose a significant security threat to deep learning models, aiming to induce improper behavior in the target model by adding specific perturbations to the input, such as misclassification in image classifiers. We classify existing backdoor attacks on models into two types: spatially covert backdoor attacks and temporally covert backdoor attacks.

% 空间隐蔽性后门攻击是指攻击者通过微调模型参数、修改输入特征或操纵模型训练过程等方式，使得现有防御方法无法在特征空间中有效区分恶意攻击者与良性参与者，从而有效逃避检测。EDGE CASE\cite{EDGE_CASE}提出了一种针对联邦学习的边缘案例后门攻击方法，通过在训练和测试数据集中通常不存在但自然存在的输入数据点（即边缘样本）来注入后门。Shadowcast\cite{xu2024shadowcast}通过在特征空间中引入微小、不可察觉的扰动，操纵视觉语言模型（VLMs）在特定视觉输入下生成误导性的文本输出。Flip\cite{jha2023label}通过修改训练数据的标签，使得模型训练轨迹接近于带有后门的专家模型，从而在特征空间中达到隐蔽攻击的效果，即使在图像干净的情况下也能逃避现有检测方法。
\textbf{Spatially Covert Backdoor Attacks} refer to attacks where adversaries fine-tune model parameters, modify input features, or manipulate the model training process in a way that existing defense cannot effectively distinguish between malicious attackers and benign participants in the feature space, thereby evading detection. EDGE CASE\cite{EDGE_CASE} proposes an edge-case backdoor attack method for federated learning by injecting backdoors using input data points that are naturally occurring but typically absent in both training and testing datasets (i.e., edge-case samples). Shadowcast \cite{xu2024shadowcast} manipulates VLMs to produce misleading textual outputs for specific visual inputs by introducing subtle, imperceptible perturbations in the feature space. Flip \cite{jha2023label} modifies the labels of training data so that the model's training trajectory approximates that of an expert model with a backdoor. This hidden process completes covert attacks in the feature space, thus evading existing detection methods even when the images are clean.

% 时间隐蔽性后门攻击是指攻击者通过调整模型训练过程或优化后门植入等方式，使后门在恶意攻击者结束攻击后仍能长期存在，不被后续良性更新所覆盖，从而持续影响模型行为。 Neurotoxin\cite{zhang2022neurotoxin}提出了一种针对联邦学习的更持久的后门攻击方法，通过攻击在训练过程中变化较小的模型参数来增加后门的耐久性，避免与良性用户梯度的冲突，使其不易在后续的模型更新中被清除。ImgTrojan\cite{tao2024imgtrojan}通过在视觉语言模型的训练数据中注入少量恶意样本，使得这些后门即使在模型后续的良性训练中仍能保持有效，从而持续影响模型的行为。\cite{gu2023gradient}提出了一种新的更新控制方法，通过跨层更新幅度归一化和层内更新方向投影，解决了参数高效调优（PET）过程中后门攻击的遗忘问题，从而维持攻击的持久性和隐蔽性。A3FL\cite{zhang2024a3fl}通过对抗性适应损失函数来优化触发器的方式，使得后门能够在全局训练动态中持久存在，从而在联邦学习模型中实现高效且持久的攻击效果。
% Chameleon \cite{dai2023chameleon} focuses on enhancing the spatial covert nature of backdoor attacks by adjusting the relationships between poisoned samples, interference samples, and promoting samples in contrastive learning.
\textbf{Temporally Covert Backdoor Attacks} involve adjusting the model training process or optimizing backdoor implantation such that the backdoor persists even after the malicious attacker has stopped the attack, remaining undetected by subsequent benign updates, and continuing to affect the model’s behavior. NEUR\cite{zhang2022neurotoxin} proposes a more persistent backdoor attack method for federated learning by targeting model parameters that change less during training. This approach increases the durability of the backdoor, avoids conflicts with the gradients of benign nodes, and makes it less likely to be removed in subsequent model updates. ImgTrojan \cite{tao2024imgtrojan} injects a small number of malicious samples into the training data of vision-language models, ensuring that these backdoors remain effective even after subsequent benign training, thereby continuously affecting the model's behavior. \cite{gu2023gradient} proposes a novel update control method that normalizes cross-layer update magnitudes and projects intra-layer update directions to address the issue of backdoor forgetting during parameter-efficient tuning (PET), thus maintaining the persistence and concealment of the attack. A3FL \cite{zhang2024a3fl} optimizes the trigger by using an adversarial adaptation loss function, enabling the backdoor to persist throughout global training dynamics, thereby achieving efficient and persistent attack effects.
% 总之，现有的后门攻击策略在空间隐蔽性和时间隐蔽性方面都有了显著的进展。空间隐蔽性后门攻击通过优化特征空间中的触发器或更新，使得恶意行为难以被现有的检测方法发现，从而实现了更高效、更难以检测的攻击。而时间隐蔽性后门攻击则专注于提高后门的持久性，使得即使在恶意攻击结束后，这些后门依然能够在模型中长期存在并继续影响其行为。通过这些攻击方式的结合，攻击者能够在各种应用场景中有效地躲避检测，并确保攻击效果的持续性，这对现有的防御机制提出了更高的挑战，强调了未来在开发更加鲁棒的防御方法方面的迫切需求。

%总的来看，现有的后门攻击方法已展现出显著的隐蔽性和持久性，能够有效规避当前的检测机制。这些攻击不仅在特征空间中巧妙隐藏恶意意图，还能在长期训练过程中保持攻击效果，对模型行为产生持续而深远的影响，也对模型安全构成了严峻挑战。这对现有的防御机制提出了更高的挑战，强调了未来在开发更加鲁棒的防御方法方面的迫切需求。
Overall, existing backdoor attack methods have demonstrated significant advances in both spatial and temporal concealment, effectively circumventing current detection mechanisms. These attacks not only cleverly hide malicious intent in the feature space but also maintain their effects throughout long-term training, posing a sustained and profound impact on model behavior, thus presenting a severe challenge to model security. This underscores the need for developing more robust defense methods.

\subsection{Backdoor countermeasures}
%在当前深度学习模型的安全性研究中，针对后门攻击的防御措施主要可以分为两大类：后门检测和后门缓解。% Backdoor Mitigation or Elimination
In current research on defense technologies, defense measures against backdoor attacks can be also broadly categorized into two major types: %backdoor detection and backdoor mitigation.

% 后门检测主要旨在识别模型中已存在的后门攻击。在这一类中，SEER\cite{zhu2024seer}提出了一种用于视觉-语言模型的后门检测算法，通过在图像和文本模态的特征空间中联合搜索目标文本和图像触发器，成功实现了在多种场景下的后门检测。FoolsGold\cite{foolsgold}提出了一种通过检测各客户端更新的相似性来识别攻击者方法，该方法利用攻击者的更新通常更为相似这一特征自适应调整每个客户端的学习率，从而减少攻击者对模型训练的影响，有效防御投毒攻击，即使在存在大量恶意客户端的情况下也能显著降低攻击成功率。ASSET\cite{pan2023asset}提出了一种通过主动诱导后门样本和干净样本在模型行为上的差异，从而实现跨多种深度学习范式的鲁棒后门数据检测方法，并在端到端监督学习、自监督学习和迁移学习中表现出色。DECREE\cite{feng2023detecting}提出了一种用于检测自监督学习中预训练图像编码器后门的创新方法，该方法无需依赖标签数据或下游分类器，且在多种数据集和攻击类型下表现出极高的检测准确率。
\textbf{Backdoor Detection} primarily aims to identify existing backdoor attackers. In this category, FoolsGold\cite{foolsgold} proposes a method to identify attackers by detecting the similarity of updates from each client. This method adaptively adjusts the learning rate of each nodes based on the observation that the updates from attackers are usually more similar. It effectively defends against poisoning attacks and significantly lowers the attack success rate even with a large number of malicious nodes. ASSET \cite{pan2023asset} introduces a robust backdoor data detection method across multiple deep learning paradigms by actively inducing behavioral differences between backdoor and clean samples, demonstrating excellent performance in end-to-end supervised learning, self-supervised learning, and transfer learning. DECREE \cite{feng2023detecting} presents an innovative method for detecting backdoors in pre-trained image encoders used in self-supervised learning, achieving high detection accuracy across various datasets and attack types without relying on label data or downstream classifiers.

% 后门缓解则侧重于通过各种技术手段来消除或减轻后门攻击的影响。FLAME\cite{FLAME}提出了一种防御联邦学习中后门攻击的方法，通过动态聚类和权重剪裁来识别并移除可能的恶意模型更新，同时注入差分隐私噪声以有效消除后门的影响，从而在保持全局模型性能的前提下，确保后门攻击的防御效果，即使面对多样的攻击者模型和数据分布也能显著降低攻击成功率。MCLDef\cite{yue2023model}提出了一种基于模型对比学习的两阶段后门防御方法，通过收缩或破坏中毒数据在特征空间中的聚类，并将中毒数据的特征拉向其干净对应物，从而有效去除深度神经网络中的后门，同时在不显著降低模型准确性的情况下提升防御效果。DPoE\cite{liu2023shortcuts}提出了一种基于端到端集成的后门防御框架，通过结合浅层模型和主模型来捕捉和抑制后门触发器，从而有效应对各种显性和隐性的后门攻击，同时减轻噪声标签对模型性能的影响。此外，PSIM\cite{zhao2024defending}提出了一种基于参数高效微调的防御模块，通过利用样本的置信度来识别被后门攻击污染的样本，显著增强了模型抵御权重中毒后门攻击的能力，并在不影响模型准确性的情况下有效过滤出被污染的样本。CleanCLIP\cite{bansal2023cleanclip}通过在视觉和文本编码器上进行无监督微调，独立调整每种模态的表示，以削弱视觉-语言对比学习模型中由后门攻击引入的错误关联，从而有效减少后门攻击的影响，同时保持模型在正常数据上的性能。
\textbf{Backdoor Mitigation} focuses on eliminating or reducing the impact of backdoor attacks through various technical means. FLAME\cite{FLAME} proposes a method to defend against backdoor attacks in federated learning by dynamically clustering and pruning weights to identify and remove potential malicious model updates. It also injects differential privacy noise to effectively eliminate the impact of backdoors, thereby ensuring the defense against backdoor attacks while maintaining global model performance. This approach significantly reduces the attack success rate even when facing diverse attacker models and data distributions. MCLDef \cite{yue2023model} proposes a two-stage backdoor defense method based on model contrastive learning, effectively removing backdoors in deep neural networks by disrupting the clustering of poisoned data in the feature space and pulling the features of poisoned data toward their clean counterparts, while improving defense effectiveness without significantly reducing model accuracy. DPoE \cite{liu2023shortcuts} introduces an end-to-end integrated backdoor defense framework that captures and suppresses backdoor triggers by combining a shallow model and a main model, effectively countering various explicit and covert backdoor attacks while mitigating the impact of noisy labels on model performance. Additionally, PSIM \cite{zhao2024defending} proposes a defense module based on parameter-efficient fine-tuning, significantly enhancing the model's ability to resist weight poisoning backdoor attacks by identifying samples polluted by backdoor attacks using sample confidence, effectively filtering out polluted samples without affecting model accuracy. CleanCLIP \cite{bansal2023cleanclip} reduces the impact of backdoors in vision-language contrastive learning models by adjusting the representations of each modality through unsupervised fine-tuning of the visual and text encoders while maintaining model performance on clean data.

%尽管这些方法在应对后门攻击方面展现了显著效果，但在面对更隐蔽或复杂的后门攻击时，效果依然可能不够理想。某些方法还依赖于外部知识或置信度的设定，可能导致误判或性能瓶颈。此外，这些方法在实际应用中也增加了计算开销和训练时间。因此，未来的研究仍需在提升整体性能与效率的同时，着力解决隐蔽或复杂后门攻击的防御挑战。
Despite the effectiveness of these methods in countering explicit backdoors, their performance may still be insufficient when faced with more covert or complex backdoor attacks. Some methods rely on external knowledge or confidence settings, which may lead to misjudgments or performance bottlenecks. Moreover, these methods increase computational overhead and training time in practical applications. %Therefore, future research must continue to focus on addressing the challenges posed by covert or complex backdoor attacks while enhancing overall performance and efficiency.

\section{System model \& Preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%symbols 表格
\begin{table}[!t]
{
\renewcommand{\arraystretch}{1.2}
\caption{Summary of Main Notation}
\label{notations}
\vspace{0em}
\centering
\begin{tabular}{| c || p{6cm}  |}
\hline
\textbf{Symbol} & \multicolumn{1}{c |}{\textbf{Description}}\\
    \hline
    $ N $ & The number of nodes participating in each round.\\ \hline
    $R_i$ & The $i$-th robot node. \\ \hline
    $D_i$ & The private local dataset of node $R_i$.\\ \hline
    $\theta_g^t, \theta_i^t$ & The global model and local model of $R_i$ at round $t$. \\ \hline
    $\triangledown \theta_i^t$ & Local update of $R_i$ during round $t$. \\ \hline
    $G_i^t $ & Frequency component of $R_i$'s update at round $t$. \\ \hline
    $m$ & The length of the low-frequency components. \\ \hline
    $H^t$ & The matrix formed by stacking $G_i^t$. \\ \hline
    $\tilde{G}^t $ & The extracted global clean ingredient at round $t$. \\ \hline
    $\lambda_{max}^t$ & The largest singular value of matrix $H^t$ at round $t$. \\ \hline
    $\xi_{max}^t$ & The left singular vector corresponding to $\lambda_{max}^t$. \\ \hline
    $Chi_i^t$ & The difference between $\triangledown \theta_i^t$ and $\tilde{G}^t $ at round $t$. \\ \hline
    $t'$ & The round number within total $T$ rounds. \\ \hline
    $O_i^{t'}$ & The intention point of $R_i$ at round $t'$. \\ \hline
    \( {v}_{i}^{t'} \) & The vector of the behavior ray for $R_i$ at round $t'$. \\ \hline
    $lof_i$ & The outlier level of $R_i$.\\ \hline
    $cre_i$ & The credit score of $R_i$.\\ \hline
\end{tabular}
    }
 \vspace{-1.5em}
 \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{figure}[htbp]
%     \centering
%     % \includegraphics[width=0.5\textwidth]{figure}
%     \label{fig:scenario}
% \end{figure}

%如图\ref{fig:scenario}所示，考虑在机器人物联网（IoRT）网络中对视觉大模型进行联邦微调的场景下，整个系统模型包括多个机器人节点和一个中心服务器。每轮，每个机器人节点在本地对视觉大模型进行微调并只上传微调部分的参数更新，随后中心服务器对所有更新进行聚合，然后下发聚合后的参数，开启新一轮的联邦微调。以下是系统模型的详细描述。
As illustrated in Figure \ref{fig1:scene}, \textcolor{red}{consider the scenario of federated fine-tuning (FFT) for large vision language models (LVLMs) in an Internet of Robotic Things (IoRT) network. The entire system model consists of multiple robot nodes and a central server. In each round, each robot node locally fine-tunes the vision model and only uploads the updates of the fine-tuned part. The central server then aggregates all updates and distributes the aggregated parameters to initiate a new round of federated fine-tuning. Below is a detailed description of the system model.}


%\textbf{参与者和数据集}：假设系统模型中存在 $N$ 个机器人节点，每个节点记作 $R_i$, 其中$i \in \{1, 2, \ldots, N\}$。 每个机器人节点 $R_i$ 拥有本地数据集 $D_i = \{x_{i,j}, y_{i,j}\}_{j=1}^{|D_i|}$，其中 $x_{i,j}$ 表示训练样本，$y_{i,j}$ 表示对应的标签数据，$|D_i|$ 为数据集的大小，所有节点本地数据集的并集$D = \bigcup_{i=1}^{N} D_i$构成整体数据集。
\textbf{Participants and Datasets}:
\textcolor{red}{Assume there are $N$ robot nodes in the system model, with each node denoted as $R_i$, where $i \in {1, 2, \ldots, N}$. Each robot node $R_i$ possesses a local dataset $D_i = {x_{i,j}, y_{i,j}}{j=1}^{|D_i|}$, where $x{i,j}$ represents a training sample, $y_{i,j}$ represents the corresponding label, and $|D_i|$ denotes the size of the dataset. The union of all local datasets across the nodes, $D = \bigcup_{i=1}^{N} D_i$, constitutes the overall dataset.}

% In this system model, there are $N$ robotic nodes, each denoted as $R_i$, where $i \in {1, 2, \ldots, N}$. Each robotic node $R_i$ has a local dataset $D_i = \{x_{i,j}, y_{i,j}\}_{j=1}^{|D_i|}$, where $x{i,j}$ represents the input data, $y_{i,j}$ represents the corresponding label, and $|D_i|$ is the size of the dataset. The union of the local datasets across all nodes, $D = \bigcup_{i=1}^{N} D_i$, forms the overall dataset.

%\textbf{LoRA}： 在LoRA(Low-Rank Adaptation) \cite{lora}方法中，每个参数矩阵 $W$ 被表示为：
\textbf{Fine-tuning}:
Taking Low-Rank Adaptation (LoRA) \cite{lora} as an example, model parameter matrix $W$ can be expressed as:
\begin{equation}
    W = W_0 + \Delta W, \quad \Delta W = BA,
\end{equation}
    %其中，$W_0$ 为模型的原始权重矩阵，$\Delta W$ 是低秩增量矩阵，$B$ 和 $A$ 是低秩分解矩阵，$r$ 为矩阵的秩。在对视觉大模型进行联邦微调的场景中，全局模型原始参数为$\Theta_p = \sum {W_0}$，而LoRA引入的增量参数为$\theta_p = \sum {W}$，因此全局模型的整个参数集为$\Theta = \Theta_p + \theta_g$。在整个联邦微调过程中，仅对全局模型的增量参数$\theta_g$ 进行微调训练，保持原始参数$\Theta_p$不变。
\textcolor{red}{where $W_0$ represents the original weight matrix of the model, $\Delta W$ denotes the low-rank increment matrix, $B$ and $A$ are the low-rank decomposition matrices, and $r$ is the rank of the matrix. In the scenario of FFT for LVLMs, the fixed parameters of the global model are given by $\Theta_p = \sum {W_0}$, and the incremental parameters introduced by LoRA are denoted as $\theta_g = \sum {W}$. Therefore, the entire parameter of the global model is $\Theta = \Theta_p + \theta_g$. Throughout the FFT process, only the parameters $\theta_g$ of the global model are fine-tuned, while the parameters $\Theta_p$ remain unchanged.}
    
    % In the federated fine-tuning scenario of the large-scale vision model, the global model's original parameters are $\Theta_p = \sum {W_0}$, while the incremental parameters introduced by LoRA are $\theta_p = \sum {W}$. Therefore, the global model's full parameter set is $\Theta = \Theta_p + \theta_g$. Only the incremental parameters $\theta_g$ are fine-tuned throughout the federated fine-tuning, while the original parameters $\Theta_p$ remain unchanged.
    
%\textbf{本地模型训练}：
\textbf{Local training}:
%在每轮联邦训练的开始时，中心服务器将全局模型的增量参数 $\theta_g^{t-1}$ 发送给每个机器人节点$R_i$。每个节点在获得增量参数$\theta_g^{t-1}$后，基于本地数据集 $D_i$ 进行微调训练。
At the beginning of each FFT round, the central server sends the global incremental parameters $\theta_g^{t-1}$ to each robot node $R_i$. Upon receiving $\theta_g^{t-1}$, each robot node fine-tunes the local incremental parameters based on its local dataset $D_i$.
% 算法\ref{alg:local_update}展示了节点进行本地模型每轮训练的主要过程。
%假设本地训练的轮次为$E_l$，批次大小为$b$，学习率为$\eta$。对于每一轮，节点$R_i$首先从其本地数据集$D_i$中随机抽取一个批次数据$D_i^b \sim Sample(D_i, b)$，然后利用随机梯度下降等优化算法，对增量参数进行更新，
Assume the number of local training epochs is $E_l$, the batch size is $b$, and the learning rate is $\eta$. For each epoch, the node $R_i$ randomly samples a batch of data $D_i^b \sim Sample(D_i, b)$ from $D_i$ and updates the $\theta_g^{t-1}$ using an optimization procedure as:
\begin{equation}
    (\theta_i^{t})^e = (\theta_i^{t})^{e-1} - \eta \nabla f(D_i^b, (\theta_i^{t})^{e-1}),
\end{equation}
%其中$(\theta_i^{t})^e$表示在第$e$轮微调后的参数，初始时$(\theta_i^{t})^0 = \theta_g^{t-1}$。
where $(\theta_i^{t})^e$ denotes the local incremental parameters after $e$ training epoch, with the initial value $(\theta_i^{t})^0 = \theta_g^{t-1}$.
%本地训练的目标是最小化损失函数 $f(D_i^b, (\theta_i^{t})^e)$： 
The local training objective to minimize the loss $f(D_i^b, (\theta_i^{t})^e)$:
\begin{equation}
    f(D_i^b, (\theta_i^{t})^e) = \frac{1}{|D_i^b|} \sum_{j=1}^{|D_i^b|} \ell(x_{i,j}, y_{i,j}; \Theta_p + (\theta_i^{t})^e),
\end{equation}
%其中$\Theta$是模型的原始参数， $\ell$表示损失函数（如交叉熵损失）。本地训练完成后，节点计算其增量参数更新 $\triangledown \theta_i^t = (\theta_i^t)^{E_l} - (\theta_i^t)^0$ 并上传至中心服务器。
where $\ell$ denotes the loss function (e.g., cross-entropy loss). After local training is completed, the robot node computes the update of the incremental parameters $\triangledown \theta_i^t = (\theta_i^t)^{E_l} - (\theta_i^t)^0$ and uploads it to the central server.

%\item \textbf{联邦聚合}：当中心服务器接收到所有机器人节点的本地更新$\triangledown \theta_i^t$后，利用相应的聚合算法进行聚合得到新一轮的全局增量参数$\theta_g^t$：
\textbf{Federated Aggregation}:
\textcolor{red}{After the central server receives the updates $\triangledown \theta_i^t$ from all robot nodes, it applies the appropriate aggregation algorithm to generate the next round's global incremental parameters $\theta_g^t$:
% The central server collects the local updates $\triangledown \theta_i^t$ from each robot node $R_i$ and aggregates them using a specified aggregation algorithm to update the global incremental parameters $\theta_g^t$:   
\begin{equation}
    \theta_g^t = \theta_g^{t-1} + Agg(\triangledown \theta_1^t, \triangledown \theta_2^t, \dots, \triangledown \theta_n^t),
\end{equation}
%其中，$Agg$表示中心服务器使用到的聚合算法，例如FedAvg、FLTrust\cite{cao2020fltrust}、RoseAgg\cite{yang2024roseagg}等，$\theta_g^t$ 是第 $t$ 轮更新的全局增量参数，更新后的全局增量参数 $\theta_g^t$ 将在下一轮训练前下发给所有机器人节点，用于进一步的本地微调。
where $Agg$ denotes the aggregation algorithm employed by the central server, such as FedAvg, FLTrust \cite{cao2020fltrust}, or RoseAgg \cite{yang2024roseagg}.}


\section{Threat Model}
% 在对视觉语言模型进行联邦微调的场景中，我们假设存在一个或者多个由攻击者操纵的恶意节点，并且恶意节点的数量小于全部参与节点的一半。攻击者的目标是对全局模型$\Theta$ 进行后门植入，使得模型能够将任何带有预定义触发器 $\delta$ 的测试输入分类为目标类别，即$\Theta(x+\delta) = y'$，其中$x$代表正常输入，$y'$表示目标类别。同时尽可能保持对干净输入的分类准确性，即$\Theta(x) = y$，其中$y$为输出$x$的原始类别。
\textcolor{red}{In the scenario of FFT for LVLMs, we assume the presence of one or more malicious nodes controlled by attackers, with the number of malicious nodes being less than half of all participating nodes.}

\textbf{Attacker's Goal:} The attacker's goal is to implant a backdoor into the global model $\Theta$, such that the model classifies any input with a predefined trigger $\delta$ as the target class, i.e., $\Theta(x + \delta) = y'$, where $x$ represents a normal input and $y'$ denotes the target class. Simultaneously, the attacker seeks to maintain the classification accuracy for clean inputs, i.e., $\Theta(x) = y$, where $y$ is the original class corresponding to $x$.

%Attacker's Ability: 攻击者对恶意节点的本地训练过程具有完全的控制权，意味着攻击者可以任意操控本地数据、触发器模式、优化策略和本地更新。此外，攻击者可以采用“智能”攻击策略，这种策略的特点是攻击效果不会在单轮训练中显现，而是通过多轮训练的累积效应逐步将后门植入全局模型中。这种场景在实际中是可能存在的，因为中央服务器只能接收到客户端上传的训练后模型更新，而无法知晓每个客户端的具体训练过程。然而，攻击者无法对中央服务器的操作进行干扰，例如，无法更改全局模型的聚合规则或篡改其他良性客户端的本地更新。
\textbf{Attacker's Ability:} 
\textcolor{red}{The attacker has complete control over the local training process of the malicious robot nodes, meaning they can manipulate local data, trigger patterns, optimization strategies, and local updates at will. Additionally, the attacker may adopt a stealthy attack strategy, where the backdoor is not implanted in a single training round but gradually embedded into the global model through the cumulative effect of multiple rounds of training. This scenario is plausible in practice, as the central server only receives the updates uploaded by robot nodes and has no insight into the specific training process of each node. However, the attacker cannot interfere with the aggregation process of the central server (i.e., altering the global model aggregation rules) or tamper with the local updates of benign nodes.}


% In the FFT processes of LVLMs, it is assumed that the attacker has complete control over the local training process of malicious nodes. This means the attacker can manipulate the local dataset, trigger patterns, optimization strategies, and the local update procedure at will. Additionally, the attacker can employ stealthy attack strategies, where the backdoor is not immediately apparent in a single training round but is gradually embedded into the global model through the cumulative effect of multiple training rounds. Such a scenario is feasible in practice since the central server only receives the model updates uploaded by clients after training and has no insight into the specific local training process of each client. However, the attacker is unable to interfere with the central server's operations, such as modifying the global model aggregation rules or tampering with the model updates from other benign clients.


\section{Methodology}
Our SecFFT method consists of two major modules: Instantaneous Attack Behavior Perception and Long-term Attack Intention Detection, which are elaborated, respectively.

\subsection{Instantaneous Attack Behavior Perception}
\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/fig2.png}
    \caption{SecFFT's instantaneous attack behavior perception module with frequency-domain deep outlier feature semantics extraction}
    \label{fig2:instant}
\end{figure}
%^\textbf{Motivation:} 目前的防御策略主要集中于利用攻击的“浅层语义特征”来进行恶意节点识别，所谓浅层语义是指模型上传更新的方向\cite{foolsgold}，范数\ref{sun2019can}以及几何中心\cite{pillutla2022robust}等几何或者统计特性。然而，这些基于浅层特征的防御方法在高维空间中存在显著的局限性。首先，这些防御方式只能在特定假设条件下对某些类型的攻击起作用。例如，余弦距离能够检测出具有较大方向偏差的恶意更新，而欧几里得距离则用于检测通过扩大$L_2$范数影响全局模型的恶意更新。同时最新的研究表明\cite{huang2023multi}，基于欧几里得距离等传统的距离度量方法在高维空间中无法有效区分恶意和良性更新，因为这些方法往往受到维度灾难的影响。此外攻击策略也在不停的演变，现在的攻击者已经能够通过精心调整，使恶意更新在方向、范数等浅层特征上与良性更新相似，从而巧妙地避开这些基于浅层语义特征的防御措施，最终在全局模型中植入后门。但尽管攻击者的攻击策略变得越来越复杂，值得注意的是，后门攻击的本质在于让模型建立起预定义触发器和目标之间的联系，因此无论攻击者如何调整自己的攻击方式或策略，其上传的模型更新相较于良性用户始终在某种分布上具有偏移。
\textbf{Motivation:} 
Current defense strategies primarily focus on identifying malicious nodes by leveraging shallow semantic features of the attack, such as the direction \cite{foolsgold}, magnitude \cite{sun2019can}, and geometric or statistical properties like geometric centers \cite{pillutla2022robust} of updates. However, these defense methods based on shallow semantic features face significant limitations in high-dimensional spaces. First, these methods are only effective against certain types of attacks under specific assumptions. For example, cosine distance can detect malicious updates with large directional deviations, while Euclidean distance is used to detect malicious updates that affect the global model by increasing the $L_2$ norm. Furthermore, recent studies \cite{huang2023multi} have shown that traditional distance metrics, such as Euclidean distance, cannot effectively distinguish between malicious and benign updates in high-dimensional spaces due to the curse of dimensionality. Additionally, attack strategies are constantly evolving, and attackers can now carefully adjust their malicious updates to resemble benign updates in terms of direction, magnitude, and other shallow features. This allows them to bypass defenses based on shallow semantic features and eventually implant backdoors into the global model. \textcolor{red}{Despite the increasingly sophisticated strategies employed by attackers, it is important to note that the essence of backdoor attacks lies in establishing a link between the predefined trigger and the target within the model. Thus, regardless of how attackers adjust their attack strategies, their updates will always exhibit some distributional shift compared to benign nodes.}

% Current defense strategies primarily focus on identifying malicious nodes using "shallow semantic features" of attacks, such as geometric or statistical characteristics like the direction\cite{foolsgold}, magnitude\cite{sun2019can}, and geometric center\cite{pillutla2022robust} of node updates. However, these shallow feature-based defenses have significant limitations in high-dimensional spaces. For instance, these methods often function effectively only under specific assumptions and for certain types of attacks. For example, cosine distance can detect malicious updates with significant directional deviations, while Euclidean distance is typically employed to identify malicious updates that inflate the $L_2$ norm and affect the global model. Recent studies have also shown \cite{huang2023multi} that traditional distance metrics like Euclidean distance are inadequate for distinguishing between malicious and benign updates in high-dimensional spaces due to the curse of dimensionality. Moreover, attack strategies continue to evolve, with attackers now able to fine-tune their updates to resemble benign ones in terms of direction, norm, and other shallow features, effectively bypassing these shallow semantic-based defenses while still implanting backdoors into the global model. It is important to note, however, that the core of a backdoor attack lies in establishing an association between a predefined trigger and the target. Regardless of how the attacker adjusts their attack methods or strategies, the uploaded updates will always display a distributional shift compared to benign nodes.


%\textbf{Overview:} 在神经网络中，每个权重代表两个神经元之间连接的强度，权重分布及其相关的能量在训练过程中会经历动态演变，以缩小模型预测结果与真实目标类别之间的差距。当后门攻击迫使神经网络模型学习一种在正常数据中不存在的关联模式时，根据后门触发器的设计和实现方式，这种模式可能是微妙的，也可能是相当明显的，但无论如何，它都代表了与模型从正常数据中学习到的模式的偏离。因此，为解决基于浅层语义特征的防御方法在高维空间中面临的局限性，我们从后门攻击的本质出发\cite{zeng2021rethinking}，提出了一种基于深层语义特征的防御策略，重点分析模型更新在频域空间上的差异。通过将本地模型更新转换到频域，我们能够更准确地捕捉恶意更新在低频成分上的异常表现，这些异常通常难以被传统的浅层特征防御方法发现。通过对频域上的相应特征进行分析，我们可以有效地区分出恶意节点与良性节点，从而增强联邦学习系统在面对复杂后门攻击时的鲁棒性和检测精度。
\textbf{Overview:} 
In neural networks, each weight represents the strength of the connection between two neurons, and the distribution of these weights, along with their associated energy, undergoes dynamic evolution during training to reduce the gap between the model's predicted results and the true classes. nonetheless, When a backdoor attack forces the neural network to learn an association that does not exist in normal data, which may be subtle or quite obvious depending on the design and implementation of the backdoor trigger, it invariably represents a deviation from the association learned by the model from normal data. \textcolor{red}{To address the limitations faced by defense methods based on shallow semantic features in high-dimensional spaces, we propose a new defense strategy rooted in the essence of backdoor attacks \cite{zeng2021rethinking}, which leverages deep semantic features by focusing on the differences in model updates in the frequency domain. According to our experimental results, by transforming local model updates into the frequency domain, we can more accurately capture the abnormal behavior of malicious updates which is typically difficult to detect using traditional shallow feature-based defenses in low-frequency components. By analyzing the relevant features in the frequency domain, we can effectively distinguish between malicious and benign nodes, thereby enhancing the robustness and accuracy of federated learning in the face of sophisticated backdoor attacks.}

% In deep neural networks, each weight signifies the strength of the connection between two neurons. The distribution of these weights and their corresponding energy dynamically evolves during training to minimize the gap between the model's predictions and the ground truth in the training data. When a backdoor attack compels the neural network to learn an association pattern that does not exist in normal data, this pattern depending on the design and implementation of the backdoor trigger can be subtle or quite evident. Nonetheless, it always signifies a deviation from the patterns learned from normal data. To address the limitations of shallow feature-based defenses in high-dimensional spaces, we propose a defense strategy grounded in the essence of backdoor attacks\cite{zeng2021rethinking}, focusing on deeper semantic features by analyzing differences in the frequency distribution of model updates. By transforming local model updates into the frequency domain, we can more effectively capture the anomalous behavior of malicious updates in low-frequency components, which are typically challenging to detect using traditional shallow-feature detection methods. Through frequency domain feature analysis, we can effectively distinguish malicious nodes from benign ones, thereby enhancing the robustness and detection accuracy of federated learning systems when confronted with sophisticated backdoor attacks. Figure \ref{fig2:instant} formalizes this method we proposed.

\subsubsection{Frequency domain transformation}
%受高维空间中维度灾难的影响，传统的基于距离度量的方法已无法有效识别恶意节点。相反，将模型更新转换到频率域后，其差异将主要集中在低频成分上。因此，专注于低频成分的分析，在提升识别准确率的同时，将显著的降低计算开销。假设每个节点上传的更新为 \(\triangledown \theta_i^t \in \mathbb{R}^d\)，其中 \(i\) 表示机器人节点，\(t\) 表示通信轮次，\(d\) 为本地模型上传更新的维度。对于每个更新 \(\triangledown \theta_i^t\)，对其进行归一化，然后通过一维的DCT-II\cite{ahmed1974discrete}变化将其转换为对应的频率分布，并提取$m$个低频分量，例如5000，得到低频向量\(G_i^t\)。
Due to the curse of dimensionality in high-dimensional spaces, traditional methods based on shallow semantic
feature can no longer effectively identify malicious nodes. In contrast, once model updates are transformed into the frequency domain, their differences are primarily concentrated in the low-frequency components. Focusing on the analysis of these low-frequency components not only improves identification accuracy but also significantly reduces computational overhead. \textcolor{red}{For each update \(\triangledown \theta_i^t\), we apply one-dimensional DCT-II \cite{ahmed1974discrete} to obtain its corresponding frequency distribution. Then we extract $m$ low-frequency components\cite{fereidooni2023freqfed}, such as 5000, yielding the low-frequency vector $G_i^t$.}

%%___________________________________________________________________________________________________________________________
\begin{equation}
G_i^t = Trunc(DCT(Flatten(\triangledown \theta_i^t)), m)
\label{eq:DCT}
\end{equation}

% 频域转换的主要过程如公式\ref{eq:DCT}所示，这里的 $Trunc$ 操作表示仅保留前$m$个低频分量。
The main process of frequency domain transformation is shown in Equation \ref{eq:DCT}, where the $Trunc$ operation indicates retaining only the first $m$ low-frequency components.

\subsubsection{Clean ingredient extraction}
% 在提取到节点更新对应的低频向量\(G_i^t\)后，我们使用流行的聚类算法例如HDBSCAN\cite{mcinnes2017hdbscan}对这些更新进行聚类，得到多个簇$C_0^t, C_1^t, \ldots, C_{\kappa}^t$，其中$\kappa$表示簇的数量。在大多数联邦学习场景中，良性节点的数量通常多于恶意节点的数量，且良性节点的更新通常更接近全局模型的方向并表现出更高的聚集性。基于这一观察，我们选择节点数量最多的簇$C_{max} = \{R_{i_0}, R_{i_1}, \ldots, R_{i_n}\}$作为主要分析对象。为了进一步提取该簇的主要特征或模式，我们对其中所有节点组成的矩阵进行奇异值分解\cite{wang2023scfl}。由于，SVD分解的左奇异向量$\tilde{G}^t$对应于数据的主要方向，因此，$\tilde{G}^t$可以作为良性节点在低频域内的主要特征。
After extracting the corresponding low-frequency vectors \(G_i^t\) from updates, we employ popular clustering algorithms such as HDBSCAN \cite{mcinnes2017hdbscan} to cluster these vectors, resulting in multiple clusters \(C_0^t, C_1^t, \ldots, C_{\kappa}^t\), where \(\kappa\) denotes the number of clusters. In most federated learning scenarios, the number of benign nodes typically exceeds that of malicious nodes, which is consistent with the assumptions outlined in our threat model. Moreover, the updates from benign nodes are generally closer to the direction of the global model and exhibit a higher degree of aggregation. This behavior is also evident in the frequency domain, where it becomes even more pronounced. 
\textcolor{red}{Based on this observation, we select the largest cluster \(C_{max} = \{G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}\}\) as the primary subject for analysis. To further extract the main characteristics of this cluster, we perform singular value decomposition (SVD)\cite{wang2023scfl} on the matrix $H^t = (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n}$ formed by all nodes in this cluster. Since the left singular vectors of the SVD, denoted as \(\tilde{G}^t\), represent the principal directions of these vectors, \(\tilde{G}^t\) can be regarded as the principal component of benign nodes in the low-frequency domain.}


\begin{equation}
\tilde{G}^t = \frac{H^t \xi^t_{max}}{\sqrt{\lambda^t_{max}}}
\label{eq:singular}
\end{equation}


Equation \ref{eq:singular} illustrates the main process of computing the left singular vector $\tilde{G}^t$. $\lambda^t_{max}$ and $\xi^t_{max}$ correspond to the largest eigenvalue and its eigenvector of the matrix $\hat{H}^t = (H^t)^{T} H^t$, respectively. In this way, we effectively extract the principal component that reflect the updates of benign nodes in the frequency domain, so $\tilde{G}^t$ can be used as the clean ingredient for subsequent malicious node detection.

\subsubsection{Chi-square distance calculation}
% 我们利用每个节点的低频向量与“干净成分”之间的差异度来作为衡量恶意节点和良性节点的依据。对于每个节点的低频向量 \(G_i^t\) 以及上一步中求得的“干净成分” \(\tilde{G}^t\)，通过卡方距离来计算两者之间的差异度，得到距离差异集合$S^t = Chi^t_i, Chi^t_2, \ldots, Chi^t_N$。卡方距离的计算过程为：
We use the divergence between each node's low-frequency vector and the clean ingredient as a measureto distinguish between malicious and benign nodes. For each  low-frequency vector \(G_i^t\) and the clean ingredient \(\tilde{G}^t\) we calculate their divergence using the Chi-square distance, yielding \(S^t = \{Chi^t_1, Chi^t_2, \ldots, Chi^t_N\}\). The calculation process for the Chi-square distance is:

\begin{equation}
{Chi^t_i}^2 = \frac{1}{2} \sum_{k=0}^{m-1}\frac{(G_i^t[k] - {\tilde G}^t[k])^2}{|G_i^t[k]|+|{\tilde G}^t[k]| + \epsilon}
\label{equation:KL}
\end{equation}
% 其中 \(m\) 是低频向量的维度，\(\epsilon\) 是一个小的常数，用于避免分母为零。相比于传统的欧氏距离，卡方距离根据两个向量对应分量的大小进行加权，使得特征值较大的部分对距离的影响更大，从而能够更准确地反映低频向量中重要特征之间的差异，同时忽略不重要的噪声成分。
where \(G_i^t[k]\) denotes the k-th element of vector \(G_i\) and \(\epsilon\) is a small constant to avoid division by zero. Compared to the traditional Euclidean distance, the Chi-square distance weights according to the magnitude of the corresponding components of the two vectors, making the influence of components with larger feature values more significant on the distance. This allows for a more accurate reflection of the differences between important features in the low-frequency vectors, while ignoring unimportant noise components.

% 为什么要用卡方距离，不用欧式距离？实验论证？

\subsubsection{Single-round malicious behavior perception}
% 为了准确地识别恶意节点，我们利用良性节点的低频成分与干净成分之间的差异度相比于恶意节点与干净成分之间更为相似这一特性，对差异集合$S^t$进一步进行聚类分析。具体而言，我们采用流行的KMeans聚类算法\cite{wan2023four}对距离差异集合$S^t$进行聚类，并将类别数设置为2，得到聚类\(C'_1, C'_2\)，将用户数量较大的簇\(C'_{max}\)中的所有节点标记为良性节点， 记作为\(U_{nor}\)，将另一簇\(C'_k\) \(k \neq {max}\)中的所有节点标记为恶意节点，记作\(U_{mal}\)。  
To accurately identify malicious nodes, we leverage the characteristic that the divergence between benign nodes' low-frequency components and the clean ingredient is more similar compared to that of malicious nodes. Based on this, we further perform cluster analysis on the divergence set \(S^t\). Specifically, we employ the popular clustering algorithm KMeans \cite{wan2023four} to \(S^t\), setting the number of clusters to 2, yielding two clusters \(C'_1, C'_2\). Based on the assumption before,  we label all nodes in the cluster with the larger number of nodes \(C'_{max}\) as benign nodes, denoted by \(U_{nor}\). while all nodes in the other cluster \(C'_k\) (\(k \neq {max}\)), are labeled as malicious nodes, denoted as \(U_{mal}\).

% 算法\ref{alg:malicious-node-detection}展示了单轮恶意用户识别的整体过程，其中3-6行代表了频率转换的计算过程，7-12行代表了“干净分量”$\tilde G^t$的计算过程，13-16行代表了每个用户与“干净分量”间的卡方差异度的计算过程，最后17-18行代表了通过KMeans聚类算法进行恶意用户检测的计算过程。
Algorithm \ref{alg:malicious-node-detection} outlines the overall process of Instantaneous Attack Behavior Perception. 
Lines 3-6 describe the computation process of frequency domain transformation, lines 7-12 detail the extraction process of clean component, lines 13-16 cover the calculation of the Chi-square divergence between each update and the clean ingredient, and finally, lines 17-18 outline the process of single-round malicious behavior perception using KMeans.

\begin{algorithm}
\caption{Instantaneous Attack Behavior Perception}
\label{alg:malicious-node-detection}
\begin{algorithmic}[1]
\State \textbf{Input:} $d$, $N$, $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$, $m$ \Comment{$d$ is the dimension of each update; $N$ is the number of nodes participating during each round; $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$ is the local updates from robot nodes during the $t$-th round; $m$ is the length of low-frequency components}
\State \textbf{Output:} $U_{nor}$, $U_{mal}$ \Comment{benign nodes, malicious nodes}
\State{\color{CadetBlue}/* \textbf{Frequency Domain Transformation */}} 
% \State Step 1: Frequency Domain Transformation
\For {$R_i \in \textcolor{red}{\{R_1, \ldots, R_N\}}$}
    \State \textcolor{red}{$G_i^t \gets Trunc(DCT(Flatten(\triangledown \theta_i^t))), m)$}
\EndFor

% \State
\State{\color{CadetBlue}/* \textbf{Clean Ingredient Extraction */}} 
% \State Step 2: Clean Ingredient Extraction
\State $(C_0^t, C_1^t, \ldots, C_{\kappa}^t) \gets Clustering\textcolor{red}{ (G_0^t, G_1^t, \ldots, G_N^t)}$ \Comment{$\kappa$ denotes the number of clusters}
\State \textcolor{red}{$ C^t_{max} \gets \underset{C^t_j}{\arg\max} \, |C^t_j|$ \Comment{$|C^t_j|$ denotes the number of nodes in cluster $C^t_j$, $j = 1, 2, \ldots, \kappa $}}
\State $H^t \gets (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n} $ \Comment{Stacking to form Matrix $H^t$, where $R_{i_0}, R_{i_1}, \ldots, R_{i_n} \in C^t_{max}$.}

\State $\hat{H}^t \gets (H^t)^{T} H^t$
\State $\lambda_{max}^t, \xi_{max}^t \gets eig(\hat{H}^t)$ \Comment{Calculating the maximum singular value and its corresponding eigenvector}
\State $\tilde{G}^t \gets \frac{H^t \xi_{max}^t}{\sqrt{\lambda_{max}^t}}$ \Comment{The clean ingredient}

% \State
\State{\color{CadetBlue}/* \textbf{Chi-square distance calculation */}} 
% \State Step 3: Chi-square distance calculation
% \State $P_i^t \gets Softmax(G_i^t), \, Q^t \gets Softmax(\tilde{G}^t)$
\For {$R_i \in \textcolor{red}{\{R_1, \ldots, R_N\}}$}
    \State ${Chi_i^t}^2 \gets \frac{1}{2} \sum_{k=0}^{m-1}\frac{(G_i^t[k] - {\tilde G}^t[k])^2}{|G_i^t[k]|+|{\tilde G}^t[k]| + \epsilon}$
\EndFor
\State \textcolor{red}{$S^t \gets \{Chi^t_1, Chi^t_2, \ldots, Chi^t_N\}$} \Comment{The Distance differences calculated by Chi-square distance.}

% \State
\State{\color{CadetBlue}/* \textbf{Single-round malicious behavior perception */}} 
% \State Step 4: Single-round malicious behavior perception
\State $\textcolor{red}{\{{C^t_1}', {C^t_2}'\}} \gets KMeans(S^t, 2)$ \Comment{Cluster $S$ into 2 clusters using KMeans.}
\State \textcolor{red}{$U_{nor} \gets C'_{max}$, $U_{mal} \gets \{C'_i \, | \, i \neq max\}$}

\end{algorithmic}
\end{algorithm}


\subsection{Long-term Attack Intention Detection}

% \textbf{Motivation}: 为了规避异常检测，有很多通过多轮次的组合攻击来植入后门的攻击。这些攻击很难在单轮次中检测出来，大致分为三类：1)限制大小的攻击，如\cite{geisler2024attacking, chen2024optimal}，这些攻击方法会限制单次攻击的大小，使得攻击并不是很明显，从而变得难以检测；2)限制角度的攻击，如\cite{you2023three, sagliano2024powered, dong2023adaptive}，这些攻击会限制每次攻击的角度，使其与正常的攻击类似从而变得难以识别；3)限制符号的攻击，如\cite{wan2023average, zhu2023boosting}，这些攻击通过梯度缩放或者梯度合成，控制恶意攻击的梯度与正常客户端梯度的正负维持一致，从而增加识别难度。本部分结合每个客户端的历史记录，通过识别攻击者最终的模型引导意图点来识别恶意节点。
\textbf{Motivation}: To evade anomaly detection systems, many backdoor attacks employ multi-round composite strategies that are difficult to detect in a single round. These attacks can be broadly classified into three types: (1) \textbf{Size-Limited Attacks} (e.g., \cite{geisler2024attacking, chen2024optimal}), which constrain the magnitude of each attack to make it subtle and less conspicuous, thereby reducing its detectability; (2) \textbf{Angle-Limited Attacks} (e.g., \cite{you2023three, sagliano2024powered, dong2023adaptive}), which restrict the direction of each attack so that it appears similar to legitimate updates, making them harder to recognize; and (3) \textbf{Sign-Limited Attacks} (e.g., \cite{wan2023average, zhu2023boosting}), which use techniques such as gradient scaling or gradient composition to ensure that the signs of the malicious gradients align with those of legitimate clients, thereby increasing the difficulty of detection. This section presents an approach that leverages each client's historical records to identify malicious nodes by analyzing their ultimate intent to manipulate the global model.



% 前面的防御已经可以有效地针对单轮次攻击进行识别，本部分主要结合客户端的历史记录对客户端进行有效的识别。本部分将保留历史$T$轮次的全局模型$\theta_g^{t'}$，其中$\max\{t-T+1, 1\}\leq  t'\leq t$，并将其Flatten后视为高维空间中的一个点；同时保留每个客户端的历史更新变化，将其视为高维空间中的一个向量，将其延伸后视为一个射线。对于每个客户端，使用最小覆盖球算法计算得到一个最小的超球，覆盖$\zeta$比例的射线。最终球心的位置可以被视为对应客户端对全局模型的意图引导点，球心的半径可以视为对应客户端的置信度。

\textbf{Overview}: The previous defense algorithms have effectively identified single-round attacks; this section focuses on leveraging clients' historical records for effective identification. We maintain the global models $\theta_g^{t'}$ from the past $T$ rounds, where $\max\{t-T+1, 1\}\leq t'\leq t$, and consider their flattened versions as points in a high-dimensional space. Simultaneously, we keep track of each client's historical updates, viewing them as vectors in the high-dimensional space and extending them as rays. For each client, we use the Minimum Enclosing Ball algorithm to compute a minimal hypersphere that covers a $\zeta$ proportion of the ray. The final position of the hypersphere's center can be regarded as the intended steering point of the global model for the corresponding node, and the radius of the hypersphere can be regarded as the reliability level.



This section mainly consists of four steps:

\subsubsection{Construction of weights updates and model databases}

% 像正常的联邦学习过程一样，中央服务器每次下发一个全局模型，每个客户端得到全局模型后使用本地数据进行训练，并将更新变化上传到中央服务器中。我们将第$t$轮次的全局模型记为$\theta_t$，将客户端$i$第$t$轮次训练后的模型记为$\theta^t_i$。客户端$i$将训练后的模型$\theta^t_{i}$减去训练前中央服务器下发的全局模型$\theta^t$，就得到了$t$轮次的更新变化$\triangledown \theta^t_{i}=\theta^t_{i}-\theta^t$。客户端将更新变化$\triangledown \theta^t_{i}$上传到中央服务器，中央服务器在聚合的同时，记录下每个客户端当前轮次的更新$\triangledown \theta^t_{i}$展平后的结果$\bar{\theta_i^t}$，同时存下中央服务器上轮次下发的全局模型$\theta^{t-1}$。中央服务器最多保留$T$轮次的模型和更新历史记录。“Keep T-rounds History”的主要算法过程如算法\ref{alg:malicious-node-detection-history}的3-13行所示。
As in a typical federated learning process, the central server distributes a global model in each round. Upon receiving the global model, each client trains on its local data and uploads the updates to the central server. Let the global model in the $t$-th round be denoted as $\theta_t$, and the model of client $i$ after training in the $t$-th round be denoted as $\theta^t_i$. Client $i$ computes its update in the $t$-th round as the difference between the trained model $\theta^t_{i}$ and the global model received before training $\theta^t$, i.e., $\triangledown \theta^t_{i} = \theta^t_{i} - \theta_g^t$. The client uploads the update $\triangledown \theta^t_{i}$ to the central server. While aggregating, the central server records the flattened result of each client's update in the current round, $\bar{\theta_i^t}$, as well as the global model $\theta^{t-1}$ distributed by the central server in the previous round. The central server retains the models and weights update histories for up to $T$ rounds.% The main algorithm process for "Keep T-rounds History" is shown in lines 3-13 of Algorithm \ref{alg:malicious-node-detection-history}. 

\subsubsection{Construction of attack intention}
% 这个问题可以抽象为高维空间中的一些具有起点的射线。射线的起点代表上轮次的全局模型，射线的方向代表本轮次展平后的更新变化。问题的优化目标是：找到一个最小的超球，至少覆盖$\zeta$比例的射线。
This problem can be abstracted as rays in a high-dimensional space with specific starting points. The starting point of a ray represents the global model from the previous round, and the direction of the ray represents the flattened update in the current round. The optimization goal of the problem is to find a minimum hypersphere that covers at least a $\zeta$ proportion of the rays.
% 我们使用符号$O_i$代表客户端$i$在高维空间中超球的球心，使用符号$r_i$代表这个超球的半径。假设当前轮次为$t$，$t'$是最近$T$轮次中的其中一轮，使用符号$\tilde O_i^{t'}$代表球心到第$t'$对应射线的最近点。则可以定义优化问题：
We use the symbol $O_i$ to represent the center of the hypersphere for client $i$ in the high-dimensional space and $r_i$ to represent the radius of this hypersphere. Suppose the current round is $t$, and $t'$ is one of the recent $T$ rounds. Let $\tilde O_i^{t'}$ denote the closest point from the hypersphere center to the ray corresponding to round $t'$. Then, the optimization problem can be defined as:

\begin{equation}
    \min_{O_i, r_i} \quad r_i
\end{equation}

\begin{equation} 
\text{s.t.} \quad \left| \left\{ t' \mid \| O_i - \tilde{O}_{i}^{t'} \| \leq r_i \right\} \right| \geq \zeta T,
\end{equation}
\begin{equation} 
    \quad\quad\max\{t-T+1, 1\}\leq  t'\leq t.
\end{equation}
% “Obtain the Purpose Intention”的主要算法过程如算法\ref{alg:malicious-node-detection-history}的14-18行所示。此部分又可以分为“Construct Ray Model”和“Minimum Enclosing Hypersphere Calculation”两部分。
%The main algorithm process for "Obtain the Purpose Intention" is shown in lines 14-18 of Algorithm \ref{alg:malicious-node-detection-history}. This section can be further divided into two parts: "Construct Ray Model" and "Minimum Enclosing Hypersphere Calculation."
% “Construct Ray Model”的主要过程如下。对于每个客户端 \(R_i\)，中央服务器保留了最近 \(T\) 轮的全局模型历史以及每轮次的更新变化历史。设 \( \theta_g^{t-T}, \theta_g^{t-T+1}, \dots, \theta_g^{t-1} \) 是最近 \(T\) 轮次的全局模型，且这些全局模被“展平”到了高维空间中的一个点。类似地，设 \( \overline{\triangledown\theta_{i}^{t-T}}, \overline{\triangledown\theta_{i}^{t-T+1}}, \dots, \overline{\triangledown\theta_{i}^{t-1}} \) 是最近 \(T\) 轮次客户端 \(i\) 上传的展平后的梯度变化向量。

%The main process of "Construct Ray Model" is as follows. 
For each client \(R_i\), the central server retains the global model history and the update history for the most recent \(T\) rounds. Let \( \theta_g^{t-T}, \theta_g^{t-T+1}, \dots, \theta_g^{t-1} \) represent the global models of the most recent \(T\) rounds, which have been "flattened" to a point in a high-dimensional space. Similarly, let \( \overline{\triangledown\theta_{i}^{t-T}}, \overline{\triangledown\theta_{i}^{t-T+1}}, \dots, \overline{\triangledown\theta_{i}^{t-1}} \) represent the flattened gradient update vectors uploaded by client \(i\) in the most recent \(T\) rounds.
% 对于每一轮 \( t' \) (\( \max\{t-T+1, 1\}\leq  t'\leq t \))，我们将每个射线的起点表示为展平后的全局模型 \( \theta_g^{t'} \)，并将每个射线的方向向量表示为展平后的梯度变化 \( \overline{\triangledown\theta_{i}^{t'}} \)。因此，射线模型可以构建如下：
For each round \( t' \) (\( \max\{t-T+1, 1\}\leq  t'\leq t \)), the starting point of each ray is represented by the flattened global model \( \theta_g^{t'} \), and the direction vector of each ray is represented by the flattened gradient update \( \overline{\triangledown\theta_{i}^{t'}} \). Thus, the ray model can be constructed as follows:

\begin{equation}
    \left\{\begin{matrix}
    \widetilde{\theta_{i}^{t'-1}} = Flatten(\theta_g^{t'-1})\\
    {v}_{i}^{t'} = \overline{\triangledown\theta_{i}^{t'}}
    \end{matrix}\right.,
\end{equation}
% 其中，\( \widetilde{\theta_{i}^{t'-1}} \) 是射线的起点，\( {v}_{i}^{t'} \) 是射线的方向向量。则射线方程为：
where \( \widetilde{\theta_{i}^{t'-1}} \) is the starting point of the ray, and \( {v}_{i}^{t'} \) is the direction vector of the ray. The ray equation is then given by:

\begin{equation}
l_i^{t'}=\widetilde{\theta_{i}^{t'-1}}+\alpha {v}_{i}^{t'},
\end{equation}
% 其中，$\alpha\in [0, +\infty)$为射线的自变量参数。
where $\alpha\in [0, +\infty)$ is the parameter of the ray.
% “Minimum Enclosing Hypersphere Calculation”的主要过程如下。基于构建的射线模型，使用最小覆盖球算法找到一个能够覆盖至少 \( \zeta \) 比例的射线的最小超球。首先，设定初始球心 \( O_{i,0} \) 为所有射线起点的几何中心，计算公式如下：
Therefore, we approximate the attack intention hiddden behind the series of behaviors based on Minimum Enclosing Hypersphere Ball (MEHB) construction as follows. Based on the constructed ray model, the MEHB model is adopted to find the smallest hypersphere that can cover at least a \( \zeta \) proportion of the rays, which denotes the intention of the current node. First, the initial center of the hypersphere \( O_{i,0} \) is set to the geometric center of all ray starting points, calculated as follows:

\begin{equation}
    O_{i,0} = \frac{1}{\min\{T, t\}} \sum_{t'=\max\{t-T+1, 1\}}^{t} \widetilde{\theta_g^{t'-1}}.
\end{equation}

% 初始半径 \( r_{i,0} \) 设定为从初始球心 \( O_{i,0} \) 到所有射线起点的最大距离：
The initial radius \( r_{i,0} \) is set as the maximum distance from the initial center \( O_{i,0} \) to all ray starting points:

\begin{equation}
r_{i,0} = \max_{t'=\max\{t-T+1, 1\}}^{t}  \|O_{i,0} - \widetilde{\theta_{g}^{t'-1}}\|.
\end{equation}
% 接下来，采用迭代方法来更新球心和半径：

% 对于每次迭代 \( k \)，计算当前球心 \( O_{i,k} \) 到所有射线的最近点 \( \tilde{O}_{i,k}^{t'} \)。对于每个节点$R_i$的第$t'(\max\{t-T+1, 1\}\leq  t'\leq t)$轮，对于射线 \( l_i^{t'} \)，找到球心 \( O_{i,k} \) 与当前射线的投影点 \( \hat O_{i,k}^{t'} \)，并计算参数 \( \alpha_k \)：
Then, the center and radius are iteratively updated. 
For each iteration \( k \), compute the nearest points \( \tilde{O}_{i,k}^{t'} \) from the current center \( O_{i,k} \) to all rays. For the $t'$-th round of each node $R_i$ (\(\max\{t-T+1, 1\}\leq  t'\leq t\)), for the ray \( l_i^{t'} \), find the projection point \( \hat O_{i,k}^{t'} \) of the center \( O_{i,k} \) onto the current ray, and compute the parameter \( \alpha_k \):

\begin{equation}
\alpha_k = \frac{(O_{i,k} - \widetilde{\theta_{i}^{t'-1}}) \cdot {v}_{i}^{t'}}{{v}_{i}^{t'}\cdot {v}_{i}^{t'}},
\end{equation}
% 则最近点 \( \tilde O_{i,k}^{t'} =\widetilde{\theta_{i}^{t'-1}}+\max \left\{ 0, \alpha_k\right\} {v}_{i}^{t'} \)。
% 计算当前球心 \( O_{i,k} \) 到这些最近点 \( \tilde O_{i,k}^{t'} \) 的距离集合 \( Dis_{i,k}= \{ \| O_{i,k}-\tilde O_{i,k}^{t'} \|, \max\{t-T+1, 1\}\leq  t'\leq t\} \)，并按从小到大的顺序进行排序，然后暂时舍弃$1-\zeta$比例的射线来忽略离群点对计算过程的影响，得到集合${Dis}_{i,k}'$，保留射线对应轮次的集合记为$\tilde T$。将球心向着被保留的最近点中距离最远的点$\tilde{O}_{i,k}^{t_{max}'}$移动：

Thus, the nearest point is given by \( \tilde O_{i,k}^{t'} =\widetilde{\theta_{i}^{t'-1}}+\max \left\{ 0, \alpha_k\right\} {v}_{i}^{t'} \). 
Calculate the set of distances from the current center \( O_{i,k} \) to these nearest points \( \tilde O_{i,k}^{t'} \), denoted as \( Dis_{i,k}= \{ \| O_{i,k}-\tilde O_{i,k}^{t'} \|, \max\{t-T+1, 1\}\leq  t'\leq t\} \). Sort these distances in ascending order and temporarily discard a proportion of \(1-\zeta\) of the rays to ignore the impact of outliers, resulting in the set ${Dis}_{i,k}'$. The rounds corresponding to the retained rays are denoted as $\tilde T$. Move the center towards the farthest point $\tilde{O}_{i,k}^{t_{max}'}$ among the retained nearest points:

\begin{equation}
O_{i,k+1} = O_{i,k} + \eta' (\tilde{O}_{i,k}^{t_{max}'}-O_{i,k}),
\end{equation}
% 其中$\eta'$为学习率。移动后的球心半径为：
where $\eta'$ is the learning rate. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{figures/fig3.png}
    \caption{Long-term attack intention detection module and secure aggregation}
    \label{fig3:longterm}
\end{figure}

The radius of the moved center is:

\begin{equation}
r_{i,k+1} =  \{ \max\{\| O_{i,k+1}-\tilde O_{i,k+1}^{t'} \|\}, t'\in \tilde T\} ,
\end{equation}



% 其中$\tilde O_{i,k+1}^{t'}$为更新后的球心$O_{i,k+1}$到被保留射线的最近点。当更新后的半径 \( r_{i,k+1} \) 与上一次的半径 \( r_{i,k} \) 相差小于一个预设的阈值 \( \lambda \)，或者达到预设的最大迭代次数$k_{max}$时，停止迭代。
where $\tilde O_{i,k+1}^{t'}$ is the nearest point from the updated center $O_{i,k+1}$ to the retained rays. When the difference between the updated radius \( r_{i,k+1} \) and the previous radius \( r_{i,k} \) is smaller than a predefined threshold \( \lambda \), or when the maximum number of iterations $k_{max}$ is reached, the iteration stops.

\subsubsection{LOF-driven malicious intention detection}
% “Abnormal Detection”的主要过程基于局部离群因子（Local Outlier Factor, LOF）得到异常点。LOF算法是一种基于密度的异常检测方法，算法的核心思想是通过计算一个数值$lof_i$来反应节点$i$的异常程度。$lof_i$大致意思是节点$i$目的意图点$O_i$周围意图点所处位置的平均密度比上$O_i$所在位置的密度。比值越大于$1$，则$O_i$所在位置的密度越小于周围其他意图点所在位置的密度，即$O_i$越有可能是异常点。首先定义意图点$O_i$的$q$距离$\widetilde{dis_i^q}$，假设高维空间中存在节点$j$的意图点$O_j$，则有$O_j$与$O_i$之间的距离为$\|O_i-O_j\|$，如果满足以下两个条件，我们就认为$\widetilde{dis_i^q}=\|O_i-O_j\|$：
The main process of Abnormal Detection identifies outliers based on the Local Outlier Factor (LOF). The LOF algorithm is a density-based anomaly detection method. Its core idea is to calculate a value $lof_i$ to reflect the degree of abnormality of node $i$. The value of $lof_i$ represents the ratio of the average density of the intention points around the intention point $O_i$ to the density at the location of $O_i$. The greater this ratio is than $1$, the lower the density around $O_i$ compared to the surrounding intention points, indicating that $O_i$ is more likely to be an outlier. First, we define the $q$-distance $\widetilde{dis_i^q}$ of the intention point $O_i$. Assume there is an intention point $O_j$ for node $j$ in the high-dimensional space, and the distance between $O_j$ and $O_i$ is $\|O_i-O_j\|$. If the following two conditions are satisfied, we have $\widetilde{dis_i^q} = \|O_i-O_j\|$:

% \begin{itemize}
%     \item 在样本空间中，至少存在$q$个意图点$O_j'$，使得$\|O_i-O_j'\|\leq \|O_i-O_j\|$, 其中$j'\neq i$；
%     \item 在样本空间中，至多存在$q-1$个意图点$O_j'$，使得$\|O_i-O_j'\|< \|O_i-O_j\|$, 其中$j'\neq i$。
% \end{itemize}

\begin{itemize}
    \item In the sample space, there are at least $q$ intention points $O_j'$ such that $\|O_i-O_j'\| \leq \|O_i-O_j\|$, where $j' \neq i$;
    \item There are at most $q-1$ intention points $O_j'$ such that $\|O_i-O_j'\| < \|O_i-O_j\|$, where $j' \neq i$.
\end{itemize}

% 总的来说，$O_i$的$q$距离$\widetilde{dis_i^q}$表示高维空间中距离第$q$远的点。之后定义意图点$O_i$的第$q$距离邻域$Nei_i$为到$O_i$距离不超过$\widetilde{dis_i^q}$的所有意图点的集合。由于可能同时存在多个第$q$距离的数据，所以$|Nei_i|\geq q$。可以想象，离群度越大的意图点的$q$距离往往较大，离群度越小的意图点的$q$距离往往较小。之后定义意图点$O_i$相对于意图点$O_j$的可达距离：
In summary, the $q$-distance $\widetilde{dis_i^q}$ of $O_i$ represents the distance to the $q$-th farthest point in the high-dimensional space. Then, we define the $q$-distance neighborhood $Nei_i$ of the intention point $O_i$ as the set of all intention points whose distance to $O_i$ does not exceed $\widetilde{dis_i^q}$. Since multiple data points at the $q$-distance may exist simultaneously, $|Nei_i| \geq q$. It can be imagined that the $q$-distance of intention points with greater outlier degrees is often larger, while those with smaller outlier degrees tend to have smaller $q$-distances. Next, we define the reachable distance of intention point $O_i$ relative to point $O_j$:

\begin{equation}
rea_{i,j}=\max\{\widetilde{dis_i^q}, \|O_i-O_j\|\},
\end{equation}

% 也就是说，如果意图点$O_j$远离意图点$O_i$，则两者之间的可达距离就是他们之间的实际距离$\|O_i-O_j\|$；而如果二者距离足够近，则可达距离用意图点$O_i$的$q$距离$\widetilde{dis_i^q}$代替。之后定义意图点$O_i$的局部可达密度$lrd_i$为其$Nei_i$所有意图点的平均可达距离的倒数，即：
In another word, if the intention point $O_j$ is far from the intention point $O_i$, the reachable distance between them is their actual distance $\|O_i-O_j\|$; if they are close enough, the reachable distance is replaced by the $q$-distance $\widetilde{dis_i^q}$ of the intention point $O_i$. Next, we define the local reachable density $lrd_i$ of the intention point $O_i$ as the reciprocal of the average reachable distance of all intention points in its $Nei_i$:

\begin{equation}
lrd_i=1/(\frac{\sum_{j\in Nei_i} rea_{i,j}}{|Nei_i|})
\end{equation}

% 此时，若有重复点，则可能导致$lrd$变为无限大。$lrd_i$的可以理解为意图点$O_i$所处位置的密度，密度越高则意图点$O_i$越有可能属于同一簇，密度越低则意图点$O_i$越有可能是离群点。也就是说，如果意图点$O_i$和周围邻域点是同一簇，则可达距离可能为较小的$\widetilde{dis_i^q}$，导致可达距离之和较小，密度值较高；如果$O_i$和周围邻居意图点较远，则可达距离可能会取较大的$\|O_i-O_j\|$，导致可达距离之和较大，密度值较低，越有可能是离群点。最后，我们定义意图点$O_i$的局部离群因子$lof_i$为其$Nei_i$所有意图点的局部可达密度与其自身局部可达密度的比值的平均值，即：
At this point, if there are duplicate points, $lrd$ may become infinite. $lrd_i$ can be understood as the density at the location of intention point $O_i$. The higher the density, the more likely intention point $O_i$ belongs to the same cluster; the lower the density, the more likely $O_i$ is an outlier. In other words, if intention point $O_i$ and its surrounding neighborhood points are in the same cluster, the reachable distance is likely to be the smaller $\widetilde{dis_i^q}$, resulting in a smaller sum of reachable distances and a higher density value; if $O_i$ is far from its neighboring intention points, the reachable distance is likely to take the larger $\|O_i-O_j\|$, resulting in a larger sum of reachable distances and a lower density value, making it more likely to be an outlier. Finally, we define the local outlier factor $lof_i$ of intention point $O_i$ as the average of the ratio of the local reachable densities of all intention points in its $Nei_i$ to its own local reachable density:

\begin{equation}
    lof_i=\frac{\sum_{j\in Nei_i}\frac{lrd_j}{lrd_i}}{|Nei_i|}=\frac{\sum_{j\in Nei_i} lrd_j}{|Nei_i|\cdot lrd_i}
\end{equation}

% 如果$lof_i$比较接近$1$，则说明意图点$O_i$与其邻域点密度差不多，$O_i$可能和邻域属于同一簇；如果$lof_i$小于$1$，则说明意图点$O_i$的密度高于其邻域点的密度，$O_i$为密集点；如果$lof_i$大于$1$，则说明意图点$O_i$的密度低于其邻域点的密度，$O_i$可能是离群点。总之，LOF算法主要通过比较每个意图点$O_i$和其邻域点的密度来判断$O_i$是否为离群点，密度越低，则越有可能是离群点。而密度主要是通过点之间的距离来计算的，点之间的距离越远密度越低，距离越近密度越高。计算每个节点$i$的局部离群因子$lof_i$，将$lof_i$大于$1$的客户端视为异常客户端，并将其梯度丢弃。
If $lof_i$ is close to $1$, it indicates that the density of intention point $O_i$ is similar to its neighboring points, suggesting that $O_i$ and its neighborhood belong to the same cluster. If $lof_i$ is less than $1$, it means that the density of intention point $O_i$ is higher than its neighboring points, indicating that $O_i$ is a dense point. If $lof_i$ is greater than $1$, it means that the density of intention point $O_i$ is lower than its neighboring points, suggesting that $O_i$ may be an outlier. In conclusion, the LOF algorithm mainly determines whether $O_i$ is an outlier by comparing the density of each intention point $O_i$ with that of its neighboring points. The lower the density, the more likely it is an outlier. Density is primarily calculated based on the distance between points: the greater the distance between points, the lower the density; the closer the distance, the higher the density. After calculating the local outlier factor $lof_i$ for each node $i$, clients with $lof_i$ greater than $1$ are regarded as abnormal clients, and their gradients are discarded.
% “Abnormal Detection”的主要过程如算法\ref{alg:malicious-node-detection-history}的19-30行所示。
% The main process of "Abnormal Detection" is shown in lines 19-30 of Algorithm \ref{alg:malicious-node-detection-history}.

\subsubsection{Secure Aggregation}
% 剔除了异常节点后，依据正常节点的置信度$cre$进行聚合。其中定义：
After removing abnormal nodes, the aggregation is performed based on the confidence $cre$ of normal nodes. The definition is as follows:

\begin{equation}
    cre_i=\frac{1}{r_i+\rho},
\end{equation}
% $\rho$是一个很小的正数，以防分母为$0$。

% 如图\ref{fig:before-agg}所示，使用LOF算法识别恶意客户端可以剔除潜在的恶意节点，但是在正常的节点中，同样存在一些置信度很低的节点。这些节点的最小覆盖球甚至可能和异常节点有一定交集。因此，在聚合的过程中，这些置信度较低的点所占的权重就应该越低。

% 试想，假设有两个节点的最小覆盖超球的半径都很小，但是相差倍数很高，那么它们计算出来的置信度相差倍数也会很高。但其实它们的意图点都十分明确，因此权重应该都比较高且相差不应很大。所以我们可以使用激活函数Tanh来对置信度进行加权处理：

where $\rho$ is a small positive number to prevent the denominator from being zero.

As shown in Figure \ref{fig:before-agg}, the LOF algorithm can identify and remove potential malicious clients, but among the normal nodes, there are still some nodes with very low confidence. The minimum enclosing hypersphere of these nodes may even overlap with the abnormal nodes. Therefore, in the aggregation process, nodes with lower confidence should have lower weights.

Consider the following scenario: suppose two nodes have very small minimum enclosing hypersphere radii, but their radii differ by a significant factor. Consequently, their computed confidences would also differ significantly. However, their intention points are quite clear, so their weights should both be relatively high and not differ too much. Therefore, we can use the Tanh activation function to adjust the confidence weights:

\begin{equation}
    cre_i'=\tanh(cre_i),
\end{equation}

% 激活函数Tanh在$0$到$\infty$范围内是一个上升又快到慢的单调递增函数。当$cre_i\to 0$时$cer_i'\to 0$，也就是说节点$i$的最小覆盖球半径$r_i$很大时该节点在聚合时的权重很小；当$cre_i\to \infty$时$cer_i'\to 1$，也就是说节点$i$的最小覆盖球半径$r_i$很小时该节点在聚合时的权重较大。这样，我们就可以对每个加权处理过的置信度$cer_i'$进行归一化处理，得到权重$w_i$。其中：
The Tanh activation function is a monotonic increasing function that rises quickly at first and then slowly within the range of $0$ to $\infty$. When $cre_i \to 0$, $cer_i' \to 0$, which means that when the minimum enclosing hypersphere radius $r_i$ of node $i$ is large, its weight during aggregation is small. Conversely, when $cre_i \to \infty$, $cer_i' \to 1$, which indicates that when the radius $r_i$ is small, the weight of node $i$ in the aggregation is larger. This allows us to normalize each adjusted confidence $cer_i'$ to obtain the weight $w_i$. The formula is:

\begin{equation}
    w_i=\frac{cre_i'}{\sum_{i=1}^{N}cre_i'},
\end{equation}

% 因此第$t$轮模型的梯度聚合公式为：
Thus, the secure aggregation formula for the model in the $t$-th round is:

\begin{equation}
    \theta_g^t = \theta_g^{t-1}+\sum_{i=1}^{N}w_i\triangledown \theta_i^t,
\end{equation}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{results/prob-history-Visualization of Client Intentions and Anomalies.png}
%     \centering \caption{Results obtained using simulated data}
%     \label{fig:result-of-histry}
% \end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/fig4.jpg}
    \caption{Benign and Malicious Nodes Before Aggregation}
    \label{fig:before-agg}
\end{figure}
% 如图\ref{fig:before-agg}所示展示了异常检测和梯度聚合的计算流程示意图。图中每个球都是某个节点的意图范围。蓝色的球代表良性节点，红色的球代表异常节点。在进行异常检测时我们只考虑每个节点的意图点，即图中的球心位置。在计算可达距离时，由于意图点$O_{j_1}$距离意图点$O_i$较近，故二者之间的可达距离为意图点$O_i$的$q$距离$\widetilde{dis_i^q}$；由于意图点$O_{j_2}$距离$O_i$较远，所以二者之间的可达距离为二者之间的实际距离$\|O_i-O_{j_2}\|$。意图点$O_i$的密度高于其邻域意图点的密度，$lof_i<1$；而意图点$O_{j_2}$的密度低于其邻域意图点的密度，因此$lof_{j_2} > 1$。
As shown in Figure \ref{fig:before-agg}, the diagram illustrates the computational process of anomaly detection and gradient aggregation. Each sphere in the figure represents the intention range of a specific node. The blue spheres represent benign nodes, while the red spheres represent anomalous nodes. During anomaly detection, we only consider the intention point of each node, which is represented by the center of each sphere in the figure. When calculating the reachable distance, since intention point $O_{j_1}$ is close to intention point $O_i$, the reachable distance between them is the $q$-distance $\widetilde{dis_i^q}$ of intention point $O_i$. Since intention point $O_{j_2}$ is far from $O_i$, the reachable distance between them is the actual distance $\|O_i-O_{j_2}\|$ between them. The density of intention point $O_i$ is higher than that of its neighboring intention points, so $lof_i < 1$. On the other hand, the density of intention point $O_{j_2}$ is lower than that of its neighboring intention points, so $lof_{j_2} > 1$.

% 将异常节点剔除，在聚合良性节点的梯度时，依据正常节点的置信度进行加权处理。图中可以看出，虽然节点$j_1$被划分为了良性节点，但其置信度非常低，其超球甚至已经与异常节点$j_2$有所重合。因此在梯度聚合的时候，其权重较小。
After removing anomalous nodes, the gradients of benign nodes are aggregated with a weighting based on the confidence of the normal nodes. As shown in the figure, although node $j_1$ is classified as a benign node, its confidence is very low, and its hypersphere even overlaps with the anomalous node $j_2$. Therefore, its weight is small during gradient aggregation.

% 我们将算法总结成了伪代码，如算法\ref{alg:malicious-node-detection-history}所示。其中第3-7行是步骤1，表示了保留T轮次历史记录的方法；第8-15行是步骤2，表示了使用最小覆盖超球算法求每个机器人节点意图点和置信度的方法；第16-27行是步骤3，表明了如何通过LOF算法求出正常节点和异常节点；第28-32行是步骤4，展示了依据每个机器人节点置信度进行加权聚合的方法。

We summarize the algorithm in the form of pseudocode, as shown in Algorithm \ref{alg:malicious-node-detection-history}. Lines 3 to 7 correspond to Step 1, which outlines the method for retaining historical records for \(T\) rounds. Lines 8 to 15 correspond to Step 2, which describes the use of the minimum enclosing hypersphere algorithm to determine each robot node's intent point and confidence level. Lines 16 to 27 correspond to Step 3, which explains how to identify normal and abnormal nodes using the LOF algorithm. Finally, lines 28 to 32 correspond to Step 4, which illustrates the method for performing weighted aggregation based on each robot node's confidence level.


\begin{algorithm}
\caption{Attack intention detection and secure aggregation}
\label{alg:malicious-node-detection-history}
\begin{algorithmic}[1]
\State \textbf{Input:} Global model history $\{\theta_g^{t-T}, \dots, \theta_g^{t-1}\}$, historical gradient updates for each client $\{\triangledown \theta_{i}^{t-T}, \dots, \triangledown \theta_{i}^{t-1}\}$
\State \textbf{Output:} Sets of normal clients $U_{nor}$ and malicious clients $U_{mal}$


\For {Client $i$}
\State{\color{CadetBlue}/* \textbf{Construction of updates and model databases */}} 
    \State Record flattened gradients $\bar{\theta_i^t}$ and models $\theta_g^{t-1}$
    % \State $\widetilde{\theta_{i}^{t'-1}}  \gets Flatten(\theta_g^{t'-1})$, ${v}_{i}^{t'}  \gets \overline{\triangledown\theta_{i}^{t'}}$ for $t'  \gets \max\{t-T+1, 1\}, \ldots, t$ \Comment{Construct rays}
    \State Construct rays for each $'$, $\max\{t-T+1, 1\}\leq t' \leq t$


\State{\color{CadetBlue}/* \textbf{Construction of attack intention */}} 

    \State Initialize center $O_{i,0}$ and radius $r_{i,0}$
    \While {Not Converged}
        \State Update center $O_{i,k+1}$ and radius $r_{i,k+1}$
    \EndWhile
    \State  $cre_i  \gets \frac{1}{r_i + \rho}$ \Comment{Calculate confidence}


\State{\color{CadetBlue}/* \textbf{LOF-driven malicious intention detection*/}} 

    \For {Each point $O_j \neq O_i$}
        \State Calculate distance $\|O_i - O_j\|$
    \EndFor
    \State Determine $q$-distance $\widetilde{dis_i^q}$ for $O_i$
    \State Find neighbors $Nei_i$ within $\widetilde{dis_i^q}$
    \State $rea_{i,j}  \gets \max\{\widetilde{dis_i^q}, \|O_i - O_j\|\}$ for $O_j \in Nei_i$  \Comment{Compute reachability distance}
    \State  $lrd_i  \gets \frac{|Nei_i|}{\sum_{j \in Nei_i} rea_{i,j}}$ \Comment{Calculate reachability density}
    \State $lof_i  \gets \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$

% \For {Client $i$}
%     \State Compute $lof_i = \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$
%     \If {$lof_i > 1$}
%         \State Mark client $i$ as malicious, add to $U_{mal}$
%     \Else
%         \State Mark client $i$ as normal, add to $U_{nor}$
%     \EndIf
% \EndFor
% \State $U_{mal} = \{i \,|\, lof_i > 1\}$
% \State $U_{nor} = \{i \,|\, lof_i \leq 1\}$
\State $U_{mal}, U_{nor}  \gets \{i \,|\, lof_i > 1\}, \{i \,|\, lof_i \leq 1\}$

\State{\color{CadetBlue}/* \textbf{Secure aggregation of global FFT model*/}} 
        \State $cre_i'  \gets \tanh(cre_i)$\Comment{Compute adjusted confidence}
        \State $w_i  \gets \frac{cre_i'}{\sum_{i \in U_{nor}} cre_i'}$\Comment{Normalize weights}
\EndFor

\State \textbf{Output:} $\theta_g^t \gets \theta_g^{t-1} + \sum_{i \in U_{nor}} w_i \cdot \triangledown \theta_i^t$\Comment{Aggregate global model}
\end{algorithmic}
\end{algorithm}

% \begin{figure}[!t]
%     \centering
%     % \includegraphics[width=\linewidth]{figures/fig2.pdf}
%     \caption{Benign and Malicious Nodes Before Aggregation}
%     \label{fig2:single}
% \end{figure}

% \subsection{Multi}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/fig3.jpg}
%     \caption{Benign and Malicious Nodes Before Aggregation}
%     \label{fig3:multi}
% \end{figure}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/fig4.jpg}
%     \caption{Benign and Malicious Nodes Before Aggregation}
%     \label{fig4:before-agg}
% \end{figure}



\section{Experimental evaluation}
% This section presents a thorough evaluation of SecFFT on two benchmark datasets, aiming to illustrate its effectiveness. 本实验在一台Windows操作系统的服务器上进行，28核心128GB内存，以及2块NVIDIA GeForce RTX 3090 GPU(24G)。
This section thoroughly evaluates SecFFT on the benchmark dataset to illustrate its effectiveness, which begins by detailing the experimental setup and environment, followed by the analysis of the experimental results.

\subsection{Experimental Setup}
% 在本实验中，我们采用了常用的联邦学习场景进行评估。具体设置如下：
We used the widely adopted FedAvg framework for evaluation. The experiments were conducted on a server running the Windows operating system with 28 cores, 128GB of memory, and two NVIDIA GeForce RTX 3090 GPUs (24GB). The specific settings are as follows:



%\textbf{数据集}：我们使用FMNIST\cite{minist}作为实验数据集。FMNIST数据集包含60,000张28x28像素的灰度时尚商品图像，共分为10个类别，其中50,000张为训练集，10,000张为测试集。


\textbf{Dataset:} We used the FMNIST\cite{minist} dataset as the experimental dataset. The FMNIST dataset contains 60,000 grayscale images of fashion items with a resolution of 28x28 pixels, divided into 10 categories, with 50,000 images for training and 10,000 for testing.





 % \textbf{微调模型}：我们采用CLIP的CLIP-ViT-B/32\cite{huggingface_clip}模型作为微调所使用的预训练模型。CLIP是一种通过对比学习在文本和图像数据上进行预训练的模型，能将自然语言和视觉信息映射到同一特征空间中。CLIP-ViT-B/32基于ViT\cite{vit}架构，包含12层Transformer编码器，隐藏层维度为768，多头注意力头数为12，使用32x32的图像块作为输入。在微调过程中，我们使用LORA\cite{lora}方案仅在Vision Encoder模块插入低秩矩阵，保持Textual Encoder模块不变。我们设定低秩矩阵的秩为16，学习率为$10^{-4}$，以在有限计算资源下高效微调模型，使其更好地适应特定任务的数据分布。
\textbf{Models:} 
% We adopted the \textbf{CLIP-ViT-B/32}\cite{huggingface_clip} model from \cite{clip} as the pre-trained model for federated fine-tuning. CLIP is a vision language model pre-trained on both text and image data through contrastive learning, capable of mapping natural language and visual information into the same feature space. CLIP-ViT-B/32 is based on the ViT\cite{vit} architecture and contains 12 layers of Transformer encoders, with a hidden dimension of 768 and 12 attention heads, using 32x32 image patches as input. During fine-tuning, we used the \textbf{LORA}\cite{lora} method to insert low-rank matrices only in the Vision Encoder module, keeping the Textual Encoder module unchanged. We set the rank of the low-rank matrices to 16 and the learning rate to \textbf{$10^{-4}$} to efficiently fine-tune the model under limited computational resources, allowing it to better adapt to the data distribution of specific tasks.
We adopted the \textbf{CLIP-ViT-B/32}\cite{huggingface_clip} model from \cite{clip} as the pre-trained model for federated fine-tuning. CLIP is a vision-language model pre-trained on both text and image data through contrastive learning, capable of mapping natural language and visual information into a shared feature space. CLIP-ViT-B/32 is based on the ViT\cite{vit} architecture and consists of 12 layers of Transformer encoders, with a hidden dimension of 768 and 12 attention heads, processing 32x32 image patches as input. During fine-tuning, we employed the \textbf{LORA}\cite{lora} method to introduce low-rank matrices only into the Vision Encoder module, while keeping the Textual Encoder module unchanged. We set the rank of the low-rank matrices to 16 and the learning rate to \textbf{$10^{-4}$} to efficiently fine-tune the model under limited computational resources, enabling it to better adapt to the data distribution of specific tasks.

% \textbf{攻击方式}：对于单轮恶意用户检测，我们使用包括MR\cite{MR}、EDGE CASE\cite{EDGE_CASE}、以及NEUR\cite{zhang2022neurotoxin}在内的三种针对联邦学习场景的最新攻击。MR攻击通过将中毒图像与正常图像混合来创建恶意数据集，并使用投影梯度下降法进行本地训练来达到植入后门的效果；EDGE CASE攻击利用罕见的“边缘情况”样本，通过数据或模型投毒在联邦学习模型中插入后门；Neurotoxin攻击则尝试通过识别在正常节点训练中不常更新的参数，并利用这些参数插入后门，以提高后门的持久性。For Instantaneous Attack Behavior Perception,?
\textbf{Attack paradigms:} we employed three state-of-the-art attacks targeting federated learning scenarios, namely \textbf{MR}\cite{MR}, \textbf{EDGE CASE}\cite{EDGE_CASE}, and \textbf{NEUR}\cite{zhang2022neurotoxin}. The MR attack generates a malicious dataset by combining poisoned images with normal ones and employing the projected gradient descent method for local training to implant backdoors; the EDGE CASE attack employs rare "edge-case" samples to inject backdoors into the federated learning model through data or model poisoning; the NEUR attack seeks to identify parameters that are seldom updated during normal node training and uses these parameters to insert backdoors, thereby enhancing the persistence of the backdoor.

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/lab1-combined.pdf}
    \caption{ASR and TSR of various defense mechanisms (FedAVG, FLTrust, Foolsgold, Flame, SecFFT) under three attacks (MR, NEUR, Edge case).}
    \label{fig:lab1}
\end{figure*}

% \textbf{对比算法}：对于单轮恶意用户检测算法，我们对比了三种聚合算法：FedAVG\cite{FedAVG}、FLTrust\cite{FLTrust}和Flame\cite{FLAME}。其中FedAVG根据每个节点数据集的大小对其上传的更新进行加权聚合；FLTrust利用一个干净的数据集，仅聚合那些上传更新与该干净数据集上训练所得更新余弦相似度较高的节点；而Flame则通过模型聚类和权重剪裁来估计并注入适量噪声，有效消除联邦学习中的后门攻击。
\textbf{Baseline defense mechanisms:} 
% For Instantaneous Attack Behavior Perception, we compared four aggregation algorithms: \textbf{FedAVG}\cite{FedAVG}, \textbf{Foolsgold}\cite{foolsgold}, \textbf{FLTrust}\cite{FLTrust}, and \textbf{Flame}\cite{FLAME}. FedAVG performs weighted aggregation of the updates uploaded by each node based on the size of their dataset; FoolsGold distinguishes between benign and malicious clients by assessing pairwise similarity among model updates, subsequently down-weighting abnormal updates on the FL server; FLTrust uses a clean dataset and only aggregates updates from nodes whose updates have a high cosine similarity with the updates obtained from the clean dataset; Flame estimates and injects an appropriate amount of noise through model clustering and weight clipping to effectively eliminate backdoor attacks in federated learning.
we compared four aggregation mechanisms: \textbf{FedAVG}\cite{FedAVG}, \textbf{Foolsgold}\cite{foolsgold}, \textbf{FLTrust}\cite{FLTrust}, and \textbf{Flame}\cite{FLAME}. FedAVG conducts weighted aggregation of updates uploaded by each node based on the size of its dataset. FoolsGold differentiates between benign and malicious clients by evaluating pairwise similarity among model updates and subsequently down-weighting anomalous updates on the FL server. FLTrust employs a clean dataset and aggregates only those updates from nodes that exhibit high cosine similarity with the updates derived from the clean dataset. Flame estimates and injects an appropriate amount of noise via model clustering and weight clipping to mitigate backdoor attacks in federated learning effectively.
    
\textbf{Evaluation metrics:}
% 就像其他文章中的评价指标一样，我们使用两个关键指标来评估投毒攻击与防御方法的效果，即ASR（攻击成功率）和 TSR（测试成功率）。ASR表示恶意节点成功诱导全局模型成功预测指定目标的概率。攻击者的目标是最大化ASR，而有效的防御措施则旨在防止ASR上升。TSR表示全局模型在测试集上的预测正确率。攻击者的目标是尽量维持模型的TSR不变，以避免被轻易检测到，而有效的防御措施则不应显著降低全局模型的TSR。
% Similar to evaluation metrics used in other works\cite{tang2023port, jin2024learning, rong2023special}, we use two key metrics to assess the effectiveness of poisoning attacks and defense methods: \textbf{ASR} (Attack Success Rate) and \textbf{TSR} (Test Success Rate). ASR represents the probability that malicious nodes successfully induce the global model to predict the specified target. The goal of the attacker is to maximize ASR, while effective defense measures aim to prevent an increase in ASR. TSR represents the accuracy of the global model on the test set. The attacker's goal is to maintain the TSR of the model as unchanged as possible to avoid easy detection, while effective defense measures should not significantly reduce the TSR.
Similar to the evaluation metrics employed in other studies\cite{tang2023port, jin2024learning, rong2023special}, we utilize two key metrics to assess the effectiveness of poisoning attacks and defense mechanisms: \textbf{ASR} (Attack Success Rate) and \textbf{TSR} (Test Success Rate). ASR denotes the probability that malicious nodes successfully manipulate the global model to predict a specified target. The attacker aims to maximize the ASR, whereas effective defense mechanisms strive to prevent an increase in ASR. TSR indicates the accuracy of the global model on the test set. The attacker aims to keep the TSR of the model as stable as possible to avoid easy detection, whereas effective defense mechanisms should not significantly degrade the TSR.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/lab2-combined.pdf}
    \caption{Visualization of node identification results under three different attack scenarios (MR, Edge Case, NEUR) for various defense mechanisms (SecFFT, Flame, FLTrust, FoolsGold) using t-SNE dimensionality reduction. The red dots represent misidentified nodes, including both malicious nodes incorrectly identified as benign and benign nodes incorrectly identified as malicious. }
    \label{fig:lab2}
\end{figure*}

\subsection{Model integrity and poisoning resistance}
% 为了验证我们所提方法“Instantaneous Attack Behavior Perception”的有效性，我们分别在MR、EDGE CASE、NEUR三种攻击下进行实验，并与FedAVG(Baseline)、Foolsgold、FLTrust、Flame进行对比，比较不同防御算法下相应的TSR以及ASR。图\ref{fig:lab1}分别展示了攻击相应的实验结果。
To validate the effectiveness of our proposed method, we conducted experiments under three types of attacks: MR, Edge case, and NEUR. We compared our method with FedAVG (Baseline), FoolsGold, FLTrust, and Flame to evaluate the corresponding TSR and ASR under different defense mechanisms. The experimental results are shown in Figure \ref{fig:lab1}.




% 从图中可以看出，SecFFT在面对三种攻击场景（MR、NEUROTOXIN、EDGE_CASE）时展现了最强的鲁棒性和出色的模型性能。在所有场景下，SecFFT的攻击成功率（ASR）始终接近于零，测试准确率（TSR）依然维持在高位，这意味着该算法能够有效防御攻击，能够成功识别并防御恶意用户，同时保持全局模型的性能和准确性。相比之下，其他防御算法表现则较为逊色。虽然Flame在降低ASR方面同样表现优异，能有效识别出恶意用户，但其在识别过程中引入了较多噪声，导致全局模型的准确率（TSR）下降，特别是在MR攻击下，性能损失更为显著。FLTrust在应对MR攻击时几乎完全失效，ASR迅速上升，未能有效防御；尽管在NEUROTOXIN和EDGE_CASE场景下表现有所改善，但防御效果依然不够稳定。Foolsgold在MR和NEUROTOXIN攻击下的防御效果较差，ASR依旧很高，仅在EDGE case下表现出一些效果，但并不显著。总体而言，这些算法在抵御攻击时未能同时兼顾模型的性能，进一步突显了SecFFT在联邦学习攻击防御中的显著优势，成为最优的防御选择。
% As shown in the figure, SecFFT demonstrates the strongest robustness and excellent model performance when faced with three types of attack scenarios (MR, NEUR, EDGE CASE). In all scenarios, SecFFT's ASR remains close to zero, while the TSR stays high, indicating that the algorithm can effectively defend against attacks by successfully identifying and mitigating malicious users while maintaining the performance and accuracy of the global model. In contrast, other defense mechanisms perform less favorably. Although Flame also performs well in reducing ASR and effectively identifying malicious users, it introduces a significant amount of noise during the identification process, which leads to a decrease in the global model's accuracy (TSR), particularly under the MR attack, where the performance loss is more pronounced. FLTrust nearly fails to defend against MR attacks, with ASR rising rapidly, rendering it ineffective. While its performance improves under NEUR and EDGE CASE scenarios, the defense effectiveness remains unstable. FoolsGold exhibits poor defense performance under MR and NEUR attacks, with ASR still high, showing some effectiveness only in the EDGE CASE scenario, but not significantly. Overall, these mechanisms fail to balance model performance while defending against attacks, further highlighting SecFFT's significant advantage, making it the optimal choice for defense.
As depicted in the figure, SecFFT exhibits the highest robustness and superior model performance when confronted with three types of attack scenarios (MR, NEUR, EDGE CASE). Across all scenarios, SecFFT's ASR remains near zero, whereas the TSR remains high, indicating that the algorithm effectively defends against attacks by accurately identifying and mitigating malicious nodes while preserving the performance and accuracy of the global model. Conversely, other defense algorithms perform less effectively. Although Flame is also effective in reducing ASR and identifying malicious nodes, it introduces substantial noise during the identification process, leading to a decline in the global model's accuracy (TSR), especially under the MR attack, where the performance degradation is more pronounced. FLTrust almost fails to defend against MR attacks, with ASR rising rapidly, rendering it ineffective. While its performance improves under NEUR and EDGE CASE scenarios, its defense effectiveness remains inconsistent. FoolsGold demonstrates weak defense performance under MR and NEUR attacks, with ASR remaining high, showing limited effectiveness only in the EDGE CASE scenario. Overall, these algorithms fail to balance model performance and defense against attacks, further underscoring SecFFT's substantial advantage, establishing it as the optimal choice for defense.



\subsection{Performance of Attack Behavior Perception}
% 为了验证我们所提方法在恶意用节点识别方面具有较高的准确度，我们总结了在三种攻击(MR, Edge case, NEUR)下所有轮次中SecFFT对恶意节点的识别情况，并与FoolsGold, FLTrust, and Flame三种防御算法进行了对比。具体对比结果如图\ref{fig:lab2}所示，我们利用t-sne算法将所有轮次中节点的更新降维到了二维平面，图中红色点表示被错误识别的节点，包括恶意节点被识别成良性节点以及良性节点被错误识别成恶意节点。对于无法直接获得节点识别情况的Foolsgold防御算法，我们通过利用KMeans聚合算法将该防御算法过程中分配给每个用户的聚合权重聚成两类，并取最大类作为良性节点其余作为恶意节点的结果作为统计标准。
% To validate the high accuracy of our proposed method in identifying malicious nodes, we summarized the detection results of SecFFT under three types of attacks (MR, Edge Case, NEUR) across all rounds and compared them with three defense mechanisms: FoolsGold, FLTrust, and Flame. The specific comparison results are shown in Figure \ref{fig:lab2}. We used the t-SNE algorithm to reduce the dimensionality of the nodes' updates from all rounds to a two-dimensional plane. In the figure, red dots represent misidentified nodes, which include malicious nodes incorrectly identified as benign and benign nodes incorrectly identified as malicious. For the Foolsgold defense algorithm, which does not directly provide node identification results, we used the KMeans clustering algorithm to classify the aggregation weights assigned to each user during the defense process into two clusters, considering the larger cluster as benign nodes and the remaining as malicious nodes for evaluation purposes.
To validate the high accuracy of our proposed method in identifying malicious nodes, we summarized the detection results of SecFFT under three types of attacks (MR, EDGE CASE, NEUR) across all rounds and compared them with three defense mechanisms: FoolsGold, FLTrust, and Flame. The specific comparison results are illustrated in Figure \ref{fig:lab2}. We employed the t-SNE algorithm to reduce the dimensionality of the nodes' updates across all rounds to a two-dimensional plane. In the figure, red dots represent misidentified nodes, which include malicious nodes mistakenly identified as benign and benign nodes mistakenly identified as malicious. For the FoolsGold defense algorithm, which does not directly provide node identification results, we employed the KMeans clustering algorithm to classify the aggregation weights assigned to each user during the defense process into two clusters, considering the larger cluster as benign nodes and the remaining as malicious nodes for evaluation purposes.


% 如图所示，SecFFT 的错误识别率最低，仅为 3%，表明其在各种攻击模式下具有更强的防御能力和鲁棒性，能够准确区分恶意节点和良性节点。而 Flame、FLTrust 和 FoolsGold 的错误识别率分别为 12%、19.5% 和 37.5%，错误识别的节点分布较为广泛，尤其是 FoolsGold 的错误识别率最高，显示出其在应对复杂攻击场景时的防御效果较差。相比之下，SecFFT 在应对多种攻击类型时表现最为优异，能有效降低错误识别率，展示了更好的泛化能力和准确性。
% As shown in the figure, SecFFT has the lowest misidentification rate, at only 3\%, indicating its stronger defense capability and robustness in various attack scenarios, accurately distinguishing between malicious and benign nodes. In contrast, the misidentification rates of Flame, FLTrust, and FoolsGold are 12\%, 19.5\%, and 37.5\%, respectively, with misidentified nodes more widely distributed. Notably, FoolsGold has the highest misidentification rate, demonstrating poor defense performance in handling complex attack scenarios. Comparatively, SecFFT performs the best in dealing with various attack types, effectively reducing the misidentification rate and showing better generalization ability and accuracy.
As illustrated in the figure, SecFFT achieves the lowest misidentification rate, at only 3\%, indicating its superior defense capability and robustness across various attack scenarios, accurately distinguishing between malicious and benign nodes. Conversely, the misidentification rates of Flame, FLTrust, and FoolsGold are 12\%, 19.5\%, and 37.5\%, respectively, with misidentified nodes more broadly distributed. Notably, FoolsGold exhibits the highest misidentification rate, demonstrating suboptimal defense performance in managing complex attack scenarios. Comparatively, SecFFT outperforms other methods in handling various attack types, effectively reducing the misidentification rate and demonstrating superior generalization ability and accuracy.

\vspace{-0.28cm}
\subsection{Performance of Attack intention detection}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/lab3-combined.pdf}
    \caption{Detection performance of different defense technologies against intelligent attackers with sophisticated multi-round strategies}
    \label{fig:lab3}
\end{figure*}

%为了验证SecFFT面对具有复杂攻击策略的高级隐蔽后门攻击时候的攻击意图构建和有效防御能力，我们在NEUR攻击的基础之上，分别加上了Size约束跟Angle约束等多轮次策略。如图\ref{fig:lab3}所示，通过对比Foolsgold、Fltrust、Flame等仅基于行为的典型防御机制可以看出，基于意图的SecFFT能够显著提升攻击识别能力。即便部分防御手段如Flame能够对一些高隐蔽攻击行为进行有效识别，在叠加了复杂的多轮次攻击策略后，防御机制的识别能力迅速被绕过。而与之相反，我们的方法即便在面对最复杂的“size+angle”策略时，虽然绝对值变小，但是差距依然显著，因而依旧能够区分出攻击者与正常节点之间意图的不同。
%表\ref{tab:detect} 则详细列出了四种防御手段面对不同策略时的分类量化指标情况，可见，SecFFT不仅能够保持较好的抵御后门攻击的能力，同时也维持了相对最好的判别精度，误判率得到很好限缩，可靠性有保障。
To validate the capability of SecFFT in constructing attack intent and effectively defending against advanced covert backdoor attacks employing complex strategies, we added Size and Angle constraints to the NEUR attack over multiple rounds. As shown in Fig. \ref{fig:lab3}, by comparing with typical behavior-based defense mechanisms such as Foolsgold, FLTrust, and Flame, it is evident that the intent-based SecFFT significantly enhances attack detection capabilities. Even though certain defense methods like Flame can effectively identify some highly covert attack behaviors, their detection performance is quickly bypassed when more complex multi-round attack strategies are introduced. In contrast, our method, even when facing the most sophisticated "size+angle" strategy, maintains a notable difference, enabling the continued distinction between the attacker's intent and that of benign nodes, despite a decrease in absolute values.

Table \ref{tab:detect} provides a detailed quantitative analysis of the classification metrics for the four defense mechanisms against different strategies. It is clear that SecFFT not only consistently preserves its strong backdoor attack mitigation capability but also achieves the best detection accuracy, with significantly reduced false positive rates, ensuring reliable and robust performance.\textcolor{red}{ "Acc" refers to accuracy, which measures the proportion of correct predictions; "Rec" stands for recall, representing the model's ability to correctly identify positive instances; "FPR" denotes the false positive rate, indicating the proportion of negative instances incorrectly predicted as positive; "FNR" refers to the false negative rate, which represents the proportion of positive instances incorrectly predicted as negative; "AUC" stands for the area under the curve, reflecting the model's overall ability to distinguish between positive and negative instances; and "MCC" represents the Matthews correlation coefficient, which provides a balanced evaluation of the model's predictions.}


\begin{table}[h!]
\small
\centering
\caption{Metrics results with different attack and defense methods.}
\begin{tabular}{c|c|c|c|c|c|c|c}
\hline
Strategy & Defense & Acc. & Rec. & FPR & FNR & AUC & MCC \\ \hline

\multirow{4}{*}{None} & Foolsgold & 0.90 & 0.67 & 0.00 & 0.33 & 0.83 & 0.76 \\
                      & FLTrust   & 0.82 & 0.40 & 0.00 & 0.60 & 0.70 & 0.56 \\
                      & Flame     & 0.90 & 0.67 & 0.00 & 0.33 & 0.83 & 0.76 \\
                      & SecFFT    & \textbf{1.00} & \textbf{1.00} & 0.00 & \textbf{0.00} & \textbf{1.00} & \textbf{1.00} \\ \hline

\multirow{4}{*}{Size} & Foolsgold & 0.92 & 0.80 & 0.03 & 0.20 & 0.88 & 0.72 \\ 
                      & FLTrust   & 0.82 & 0.53 & 0.06 & 0.47 & 0.74 & 0.61 \\ 
                      & Flame     & 0.92 & 0.73 & \textbf{0.00} & 0.27 & 0.87 & 0.78 \\ 
                      & SecFFT    & \textbf{0.98} & \textbf{0.93} & \textbf{0.00} & \textbf{0.07} & \textbf{0.96} & \textbf{0.91} \\ \hline

\multirow{4}{*}{Angle} & Foolsgold & 0.88 & 0.73 & 0.06 & 0.27 & 0.84 & 0.68 \\ 
                       & FLTrust   & 0.86 & 0.60 & 0.03 & 0.40 & 0.80 & 0.65 \\ 
                       & Flame     & 0.90 & 0.67 & \textbf{0.00} & 0.33 & 0.83 & 0.76 \\ 
                       & SecFFT    & \textbf{0.96} & \textbf{0.87} & \textbf{0.00} & \textbf{0.13} & \textbf{0.94} & \textbf{0.88} \\ \hline
\end{tabular}
\vspace{1em}
\begin{tablenotes}
\scriptsize
\item ``Acc." stands for Accuracy, ``Rec." for Recall, ``FPR" for False Positive Rate, ``FNR" for False Negative Rate, ``AUC" for Area Under Curve, and ``MCC" for Matthews Correlation Coefficient. The strategies are abbreviated as ``None" (No strategy), ``Size" (Size-limited strategy), and ``Angle" (Angle-limited strategy).
\end{tablenotes}

\label{tab:detect}
\end{table}




% \begin{table}[h!]
% \small
% \centering
% \begin{tabular}{c|c|c|c|c|c|c|c|c|c}
% \hline
% \makecell{Attack \\ strategy} & Defense & Accuracy & Precision & Recall & \makecell{Specificity} & FPR & FNR & AUC & MCC \\ \hline

% \multirow{4}{*}{\makecell{No \\ strategy}} & Foolsgold & 0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\
%                       & FLTrust   &  0.82 & 1.00 & 0.40 & 1.00 & 0.00 & 0.60 & 0.70 & 0.56 \\
%                       & Flame     &  0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\
%                       & SecFFT    &  \textbf{1.00} & 1.00 & \textbf{1.00} & 1.00 & 0.00 & \textbf{0.00} & \textbf{1.00} & \textbf{1.00} \\ \hline

% \multirow{4}{*}{\makecell{Size-limited \\ strategy}} & Foolsgold &  0.92 & 0.92 & 0.80 & 0.97 & 0.03 & 0.20 & 0.88 & 0.72 \\ 
%                       & FLTrust   & 0.82 & 0.80 & 0.53 & 0.94 & 0.06 & 0.47 & 0.74 & 0.61 \\ 
%                       & Flame     & 0.92 &1.00 & 0.73 & 1.00 & 0.00 & 0.27 & 0.87 & 0.78 \\ 
%                       & SecFFT    & \textbf{0.98} & 1.00 & \textbf{0.93} & 1.00 & 0.00 & \textbf{0.07} & \textbf{0.96} & \textbf{0.91} \\ \hline

% \multirow{4}{*}{\makecell{Angle-limited \\ strategy}} & Foolsgold &  0.88 & 0.85 & 0.73 & 0.94 & 0.06 & 0.27 & 0.84 & 0.68 \\ 
%                        & FLTrust   &  0.86 & 0.90 & 0.60 & 0.97 & 0.03 & 0.40 & 0.80 & 0.65 \\ 
%                        & Flame     &  0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\ 
%                        & SecFFT    &  \textbf{0.96} & 1.00 & \textbf{0.87} & 1.00 & 0.00 & \textbf{0.13} & \textbf{0.94} & \textbf{0.88} \\ \hline
% \end{tabular}
% \vspace{1em}
% \caption{Classification metrics results with different attack and defense methods}\label{tab:detect}
% \end{table}




% \begin{table*}[h!]
% \small
% \centering
% \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c}
% \hline
% \makecell{Attack \\ strategy} & Defense & TP & FP & TN & FN & Accuracy & Precision & Recall & \makecell{Specificity} & FPR & FNR & AUC & MCC \\ \hline

% \multirow{4}{*}{\makecell{No \\ strategy}} & Foolsgold & 10 & 0 & 35 & 5 & 0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\
%                       & FLTrust   & 6  & 0 & 35 & 9 & 0.82 & 1.00 & 0.40 & 1.00 & 0.00 & 0.60 & 0.70 & 0.56 \\
%                       & Flame     & 10 & 0 & 35 & 5  & 0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\
%                       & SecFFT    & \textbf{15} & 0 & 35 & \textbf{0}  & \textbf{1.00} & 1.00 & \textbf{1.00} & 1.00 & 0.00 & \textbf{0.00} & \textbf{1.00} & \textbf{1.00} \\ \hline

% \multirow{4}{*}{\makecell{Size-limited \\ strategy}} & Foolsgold & 12 & 1 & 34 & 3 & 0.92 & 0.92 & 0.80 & 0.97 & 0.03 & 0.20 & 0.88 & 0.72 \\ 
%                       & FLTrust   & 8  & 2 & 33 & 7 & 0.82 & 0.80 & 0.53 & 0.94 & 0.06 & 0.47 & 0.74 & 0.61 \\ 
%                       & Flame     & 11 & 0 & 35 & 4  & 0.92 &1.00 & 0.73 & 1.00 & 0.00 & 0.27 & 0.87 & 0.78 \\ 
%                       & SecFFT    & \textbf{14} & 0 & 35 & \textbf{1}  & \textbf{0.98} & 1.00 & \textbf{0.93} & 1.00 & 0.00 & \textbf{0.07} & \textbf{0.96} & \textbf{0.91} \\ \hline

% \multirow{4}{*}{\makecell{Angle-limited \\ strategy}} & Foolsgold & 11 & 2 & 33 & 4 & 0.88 & 0.85 & 0.73 & 0.94 & 0.06 & 0.27 & 0.84 & 0.68 \\ 
%                        & FLTrust   & 9  & 1 & 34 & 6 & 0.86 & 0.90 & 0.60 & 0.97 & 0.03 & 0.40 & 0.80 & 0.65 \\ 
%                        & Flame     & 10 & 0 & 35 & 5  & 0.90 & 1.00 & 0.67 & 1.00 & 0.00 & 0.33 & 0.83 & 0.76 \\ 
%                        & SecFFT    & \textbf{13} & 0 & 35 & \textbf{2}  & \textbf{0.96} & 1.00 & \textbf{0.87} & 1.00 & 0.00 & \textbf{0.13} & \textbf{0.94} & \textbf{0.88} \\ \hline
% \end{tabular}
% \vspace{1em}
% \caption{Classification metrics results with different attack and defense methods}\label{tab:detect}
% \end{table*}

% As a preeminent collaborative artificial intelligence paradigm, Federated Learning (FL) has garnered substantial research focus \cite{ETT2}. 
% By effectively mobilizing a substantial number of participants with a discrete distribution, FL can concurrently enhance learning performance, resource utilization, and data security. 
% Besides, as intelligent applications proliferate, concerns regarding fairness-aware federated learning (FFL) have also captured significant attention \cite{zhou2021towards-KDDtutorial-FFL}. Due to the agnostic of multiple data sources, models trained through FL may exhibit discriminatory tendencies toward specific features or demographic groups, such as gender, race, and occupation (e.g., COMPAS recidivism algorithm \cite{angwin2022machine} and facial recognition system \cite{raji2019actionable}). In response to this inherent deficiency, various FFL algorithms, such as FairFed \cite{ezzeldin2023fairfed}, Ditto \cite{li2021ditto}, and FairFL \cite{zhang2020fairfl}, have been proposed.

% %安全问题很重要
% \subsection{Mutual reliability problem of FFL}
% Meanwhile, along with the continual emergence of novel attack techniques, such as gradient leakage and model poisoning \cite{fang2020local}, the \textit{``trust crisis''} \cite{zhou2022multi} has become a critical bottleneck in determining FFL deployment capabilities \cite{rodriguez2023survey}. Establishing a robust \textit{mutual reliability} relationship between the FL aggregator (parameter server) and local participants has proven challenging \cite{zhou2022multi}. To be specific, on the one hand, concerns about data sharing leading to privacy breaches (\textit{aggregator's reliability}) \cite{wang2021variational} raise apprehensions among owners of data and computational resources, significantly diminishing enthusiasm for collaborative learning participation and giving rise to the phenomena of ``isolated data islands''. On the other hand, PSs are troubled by the difficulty of promptly and accurately thwarting stealthy attackers hidden among a vast client base. This concern  (\textit{client nodes' reliability}) raises the specter of manipulation or even invalidation of the entire model, resulting in severe economic and intellectual property losses. 

% %列举几个特点，导致现有安全技术不能适用
% %尽管多种最新的安全增强技术能够取得显著的防御效果，但攻击者并不能
% \subsection{Characteristics and motivation of mutual reliable FFL in heterogeneous UAV networks}
% With the advancement of integrated sensing, computation and communication (ISCC) \cite{he2023integrated}, and the space-air-ground integrated network (SAGIN) \cite{shen2023survey}, unmanned aerial vehicle (UAV) networks have played a crucial role in various domains such as post-disaster reconstruction, emergency temporary communication, and medical monitoring \cite{lu2023uav}. FLs based on UAV networks have also found widespread applications \cite{ETT1, ETT3, pandya2023federated}. However, despite the proposal of various secure FL technologies, the inherent characteristics of UAV networks continue to pose significant challenges in establishing mutual reliability for FFL in UAV environments. Specifically, these challenges encompass the following aspects:

% %异构：大范围异构，小范围相似.因此
% \textbf{1) Heterogeneity among UAV nodes:} As illustrated in Figure \ref{fig1:UAV-Network}, constrained by the mobility and patrol paths of UAVs, individual nodes are often limited to conducting data collection within a specific regional scope. Hence, even when employing identical equipment, the data distributions among UAV nodes across the entire network exhibit significant heterogeneity, while UAVs within the same area are similar. Therefore, various existing reliable FL technologies lacking adaptive considerations (such as Krum \cite{blanchard2017machine-krum}, Baffle \cite{andreina2021baffle}, and AGRamplifier \cite{gong2023agramplifier}) can lead to substantial accuracy losses.

% %资源受限：因此高消耗的安全策略并不能适用  高计算消耗和带宽占用的安全技术（例如，加密）
% \textbf{2) Resource limitation of UAV devices:} As UAV nodes function as mobile devices and bear substantial flight-related loads, their communication and energy resources are relatively constrained. The efficiency of FFL training is equally important. Consequently, solutions integrating cryptography, auxiliary training, multi-round detection, or other security mechanisms with high computational costs and bandwidth utilization (e.g., ShieldFL \cite{ma2022shieldfl}, AFA \cite{munoz2019byzantine-AFA}, and FLdetector \cite{zhang2022fldetector}) are not applicable for real-world deployment.



% %我们的目标是实现（1）异构容忍的FFL框架（2）强隐私保护的个性化训练交互（3）抗污染的可信评估
% The aforementioned characteristics distinguish the reliable FFL in heterogeneous UAV networks from existing secure FFL technologies, thereby motivating the establishment of the following new criteria for its enhancement:

% \textbf{1) Heterogeneity-tolerant FFL framework:} Suitable nodes from the highly heterogeneous UAV networks can be organized promptly to efficiently fulfill arbitrary fairness-aware FL tasks, which also mitigates redundant computational energy consumption and accuracy loss induced by heterogeneity.

% \textbf{2) Privacy-preserving personalized training:} Throughout the iteration training and interaction process, sample-level privacy protection must be implemented to prevent the leakage of sensitive information. Additionally, considering the resource constraints of UAV nodes, computational and bandwidth demands should be limited.

% \textbf{3) Poisoning-resilient credit evaluation:} In addition to robust defense capabilities against various poisoning attacks, compatibility with heterogeneity and privacy requisites is also essential. In other words, without compromising the effectiveness of privacy guarantee, heterogeneous benign UAV nodes should be treated equally during the whole FFL workflow.%Achieving fairness among heterogeneous benign users without compromising the effectiveness of privacy protection is a crucial aspect.

% \subsection{Our solution and contributions}
% %解决方案
% % Hence, in this paper, we propose mutually reliable FFL (MR-FFL), a stratified community-based framework to facilitate privacy protection (FFL aggregator's reliability) and poisoning elimination (client nodes' reliability) jointly for FFL in heterogeneous UAV networks. 
% % We first divide UAV nodes into both peer communities and colleague communities according to cross-participant similarity and task-oriented fitness, respectively. 
% % Thus, the arbitrarily settled learning tasks following fair principles can be efficiently completed by fine-tuned colleague communities, even in the presence of a large degree of heterogeneity among peer communities. 
% Therefore, this paper proposes mutual reliable FFL (MR-FFL), a stratified community-based framework that collectively promotes privacy protection during data sharing (reliability of FFL aggregators) and poisoning elimination during model aggregation (reliability of client nodes) in heterogeneous UAV networks. The contributions of the proposed MR-FFL are three-fold:


% %贡献

% \begin{itemize}
%     %\item In light of shuffling-based MTD \cite{zhou2022multi} strategies, we propose a credit to identify the malicious attackers without compromising of privacy guarantees, which is also one of the design inspirations of our framework. 
%     \item Initially, UAV nodes are partitioned into peer communities and colleague communities based on cross-participant similarity and task-oriented adaptability. Thus, adhering to fairness principles, any arbitrarily determined learning task can be effectively accomplished through carefully selected colleague communities, even in the presence of significant heterogeneity among UAV nodes, while peer communities provide an amplified privacy guarantee. 
%     %随后，我们提出了PSDP的隐私模糊化方式进行自适应训练，通过参数动态约束差分隐私敏感度，从而在同等隐私保护水平下大幅降低异构环境下的噪声损失。
%     \item Subsequently, inspired by cross-silo privacy protection, we introduce the new privacy perturbation notion of peer community-specific differential privacy (PSDP) with changeable privacy budget. Through dynamically constraining the DP sensitivity within each peer community, PSDP significantly reduces noise loss in heterogeneous environments under equivalent privacy protection levels.
%     %此外，我们提出了基于三值主观逻辑模型的信用评估，分别抽离投毒攻击的“操纵”（相似度）和“破坏”（准确度）行为进行群体参与的综合长效评价，从而有效抵御多种隐蔽的投毒攻击范式。
%     \item Furthermore, we propose a new credit evaluation based on the ternary subjective logic model. This evaluation effectively integrates comprehensive and long-term assessments with the collective participation of heterogeneous UAV nodes, specifically extracting the ``manipulation'' (similarity) and ``disruption'' (accuracy) behaviors of poisoning attacks. This approach proves effective in defending against various covert poisoning attack paradigms. 
%     %\item Then, we integrate community-specific differential privacy into the MR-FFL process, to achieve privacy amplification as well as efficient and personal collaborative training at the same time. 
%     %\item More importantly, we proposed a community-based credit evaluation to resist poisoning attacks in heterogeneous environments. 
    
% \end{itemize}

% %本文组织结构
% The remainder of this paper is organized as follows: The related works are reviewed in Section \uppercase\expandafter{\romannumeral2}. The system model is presented in Section \uppercase\expandafter{\romannumeral3}. Then, stratified community construction, adaptive training, and credit evaluation modules are expounded upon in Section \uppercase\expandafter{\romannumeral4} to \uppercase\expandafter{\romannumeral6}, respectively, providing a detailed account of availability, privacy, and integrity for FFL in heterogeneous UAV networks. Section \uppercase\expandafter{\romannumeral7} presents experimental results. Finally, Section \uppercase\expandafter{\romannumeral8} concludes this paper. %and briefly explores future directions.



% \section{Related work}


% % \begin{tabular}{|p{0.4\textwidth}|p{0.5\textwidth}|}
% % \hline
% % \textbf{论文的期刊名、年份、引用} & \textbf{简介} \\
% % \hline
% % 期刊名1, 2024, 引用1 & 这篇论文讨论了...... \\
% % \hline
% % 期刊名2, 2023, 引用2 & 本研究着重于...... \\
% % \hline
% % 期刊名3, 2022, 引用3 & 本文提出了...... \\
% % \hline
% % \end{tabular}



% According to the three basic tenets of information security \cite{zhou2021augmented-globecom}, in this section, we systematically review the most crucial hindrances of existing FFL solutions in UAV networks: \textit{availability}, \textit{confidentiality}, and \textit{in tegrity} problems, which we settled in following sections, respectively. 
% \subsection{FFL in heterogeneous environments (availability)}
% To accomplish learning tasks and ensure the availability of FFL in heterogeneous environments, existing solutions can adopt debiasing on the client or server side.
% \subsubsection{Server-side debiasing} %全局化
% As the name indicated, server-side debiasing methods usually monitor the composition of training data and design new loss functions like Ratio loss \cite{wang2021addressing} to mitigate the impact of heterogeneity. 
% Besides, FairFed \cite{ezzeldin2023fairfed} adjusts the aggregation weights of heterogeneous participants based on equal opportunity difference (EOD). Hence, clients can conduct different debiasing processes. 
% Likewise, FedProto \cite{tan2022fedproto} regularizes the training of local models with the aid of abstract class prototypes from the server. 
% To handle the performance degradation caused by heterogeneous and long-tailed data, CReFF\cite{shang2022federated} re-trains the biased classifier with federated features in a privacy-preserving manner. 
% Different from the above methods, several clustered FLs provide separate models for heterogeneous clients \cite{sattler2020clustered-CFL}, which can incur exponentially growing computation costs.
% \subsubsection{Client-side debiasing} %个性化
% Diverging from server-side debiasing, client-side debiasing methods primarily enhance accuracy by altering the local model \cite{tan2022towards}. 
% For example, while retaining the standard FL mechanism as the inner optimizer, FairBatch \cite{roh2020fairbatch} further adds an outer optimizer to select minibatch sizes and improve model fairness adaptively. Similarly, Ditto \cite{li2021ditto} develops a regular term to optimize the local models without changing global aggregation rules. The robustness and fairness are jointly improved. 
% Moreover, Mohri \textit{et al.} \cite{mohri2019agnostic} propose agnostic federated learning (AFL) and prove its fairness using data-dependent Rademacher complexity guarantees. 


% %总结：现有FFL有两大问题，首先是效率不佳，往往需要多轮训练，不适合于能量受限的UAV network。其次是缺乏考虑对联邦学习可信技术的兼容。
% To summarize, existing FFLs encounter two drawbacks. Firstly, they exhibit unsatisfactory efficiency, often necessitating multiple training rounds, rendering them unsuitable for energy-constrained UAV networks. Secondly, the consideration for compatibility with reliable technologies is insufficient.
% \subsection{Reliability of information sharing (confidentiality)}%隐私安全
% \subsubsection{Cryptography solutions} 
% Homomorphic encryption (HE) and other cryptographic methods naturally serve as suitable privacy protection measures. For instance, ShieldFL \cite{ma2022shieldfl} employs secure cosine similarity to measure the distance between two encrypted gradients, utilizing dual-gate HE to resist model poisoning. BatchCrypt \cite{zhang2020batchcrypt} further enhances HE efficiency by incorporating batch gradient encoding and holistic encryption, effectively reducing training time and communication overhead. Additionally, FairFL \cite{zhang2020fairfl} adopts the principled deep multi-agent reinforcement learning framework and secure information aggregation protocol to simultaneously optimize the accuracy and the fairness of FFL while respecting the strict privacy constraints of the clients. 
% Besides, Lyu \textit{et al.} \cite{lyu2020towards} develop a local credibility mutual evaluation mechanism to guarantee fairness, and a three-layer onion-style encryption scheme to guarantee both accuracy and privacy. 
% \subsubsection{Obfuscation solutions} 

% In comparison to encryption, obfuscation approaches such as differential privacy (DP) do not introduce excessive overhead or extensive mechanism modifications, thus garnering significant attention \cite{padala2021federated}. For instance, Wei \textit{et al.} \cite{wei2021low} consider both general training performance and individual client privacy requirements to mitigate latency on wireless channels, addressing challenges posed by channel fading and interference in unknown network environments. Furthermore, considering potential model distortion from obfuscation techniques, privacy amplification as Shuffle \cite{girgis2021shuffled} can enhance the deployment capabilities of privacy protection. NbAFL \cite{wei2020federated-NbAFL} further diminishes the accuracy loss associated with DP by injecting secondary noise into the uplink and downlink channels.

% %总结：密码学方法通信量和计算量过大，而DP方法缺乏对异构考量
% Upon analysis, privacy-preserving information-sharing methods based on cryptography often incur excessive communication and computational overhead. On the other hand, methods relying on obfuscation like differential privacy lack adaptability to heterogeneous network environments, usually resulting in significant accuracy losses.
% \subsection{Reliability of model aggregation (integrity)}%model安全
% To resist the stealthy yet destructive poisoning attacks \cite{lyu2023poisoning}, multiple defense methods are proposed, which can be divided into the following types based on the realization concepts:
% \subsubsection{Mitigation-oriented technologies} 
% To ensure the integrity of the aggregated model, various robust FL methods, such as Byzantine-robustness, have been proposed. For instance, Krum \cite{blanchard2017machine-krum} selects partial neighboring nodes as references, enabling the algorithm to choose updates with the highest consensus for the next iteration. Diverging from Krum's approach of selecting only one update, FABA \cite{xia2019faba} employs gradient outlier computation to discard few gradients while retaining the majority of clients' training results, significantly enhancing learning speed. Building upon these methods, Gong \textit{et al.} devise AGRamplifier \cite{gong2023agramplifier}, which enhances the "morality" of local updates by identifying the most suppressive features in each gradient update. This augmentation further elevates model robustness, fidelity, and efficiency. 



% \subsubsection{Detection-oriented technologies} 
% An alternative approach to fortify against poisoning is the direct detection of the learning model using a validation dataset or predefined rules. For instance, Zeno \cite{xie2019zeno} evaluates the stochastic descendant score for each gradient based on a validation dataset, selectively discarding gradients with low scores for the stochastic descendant. In contrast to relying on an auxiliary validation set, Baffle \cite{andreina2021baffle} capitalizes on the diverse datasets accessible across various clients by integrating a feedback loop into the FL process. Besides, Fldetector \cite{zhang2022fldetector} anticipates a client's model update during each iteration by leveraging historical model updates and flags a client as potentially malicious if the received model update contradicts the predicted update. 
% It is noteworthy that detection-centric solutions entail additional training costs and may not identify some zero-day attacks.



% \subsubsection{Credit-oriented technologies} 
% %鉴于联邦学习是协作式、多轮次的交互过程，通过维护信用评价机制同样可以很好地清除恶意用户。例如，Kang等人使用多权重主观逻辑模型设计基于声誉的可靠联邦学习用户选择方案，并利用区块链实现声誉管理。在不需要辅助验证数据集的情况下，Xu等人提出余弦梯度Shapley值来评估每个智能体上传的模型参数更新/梯度的期望边际贡献，以区别对待。Tan等人提出了一种基于声誉感知的随机整数规划的FL客户选择方法，可以最优地选择和补偿具有不同声誉档案的客户，从而对抗潜在的异常行为。
% Considering that FL is a collaborative and iterative process, the credit evaluation mechanism proves effective in poisoning resistance. For instance, Kang \textit{et al.} \cite{credit1-kang2019IOT} design a reputation-based reliable scheme utilizing a multi-weight subjective logic model, and implement reputation management through blockchain. Xu \textit{et al.} \cite{xu2020reputation, xu2021gradient}, without the need for auxiliary verification datasets, introduced the cosine gradient Shapley value to assess the model parameter updates/gradients uploaded by each client. Tan \textit{et al.} \cite{tan2022reputation} propose a reputation-aware stochastic integer programming client selection method, selecting and compensating clients with varying reputation profiles to counter potential anomalous behavior.




% %总结：现有方案缺乏对隐私的考量，计算量过大
% In general, existing solutions often struggle to achieve a satisfactory balance between privacy and defensive performance, while also lacking adaptability to heterogeneous and dynamically changing environments. Furthermore, some methods exhibit relatively large computational overhead, imposing a non-negligible burden on UAV nodes.


% \section{System model \& Preliminaries}
% %%symbols 表格
% \begin{table}[!t]
% {
% \renewcommand{\arraystretch}{1.2}
% \caption{Summary of Main Notation}
% \label{notations}
% \vspace{0em}
% \centering
% \begin{tabular}{| c || l |}
% \hline
% \textbf{Symbol} & \multicolumn{1}{c |}{\textbf{Description}}\\
%     \hline
%     $U_i,\mathcal{D}_i$ & The $i$-th UAV devices and its dataset\\
%     \hline
%     $n^{s_{m}, i},\mathcal{P}^i$ & The size and normalized distribution of $\mathcal{D}_i$\\
%     \hline
%     $\mathcal{P}^{Tar}, w$ & Target distribution and model of learning task $Job$\\
%     \hline
%     $T$ & The maximum communication rounds of $Job$\\
%     \hline
%     $C,K$ & The set and number of all peer communities\\
%     \hline
%     $S,M$ & The set and number of all colleague communities\\
%     \hline
%     %$L$ & The number of clients in each super node\\
%     %\hline
%     $c_k$ & The $k$-th peer community\\
%     \hline
%     $s_m$ & The $m$-th colleague community\\ 
%     \hline
%     $\Delta \widetilde{\omega}_{t}^{s_{m},i}$ & The weight updates from $U_i \in s_m$ in round $t$\\
%     \hline
%     $p^{s_{m}, i}$ & The aggregation coefficient for $U_i$ within $s_m$\\
%     \hline
%     $\Delta\widetilde{\omega}_{t}^{s_{m}}$ & The weight updates from $s_m$ in round $t$\\
%     \hline
%     $p^{s_{m}}$ & The aggregation coefficient for $\Delta\widetilde{\omega}_{t}^{s_{m}}$ from $s_m$\\
%     \hline
%     $E_k$ & The clipping bound of peer community $c_k$\\
%     \hline
%     $Sen_k$ & The maximum sensitivity of $c_k$\\
%     \hline
%     $\varepsilon_k,\delta_k$& The parameters of differential privacy \\
%     \hline
%     $L$& The minimum size of colleague community\\
%     \hline
%     $\alpha^{a,b}_{t}$& The cosine similarity between $a$ and $b$\\
%     \hline
%     $PI^{c_k \rightarrow i}_{t}$ & The positive interaction between $c_k$ and $U_i$\\
%     \hline
%     $NI^{c_k \rightarrow i}_{t}$& The positive interaction between $c_k$ and $U_i$\\
%     \hline
%     $\Upsilon^{c_k \rightarrow i}_{t}$& The peer reputation opinion vector of $c_k$\\
%     \hline
%     $\Phi^{c_k \rightarrow i}_{t}$& $c_k$'s credit evaluation towards $U_i$ in round $t$\\
%     \hline
%     $\Upsilon^{s_m}_{t}$ & The colleague reputation opinion vector towards $s_m$\\
%     \hline
%     $\Phi^{s_m \rightarrow i}_{t}$& The colleague credit evaluation for $\forall U_i \in s_m$\\
%     \hline
%     $\Upsilon^{i}_{t},\Phi^{i}_{t}$& The comprehensive reputation and credit of $U_i$\\
%     \hline
%     $\psi^{i}_t$& The fairness-guaranteed selection probability\\
%     \hline
%     \end{tabular}
%         }
%      \vspace{-1.5em}
%      \end{table}
     
% \textbf{Heterogeneous UAV network scenario.} 
% %\subsection{Network scenario}
% %对于一个多无人机多任务联邦学习场景，有一个服务器与N个无人机，设无人机集合为$U=\{U_i\}$，$\vert\vert U\vert\vert=N$。所有无人机获取的数据集集合为$D=\{D_i\}$，第k个无人机的数据分布为$\mathcal{P}^k\in \mathbb{t}^F$，其中$F$为特征维度；任务场景集合为$T$，其中第k个任务场景中的数据分布为$\mathcal{P}^{tar_k}$。在同一现实场景中，无人机采集到的数据通常是类似的，即对于某个场景的分布$\phi$，所有属于该现实场景的设备集合$B'$均满足$\exists \epsilon\in \mathbb{t}^F,\forall k \in B', ||\phi-\mathcal{P}^k||_1 \leq \epsilon$。
% As shown in Figure \ref{fig1:UAV-Network}, assume a multi-UAV multi-task federated learning scenario for the classification problems. There exists a parameter server (PS)/aggregator (normally equipped with ground base station) and $N$ UAV nodes (UN) $\mathbf{U}\triangleq\{U_1,...U_i,...U_N\}$. Each UN $U_i$ has local dataset $\mathcal{D}_i\triangleq\{(\xi_{i,1},y_{i,1}),...(\xi_{i,j},y_{i,j}),...(\xi_{i,n_i},y_{i,n_i})|y\in \mathbb{R}^F\}$ sampled following distribution $\varphi_q$. %with varied size $n_i$. 
% Here $x$ and $y$ are raw data and label, respectively. As the nodes with overlapped aerial areas or patrol routines may have similar data distributions, we have $\exists \epsilon\in \mathbb{R}^F,\forall U_i, U_j \sim \phi_q, ||\mathcal{P}^i-\mathcal{P}^j||_p \leq \epsilon^{\prime}$, where $\mathcal{P}^i$ is the normalized distribution of $\mathcal{D}_i$. For the highly heterogeneous networks, we also have $\exists U_i \sim \phi_{q^{\prime}}, U_j \sim \phi_q,||\mathcal{P}^i-\mathcal{P}^j||_p \gg \epsilon^{\prime}$ in the same time.  

% %\subsection{Threat model}
% %值得一提的是，方便起见，我们此处仅以多分类问题中的数据类别作为公平性感知针对的对象，实际使用中可以通过特征extractor扩展到数据包含的任意抽象特征。此外，我们以范数差异度作为公平性衡量标准，实际应用中，也可以选取AIDD、DSF、SF等衡量方式并在特定方面取得更好的效果。
% It is crucial to highlight that, for better understanding, our focus in this paper is solely on the data distribution of multi-classification problems as the target for fairness awareness. In practical scenarios, this concept can be easily extended to any abstract features derived from specific demographic groups through feature extractor as exemplified in \cite{shuai2022balancefl}. Furthermore, our chosen metric for fairness evaluation is the norm difference. However, other alternative fairness measures such as QCID \cite{yang2021federated}, ratio loss \cite{wang2021addressing}, and cross-entropy loss \cite{mohri2019agnostic} can be employed, depending on specific requirements, to attain more favorable results.

% \textbf{Fairness-aware learning task.} Without loss of generality, the fairness-aware learning task can be denoted with the quadruple as $Job\triangleq(w,\mathcal{P}^{tar},t_0, T)$, which consists of the model $w$, target distribution $\mathcal{P}^{tar}$, arrival time $t_0$, and duration $T$. Different from existing solutions designed for certain $\mathcal{P}^{tar}$ \cite{li2022data,zeng2022heterogeneous,hiessl2022cohort}, our method can adaptively choose and schedule suitable UAV groups when a new learning task arrives. 

% \textbf{Optimization objective.} We start with vanilla FL algorithms like FedAvg \cite{li2019convergence-fedavg} without consideration of heterogeneity. The optimization objective can be expressed as: 
% %考虑一个联邦学习场景，有1个服务器和$N$个客户。具体来说，客户i的本地数据集为$D_{i}$，其类别分布被定义为$\mathcal{P}^{c_{k},i}$。不同客户的本地数据类别分布高度异构，与全局类别分布$\mathcal{P}^{real}$有巨大差距。为了最小化全局损失函数，得到普适的全局模型，我们有：
% \begin{equation}
%     w^{*}\triangleq \underset{w}{\arg \min } \sum_{i=1}^N p_i\mathcal{L}\left(w, \mathcal{D}_{i}\right) ,
% \end{equation}
% %其中，$\mathcal{L}_{i}(\cdot)$是客户i的由其本地经验风险得出的本地损失函数。然而，由于客户的数据间的高度异构性与客户数据分布与任务场景数据分布间的高度异构性，客户间的本地损失函数不尽相同，难以获得同时最小化各个模型经验风险的最优全局模型参数$w^{*}$并满足任务场景。因此，在上述场景中进行传统FL会导致全局模型无法正常收敛，无法得到满足任务场景的高性能全局模型。
% where $\mathcal{L}(.)$ represents the loss function derived from the local empirical risk of $U_i$, $p_i$ is the aggregation weight. Due to the high heterogeneity among UAV nodes and the substantial mismatch between participants' data distributions and task requirements, obtaining the globally optimal model parameters $\omega^{*}$ that simultaneously minimize the empirical risks of each model and align with task requirements is challenging. %Thus, traditional Federated Learning (FL) in such scenarios leads to the global model failing to converge effectively, resulting in an inability to obtain a high-performance global model that satisfies task scenarios.

% Hence, similar to the existing fair FL solutions in \cite{mohri2019agnostic,zhang2020fairfl,ezzeldin2023fairfed}, we define the optimization objective as follows:
% \begin{equation}
%     w^{*}\triangleq \underset{w}{\arg \min } \ \mathcal{L}_{FFL}(\omega)=\underset{(x, y) \sim \mathcal{P}^{Tar}}{\mathbb{E}}[\mathcal{L}{(\omega,(x, y))}]
% \end{equation}
% %（我这里想的是为了便于之后的凝聚聚类）此外，由于不同现实场景之间可能有较大的数据分布差异，与任务数据分布高度异构。为了最小化全局损失函数，得到适用于特定任务场景的全局模型，我们有：




% \section{Stratified community construction in heterogeneous environment}\label{sec:community}
% %为了实现高度异构的UAV节点集合与动态变化的学习任务之间的良好适配，我们提出了SCC。如图所示，该机制主要包含两个部分：PCC和CCC。其中PCC在网络初始化时运行一次，CCC则在每次收到新任务时运行一次。
% To achieve a robust alignment between highly heterogeneous UAV nodes and dynamically evolving learning tasks, we propose the stratified community construction (SCC) mechanism. As illustrated in Figure \ref{fig2:framework}, SCC comprises two main components: peer community construction (PCC) and colleague community construction (CCC). PCC executes once during network initialization, while the CCC executes each time a new task is received.
% \subsection{Peer community construction (PCC)}
% Based on norm-based pair distance, we first cluster UAV nodes with similar data distributions into $K$ peer community $C=\{ c_{1}, \ldots, c_{K} \}$. The pair distance is calculated as:
% \begin{equation}
% d_{i,j}=\lVert \mathcal{P}^{i}-\mathcal{P}^{j} \rVert_{2}, \forall U_i,U_j\in \mathbf{U}.
% \end{equation}

% %基于客户的数据分布$\mathcal{P}^{i},i\in B$。我们用最大链接法对客户进行层次凝聚聚类。两个簇间的距离为它们中任意两个客户分布之间曼哈顿距离的最大值，当簇间距离大于合并阈值$\zeta$时停止合并，得到最终的聚类结果。由此可知同簇的任意客户分布之间的最大曼哈顿距离小于$\zeta$, 即$\forall i,j \in c, d_{i,j}<\zeta$。
% Then, we employ the complete-linkage method to achieve agglomerative hierarchical clustering (AHC) among UAV nodes. The distance between two peer communities is defined as the maximum Euclidean distance between any two UNs' distributions. The clustering process ceases when the inter-community distance exceeds the merging threshold $\zeta$, resulting in the final outcome. Hence, the maximum distance between any pair of client distributions within the same PC is less than $\zeta$, i.e., $\forall U_i, U_j \in c_k, d_{i,j} < \zeta$, which is denoted as:
% \begin{equation}\label{eq:peer-construct}
%  C\triangleq \underset{c_{1} \cup c_{2} \cup \ldots c_{K}=C}{\arg \min} \left(\max _{\forall c_{k},c_{k'} \in C ,U_i \in c_{k}, U_j \in c_{k'},d_{i, j}\geq\zeta} d_{i, j}\right) .
% \end{equation}

% %根据上述公式，我们得到具有相似类别分布的$K$个簇$C=\{c_{1},\ldots,c_{K}\}$。可以计算每个簇的平均数据分布，簇$c$的平均数据分布$\mathcal{P}^{c}$计算为：
% The average distribution of each peer community $c_k$ is:
% \begin{equation}
%     	 \mathcal{P}^{c_k}=\operatorname{norm}\left(\sum_{i \in c} n^{c,i} \mathcal{P}^{c,i} \right),
% \end{equation}
% %其中，$\mathcal{P}^{c,i}$是簇$c$中客户$i$的数据分布，$n^{c,i}$是簇$c$中客户$i$的数据量。为了保证隐私与数据安全，需要保证簇的个数，否则参与方将可能更容易推断出数据属于哪一簇。同时，当簇的数量较少时，每个簇代表的数据子集更大，这可能会导致更多的敏感信息聚集在同一簇中。如果某个恶意参与方能够成功识别并攻击一个簇，他们可能能够访问或推断出更多敏感信息，增加了数据泄露的风险。因此，需要添加约束：$K \geq \eta$，以确保隐私性。
% where $\mathcal{P}^{k,i}$ represents the data distribution of $U_i$ within cluster $c_k$, and $n^{k,i}$ denotes the size of $\mathcal{D}_i$. 
% To jointly ensure performance and security, it is imperative to control the number of peer communities. A large $K$ enhances the chance of attackers inferring the sensitive information. Conversely, a small $K$ may result in insufficient intra-community similarity, leading to a deterioration in learning performance. Therefore, the introduction of a constraint, $K \geq \kappa$, is essential. This constraint ensures a minimum size of peer community for privacy considerations. $\kappa$ can be adjusted by $\zeta$.

% \subsection{Colleague community construction (CCC)}
% After peer community construction, we further select suitable UAV nodes to form colleague communities $S\triangleq\{s_1, \ldots, s_{M}\}$ with desirable distribution $\mathcal{P}^{tar}$, which avoids the performance degradation caused by heterogeneity. 

% \subsubsection{Problem formulation}
% As shown in Figure \ref{fig2:framework}, based on the requirements of task $job_i$, we first generate the ``\textit{template}'' $\mathbf{h}$ of the colleague community (i.e., required ratio of clients $h_k$ from each peer community $c_k$ in a colleague community $s_{m}$). $\mathbf{h}\triangleq\{h_{1}, \ldots, h_{K}\}$ is a vector to stipulate this composition. Then $M$ colleague communities are constructed accordingly by selecting UAV nodes from each $c_k$. Outlier $c_k$ with small sizes ($\vert\vert c_k\vert\vert< M$) are excluded to improve participation.

% The optimization problem can be defined as:
% \begin{equation}\label{eq:problem}
% \begin{aligned}
% \mathbf{h}^*\triangleq &\underset{\mathbf{h}}{\arg \min} \vert\vert \mathbf{h}\cdot\mathbf{P}-\mathcal{P}^{tar}\vert\vert_2 \\
% \text{s.t. }& \forall c_k \in C, h_k\leq b_k, \\
% &\sum_{i=1} ^K h_i\geq r,
% \end{aligned}
% \end{equation}
% where $\mathbf{P}$ is a $K \times F$ matrix to denote the average feature values for all peer communities. Every row $\mathcal{P}^{c_k}\in \mathbb{R}^F$ denotes the average feature values of one peer community. $\mathbf{B}\triangleq \{ B_{1}, \ldots, B_{K}\}$ denotes the size of all peer communities.

% \subsubsection{Problem transformation} As the above problem is an NP-C quadratic integer optimization problem \cite{murty1985some}, we want to further reduce it to a linear programming problem to meet the efficiency requirements of UAVs. 
% %即将$\mathcal{P}^{c_k}$拆成$l_k=\lceil \log_2(b_k+1) \rceil$行，拆成的新行中，第$i,1\leq i <l_k$行$d_i=2^{i-1}\mathcal{P}^{c_k},e_{k,i}=2^{i-1}$，第$l_k$行为$(b_k-2^i+1)\mathcal{P}^{c_k},e_{k,l_k}=(b_k-2^i+1)$。新矩阵有$R=\sum_{i=1}^k l_i$行，将原$\mathcal{P}$矩阵二进制拆分为一个$R\cdot F$的矩阵$\mathcal{Q}$，将整数规划问题转化成了一个0-1规划问题。
% For each $c_k$, to remove the constraint $B_k$, we conduct binary split on $\mathcal{P}^{c_k}$ to get $l_k=\lceil \log_2(B_k+1) \rceil$ new rows. Hence, the new matrix has $R=\sum_{i=1}^k l_i$ rows. The problem becomes:

% \begin{equation}
% \begin{aligned}
% \mathbf{x}^*\triangleq &\underset{\mathbf{x}}{\arg \min} \vert\vert \mathbf{x}\mathcal{Q}-\mathcal{P}^{tar}\vert\vert_2 \\
% \text{s.t. } &\forall c_k \in C, x_i\in\{0,1\}, \\
% &\sum_{i=1} ^K h_i\geq r,
% \end{aligned}
% \end{equation} 
% where $\mathbf{x}$ can map to $\mathbf{h}$, i.e., $h_k = \sum _{i=1} ^{l_k} e_{k,i}x_{\sum_{j=1}^{k-1} l_j +i}$, and $e_{k,l_k}=(B_k-2^i+1)$. Hence, the above problem is equal to finding the minimum of $(\mathbf{x}\mathcal{Q}-\mathcal{P}^{tar})\cdot (\mathbf{x}\mathcal{Q}-\mathcal{P}^{tar})^T$ as:

% \begin{equation}
% \begin{aligned}
% \mathbf{x}^*\triangleq\underset{\mathbf{x}}{\arg \min}\ \mathbf{x}\mathcal{Q} &\mathcal{Q}^T\mathbf{x}^T-2\mathcal{P}^{tar}Q^T\mathbf{x}^T+\mathcal{P}^{tar}\mathcal{P}^{tar^T}\\
% \text{s.t. }&\mathbf{x}\in\{0,1\}^R,\\
% &\sum_{i=1} ^K h_i\geq r.
% \end{aligned}
% \end{equation}

% We further introduce variable $z_{ij} \in \{0,1\}$ and have $z_{ij}\leq x_i$,$z_{ij}\leq x_j$,$z_{ij}\geq x_i+x_j-1$, to linearize the problem:

% \begin{equation}%\label{eq:problem}
% \begin{aligned}
% \min\ &\mathcal{Q}\mathcal{Q}^T\mathbf{y}-2\mathcal{P}^{tar}Q^T\mathbf{x}^T+P^{tar}P^{tar^T}\\
% \text{s.t. }& \mathbf{x}\in\{0,1\}^R,
% \\
% &x_{ij}\leq x_i, x_{ij}\leq x_j, x_{ij}\geq x_i+x_j-1,
% \\&\sum_{i=1} ^K h_i\geq r.
% \end{aligned}
% \end{equation}

% Thus, the problem can be efficiently solved by linear programming solvers\footnote{For example, https://coin-or.github.io/pulp/}. 

% % \begin{figure}[!t]
% % \centering
% % \includegraphics[width=\linewidth]{figures/fig2.PNG}
% % \caption{Stratified community construction in a heterogeneous environment.}
% % \label{fig2:framework}
% % \end{figure}

% \section{Adaptive FFL training with privacy amplification}
% \subsection{Training workflow of MR-FFL}
% % 初始化过程: task generation & community initiation
% % Step 1: Local training
% % Step 2: Noise obfuscation
% % 中间过程: Upload gradient
% % Step 3: Inner-community aggregation
% % Step 4: Global aggregation
% % Step 5: Personalisation
% % 中间过程: Download model
% % Step 6: Local update

% As shown in Figure \ref{fig3:workflow}, the training workflow of MR-FFL mainly consists of the following steps in one round of iteration:


% \begin{itemize}
%     \item \textbf{Initialization:} Once the FFL task arrives, server conducts the CCC algorithm to quickly select $M$ colleague communities with similar average distributions near to $\mathcal{P}^{tar}$.
%     \item \textbf{Step 1:} First, each node $U_i \in s_m$ trains the current model with personal data to generate the local model $\omega_t^{s_m, i}$.
%     \item \textbf{Step 2:} Then, $U_i$ obfuscates the weights update $\widetilde{\omega}_{t}^{s_{m}, i}$ with differential private noise, and uploads it to the server.
%     \item \textbf{Step 3:} Colleague community aggregates $\widetilde{\omega}_{t}^{s_{m}, i}, \forall U_i \in s_m$ to generate a colleague model $\omega_{t}^{s_{m}}$.
%     \item \textbf{Step 4:} The server aggregates result $\omega^{s_k}$ from each colleague community $s_k \in S$ to get new global model.
%     \item \textbf{Step 5:} Besides, UAV peer community can maintain a personalized peer model $\omega_{t}^{c_{k}}$ to further improve local performance. 
%     \item \textbf{Step 6:} Finally, the global model is distributed to selected UAV nodes for the next round of training.
% \end{itemize}

% As Step 1, 2, and 6 aligns with existing secure FL training process \cite{wei2020federated-NbAFL,padala2021federated}, we focus on Step 3,4 and 5 subsequently.

% \subsubsection{Colleague community aggregation} 
% %为了尽可能地减小异构数据带来的模型方向的差异，以便更好地聚合普适的全局模型，在服务器聚合前，先在super node 内部聚合。也就是说，本地训练后，客户$i, i\in s_{m}$的加噪模型更新量$\Delta \widetilde{\omega}_{t}^{s_{m},i}$被上传到super node进行super node的内部同步。
% To reduce the canceling phenomenon caused by heterogeneous data and improve training efficiency,  we first aggregate all $\Delta \widetilde{\omega}_{t}^{s_{m}, i}$ within $s_m$ to generate more homogeneous weight updates $\Delta\widetilde{\omega}_{t}^{s_{m}}$ of colleague model $s_m$ before the global aggregation: %In other words, following local training, the perturbed model update quantity, denoted as $\Delta \widetilde{\omega}{t}^{s{m},i}$ for client $i$ where $i\in s_{m}$, is uploaded to the super node for internal synchronization before server-level aggregation.
% \begin{equation}
%     \begin{gathered}
%      \Delta\widetilde{\omega}_{t}^{s_{m}} =  \widetilde{\omega}_{t-1}^{s_{m}}-\widetilde{\omega}_{t}^{s_{m}}
%      = \sum_{i \in s_{m}} p^{s_{m}, i}\Delta \widetilde{\omega}_{t}^{s_{m},i},
%      \end{gathered}
% \end{equation}
% where $p^{s_{m}, i}= {n^{s_{m}, i}}/{n^{s_{m}}}$ is aggregation coefficent, $n^{s_{m}}=\sum_{i \in s_{m}} n^{s_{m}, i}$.

% \subsubsection{Global aggregation} 
% Then, the server aggregates the learning results from all $s_m$ and updates the global model:
% \begin{equation}
% \widetilde{\omega}^g_{t} \leftarrow \widetilde{\omega}^g_{t-1} - p^{s_{m}} \sum_{m=1}^{M} \Delta\widetilde{\omega}_{t}^{s_{m}},
% \end{equation}
% where $p^{s_{m}}= \frac{n^{s_m}}{\sum_{s_{m} \in S} n^{s_m}}$, and $\widetilde{\omega}_{t}$ is the global model. The global aggregation iteratively executes $T$ rounds to complete the learning task $Job=(w,\mathcal{P}^{tar},t_0, T)$\footnote{The termination condition for the learning task can also be set based on accuracy $\epsilon^{\prime\prime}>0$ rather than a fixed number of rounds $T$, i.e., $\mathcal{L}_{FFL}(\omega_t)\leq \epsilon^{\prime\prime}$, by only modifying the quadruple to $(w,\mathcal{P}^{tar},t_0, \epsilon^{\prime\prime})$.}.

% \subsubsection{Peer community personalization} Finally, to further improve the performance on local datasets, we personalize the local model for peer community by adding the proximal term:
% \begin{equation}\label{eq:personal}
% \omega_{t}^{k} = \omega_{t-1}^{k} - \eta\left(\sum_{i=1}^{\vert\vert c_{k}\vert\vert}p^{c_{k},i}  \Delta \widetilde{\omega}_{t}^{c_{k},i} + \lambda \left(\omega_{t-1}^{k}-\omega_{t-1} \right)\right)
% \end{equation}
%     where $p^{c_k}= \frac{n^{s_m}}{\sum_{c_k \in C} \vert\vert c_k\vert\vert}$, $\eta$ is the learning rate, $\lambda$ is the regularization coefficient. The smaller $\lambda$, the more the local models $\omega_t^{k}$ can deviate from the (corrupted) global model $\omega_t$, achieving robustness at the expense of generalization \cite{li2021ditto}.

% In Algorithm \ref{algorithm1}, we present the pseudocode for the complete adaptive training process described above. It is evident from the algorithm that our approach only requires participants to provide distribution information, enabling significant improvements in efficiency, accuracy, and privacy in heterogeneous environments. Furthermore, our training method seamlessly integrates with the subsequently proposed credit evaluation mechanism. In cases where some attackers dishonestly report their information, the integrity of the model is still guaranteed.

% % \begin{figure}[!t]
% % \centering
% % \includegraphics[width=\linewidth]{figures/fig3.PNG}
% % \caption{The workflow of MR-FFL.}
% % \label{fig3:workflow}
% % \end{figure}


% \subsection{Analysis of privacy amplification}


% Different from existing central differential privacy (CDP) or local differential privacy (LDP) methods, which inevitably introduce excessive large noise and thus deteriorate the learning performance in heterogeneous environments, inspired by \cite{liu2022privacy}, we propose a novel DP notion: \textit{community-specific differential privacy} (CSDP) for heterogeneous federated learning. The anonymity is achieved within a peer community instead of the whole UAV network, which significantly reduces privacy loss under the same DP guarantee. Each peer community can be assigned with different $\varepsilon_k$ and $\delta_k$ based on personal needs.

% \subsubsection{Noise calculation} We first calculate the noise scale needed for the MR-FFL workflow to achieve our $(\varepsilon_k,\delta_k)$-CSDP. Assume a pair of neighbor datasets $\mathcal{D}^{s_{m}, i}_{t}$ and $\mathcal{D}^{s_{m}, i'}_{t}$ sampled from same $s_m$ with size $n^{s_{m}, i}$, there is only one pair of nonidentical samples $\xi^{i}_{t}$ and $\xi^{i\prime}_{t}$ within the neighbor datasets. The $l_2$ norm-based sensitivity can be calculated as:

% \begin{equation}
%      \begin{aligned}
%     \Delta F&=\max _{\xi^{i}_{t},\xi^{i\prime}_{t}}\left\|F^{s_m}\left(w_{t-1}, \mathcal{D}^{s_{m},i}_{t}\right) -F^{s_m}\left(w_{t-1}, \mathcal{D}^{s_{m},i'}_{t}\right)\right\|\\
%     &\leq \frac{n^{s_{m},i}}{n^{s_{m}} M}\left(  \max \left\| \Delta\omega_{r,t}^{s_{m},i}\right\|   + \max  \left\| \Delta\omega_{r,t}^{s_{m},i}\right\| \right)
%      \end{aligned}
% \end{equation}

% The second inequality can be deduced through a similar analysis as in \cite{wei2020federated-NbAFL}. We omit the specific process for simplicity. 
% After DP weights clipping \cite{abadi2016deep}, assuming an equal volume of data for clients and a minimum node count $L$ ($L\geq r$) within the colleague community, we have the best sensitivity as:
% \begin{equation}
%     Sen_k=\max _{i \in c_{k}}\left\{\Delta f\right\} \leq \frac{2 E_{k}}{L M},
%     \end{equation}
%  where $E_k$ is the clipping bound of $c_k$.
% The standard deviation of the Gaussian noise to achieve $(\varepsilon_k,\delta_k)$-CSDP is:
% \begin{equation}
%     \sigma_{k}=\frac{\ell_{k} Sen_k }{\varepsilon_{k}}=\frac{2 \ell_{k} E_{k}}{L M\varepsilon_{k}},
%     \end{equation}
% where constant $\ell_{k} =\sqrt{2 \ln (1.25 / \delta_{k})}$ \cite{dwork2014algorithmic}.

% \subsubsection{Privacy analysis} 

% %我们假设客户的类别分布$\mathcal{P}^{c_{k}}$符合高斯分布$\varphi_{c_{k}} $，即客户类别以方差$\sigma_{c_{k}}^{2}$正态分布在簇心$\mu_{c_{k}}$周围，即簇$c_{k}$的类别分布可以用$\varphi_{c_{k}} \sim \mathcal{N}\left(\mu_{c_{k}}, \sigma_{c_{k}}^{2}\right)$的高斯分布表示。
% We assume that the data distribution of the UAV clients, denoted as $\mathcal{P}^{c_{k}}$, follows a Gaussian distribution $\varphi_{c_{k}}$, where the data are normally distributed around the community center $\mu_{c_{k}}$ with a variance of $\sigma_{c_{k}}^{2}$. In other words, the data distribution of community $c_{k}$ can be represented by a distribution $\varphi_{c_{k}} \sim \mathcal{N}\left(\mu_{c_{k}}, \sigma_{c_{k}}^{2}\right)$ \cite{wei2020federated-NbAFL}. 
% %对于某一簇$c_{i}$,整体类别分布符合高斯分布$\varphi_{c_{i}} \sim \mathcal{N}\left(\mu_{c_{i}}, \sigma_{c_i}^{2}\right)$，从中随机抽取任意客户$\forall i,i'\in c_{i}$，客户类别分布也符合$\varphi_{c_{i}}$。
% For a specific peer community $c_{k}$, the overall data distribution follows distribution $\varphi_{c_{k}} \sim \mathcal{N}\left(\mu_{c_{k}}, \sigma_{c_i}^{2}\right)$. Hence, selecting any UAV client $\forall i,i'\in c_{k}$ from it, the client's distribution also follows $\varphi_{c_{k}}$ \cite{wei2021low}. 

% %由公式（9）可知，在本地训练中，客户最小化本地经验风险得到的梯度与客户的本地数据有关，且客户梯度间的最大距离与数据分布的分散程度正相关，可以得到簇$c_{i}$客户梯度间的最大距离：
% As indicated by \cite{sattler2020clustered-CFL}, it is evident that in local training, the gradient obtained by a client, which minimizes the local empirical risk, is related to the client's local data. The maximum distance between client gradients is positively correlated with the dispersion of the distribution. Consequently, the maximum distance between gradients of nodes within peer community $c_{k}$ can be derived as $\max_{i,i'\in c_{k}} \left\| \Delta\omega_{t}^{c_{k},i}-\Delta\omega_{t}^{c_{k},i'}\right\| \simeq \sigma_{c_k}$. 
    

% %super node按照数量$n=[n_{1},\ldots,n_{k},\ldots,n_{K}],  n_{k} \in \mathbb{N}$从簇$\{c_{1},\ldots,c_{k},\ldots,c_{K}\}$中选择$L$个客户:$\sum^{K}_{k=1} n_{k}=L$。通过卷积求和上述簇分布，可以得到super node 的类别分布$\varphi_{s}$：
% We choose UAV nodes from each peer communities $c_{k},\forall c_k \in C$ to constitute colleague communities according to composition vector $\textbf{h}=[h_{1},\ldots,h_{k},\ldots,h_{K}],  h_{k} \in \mathbb{N}$. Hence, by convolution summation among those peer distributions, we can obtain the distribution of colleague communities $\varphi_{s}$ as: 

% \begin{equation}    \varphi_{s}=h_{1}\varphi_{c_{1}}\oplus\ldots\oplus h_{k}\varphi_{c_{k}}\oplus\ldots\oplus h_{K}\varphi_{c_{K}}
% \end{equation}


% %因为簇分布$\varphi_{c_{k}} \forall c_{k} \in C$是相互独立的高斯分布，可以得到上述簇分布的卷积和。
% As $\varphi_{c_{k}}, \forall c_{k} \in C$ are i.i.d. Gaussian distributions, we have $\varphi_{s} \sim \mathcal{N}\left(\mu_{s}, \sigma_{s}^{2}\right)$, where $\mu_{s}=\sum_{k}^{K} h_{k} \mu_{c_{k}}$, $\sigma_{s}^{2}=\sum_{k}^{K} h_{k}^{2} \sigma_{c_k}^{2}$. 
% Define the maximum distance between weight updates of two UAV nodes $U_i$ and $U_{i^{\prime}}$ from the same colleague community $s$ as $\max_{i,i'\in s} \left\| \Delta\omega_{t}^{s,i}-\Delta\omega_{t}^{s,i'}\right\| \simeq \sigma_{s}$. As $\sigma_{s}=\sqrt{\sum_{k}^{K} h_{k}^{2} \sigma_{c_k}^{2}}$, easy to prove $\sigma_{s}\geq\sigma_{c_{k}}, \forall c_k \in C$.
% Then, we have:
% \begin{equation}
%     \max_{i,i'\in c_{i}} \left\| \Delta\omega_{t}^{c_{i},i}-\Delta\omega_{t}^{c_{i},i'}\right\|\leq \max_{i,i'\in s} \left\| \Delta\omega_{t}^{s,i}-\Delta\omega_{t}^{s,i'}\right\|.
% \end{equation}

% %根据敏感度的定义，可知在super node 中计算supernode内的敏感度将远大于簇内的敏感度。
% According to the definition of sensitivity, our peer community-specific $Sen_k$ and noise scale is much smaller than existing global-wide or colleague-wide DP methods. Hence, to achieve the same FFL performance, the clipping bound of our method is also much smaller, which requires less obfuscation. 

% \begin{comment}
    

% \subsection{Analysis of personalization}
% 在$K$个簇$C=\{c_{1},\ldots,c_{k},\ldots,c_{K}\}$中，每个簇$c_{k}$有相同的客户数$n$。$X^k \triangleq\left\{\omega^{k, i} \in\right.\mathbb{t}\}_{i \in[n]}$，且客户模型以方差$\upsilon^{2}$正态分布在簇心$\omega^{k}$周围，即$\omega^{k, i}=\omega^{k}+z^{k, i}$,其中$z^{k, i} \sim \mathcal{N}\left(0, \upsilon^{2}\right)$。具体来说，为了量化簇的异质性，我们假设簇心$\{\omega^{k}\}_{k \in \left[K\right]}$也以方差$\tau^{2}$正态分布在未知的固定元中心$\theta$周围,即$\omega^{k}=\theta+z^{k}$,其中$z^{k} \sim \mathcal{N}\left(0, \tau^{2}\right)$。其中，$\tau$表示簇心间的分散程度，$\tau$越大，簇越分散，整体分布的异构性越高。在此基础上，簇$c_{k}$为其中客户选择隐私预算$(\varepsilon_{k},\delta_{k})-DP$以最小化整体的泛化误差。每个簇$k$具有不同的裁剪边界$C_{k}$，并以$\sigma_{k}=\frac{2 h_{k} C_{k}}{L M\varepsilon_{k}}$的标准差在本地客户上传的模型加噪,在此基础上，簇$c_{k}$的优化目标可以表示为：
% \begin{equation}
% h_k(\omega)=\tilde{F}_k(\omega)+\frac{\lambda}{2}\|\omega-\omega^{g}\|_2^2
% \end{equation}
% 其中，$\tilde{F}_k(\omega) \triangleq \frac{1}{2}\left(\omega-\frac{1}{n}\left(\xi^k+\sum_{i=1}^{n} \omega^{k, i} \cdot \min \left(1, C_{k} /\left\|\omega^{k, i}\right\|_2\right)\right)\right)^2$是簇$c_{k}$的优化目标，簇$c_{k}$客户梯度加噪大小为$\xi^k \sim \mathcal{N}\left(0, \sigma_{k}^2\right)$。由于数据是亚高斯的，我们可以选择裁剪的边界$C_{k}$避免引入削波误差。因此，簇$c_{k}$的最优本地优化结果为$\widehat{\omega}^k \triangleq \operatorname{argmin} \tilde{F}_k(w)=\frac{1}{n}\left(\xi^k+\sum_{i=1}^{n} \omega^{k, i}\right)$。由于服务器聚合全部参与客户的模型而客户分布在各簇中，因此可得$\omega^{g}=\frac{1}{Kn} \sum_{k=1}^{K}\left(\xi^k+\sum_{i=1}^{n}\omega^{k,i}\right)=\frac{1}{K}\sum_{k=1}^{K}\widehat{\omega}^{k}$。由此可得簇$c_{k}$外各簇的平均估计结果$\widehat{\omega}^{\backslash k}=\frac{1}{K-1}\sum_{j \neq k}\widehat{\omega}^{j}$。
% \end{comment}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{algorithm}[!t]% !t top !b bottom !h right here !p float pages
% \caption{Adaptive training with privacy amplification}
% \label{algorithm1}
% 	\begin{algorithmic} [1]
%     \State \textit{\textbf{ Input: }Learning task $Job\triangleq(w^0,\mathcal{P}^{tar},t_0, T)$; Maximum
% local training iterations $R$; all participant UAV nodes $\mathbf{U}$ and their local dataset $\mathcal{D}_i$.}
%     \State \textit{\textbf{Output: }The global FFL model $\omega$ for task $Job$, personalized local models $\{ \omega^{k}\}_{k \in [K]}$} for peer communities.
%             \State \textbf{Initialize:} $w^{0}_{i} \leftarrow\ w^{0}$%,$\mathcal{P}^{real}=\operatorname{norm}\left(\sum_{i \in B} N^{i} \mathcal{P}^{i} \right)$
%             %\State {\color{CadetBlue}/* \textbf{Peer community construction */} } 
%             %\State $d_{i,j}=\lVert \mathcal{P}^{i}-\mathcal{P}^{j} \rVert_{2}$
%             %\State $C=\{ c_{1}, \ldots , c_{K} \} \leftarrow \arg \min _{c_{1} \cup c_{2} \cup \ldots c_{K}=C}\left(\max _{\forall c_{k},c_{k'} \in C ,i \in c_{k}, j \in c_{k'},d_{i, j}\geq\zeta} d_{i, j}\right) .$
%             \State Construct $C=\{ c_{1}, \ldots , c_{K} \}$ with Eq. (\ref{eq:peer-construct});
%              %\For { $r \in 1, \cdots, R$}
%                 %\State{\color{CadetBlue} /* \textbf{Initialization} */} %$S \leftarrow Select-Clients()$}
%             \State Calculate composition vector $\mathbf{h}$ by Eq. (\ref{eq:problem}) for $Job$;
%             \State Construct colleague communities as $S^t=\{s_{1}, \ldots , s_{M}\}$ according to template $\mathbf{h}$;
%                 \For {each colleague community $s_{m}$ in $S^{t}$ in parallel }
%                     \For {each UAV node $U_i$ in $s_{m}$ in parallel}
%                         \State {\color{CadetBlue}/*\textbf{Local Training*/}} 
%                         %\State $\omega_{t}^{s_{m},i} \leftarrow \omega_{t-1}^{s_{m},i}-\frac{\eta}{NI^{s_{m},i}} \nabla_\omega \mathcal{L}_{s_{m},i}\left(\omega_{t-1}^{s_{m},i}, \mathcal{D}^{s_{m},i}_{t}\right)$
%                         \State Update $\omega_{t}^{s_{m},i}$ with $\mathcal{D}_i$ for $R$ iterations;
%                         \State $\Delta \omega_{t}^{s_{m},i}=\omega_{t-1}^{s_{m},i}-\omega_{t}^{s_{m},i}$;
%                         \State{\color{CadetBlue}/* \textbf{Privacy obfuscation */}} 
%                         %\State \textbf{DP:} client $i \in c_{k}$, guarantee ($\varepsilon_{k}$,$\delta_{k}$)-DP
%                         \State Calculate noise $z^{k} \sim \mathcal{N}\left(0, \sigma_{k}^2\right)$, $\sigma_{k}=\frac{2 h_{k} C_{k}}{L M\varepsilon_{k}}$;
%                         \State $\Delta \widetilde{\omega}_{t}^{s_{m},i}=\Delta \omega_{t}^{s_{m},i}+z^{k}$;
%                     \EndFor
%                     \State{\color{CadetBlue}/* \textbf{Colleague community aggregation */}} 
%                     \State $\widetilde{\omega}_{t}^{s_{m}} \leftarrow \widetilde{\omega}_{t-1}^{s_{m}} -  \sum_{i \in s_{m}} p^{s_{m}, i}\Delta \widetilde{\omega}_{t}^{s_{m},i}$;
%                     \State $\Delta\widetilde{\omega}_{t}^{s_{m}} =  \widetilde{\omega}_{t-1}^{s_{m}}-\widetilde{\omega}_{t}^{s_{m}}$;
%                 \EndFor
%                 \State {\color{CadetBlue}/* \textbf{Global aggregation */}}
%                 \State $\widetilde{\omega}^g_{t} \leftarrow \widetilde{\omega}^g_{t-1} - p^{s_{m}} \sum_{m=1}^{M} \Delta\widetilde{\omega}_{t}^{s_{m}}$;%$\widetilde{\omega}_{t} \leftarrow \widetilde{\omega}_{t-1} - PI^{s_{m}} \sum_{m=1}^{M} \Delta\widetilde{\omega}_{t}^{s_{m}}$
%                 \State{\color{CadetBlue}/* \textbf{Peer community personalization */}}
%                     \State Update the personalized model $\omega_{t}^{k}$ for each peer community $c_k$ with Eq. (\ref{eq:personal});%$\omega_{t}^{k} \leftarrow \omega_{t-1}^{k} - \eta_{c_{k}}\left(\sum_{i=1}^{n_{c_{k}}}p_{c_{k},i}  \Delta \widetilde{\omega}_{t}^{c_{k},i} + \lambda \left(\omega_{t-1}^{k}-\omega^{g}_{t-1} \right)\right)$
%                     %\State Update $\omega_{t}^{k}$
%             % \EndFor
% \State \Return $w^g,\{w^k\}$
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}
% \caption{Single}
% \label{alg:malicious-node-detection-history}
% \begin{algorithmic}[1]
% \State \textit{\textbf{Input:} Global model $\{\theta_g^{t-T}, \dots, \theta_g^{t-1}\}$, historical updates for each nodes $\{\triangledown \theta_{i}^{t-T}, \dots, \triangledown \theta_{i}^{t-1}\}$, threshold $\varepsilon$.}
% \State \textit{\textbf{Output:} Sets of normal/malicious nodes $U_{nor}$ and $U_{mal}$.}

% \State {\color{CadetBlue}/*\textbf{Step 1: historical database construction*/}}
% \For {Client $i \in $}
%     \State Record flattened gradients $\bar{\theta_i^t}$ and models $\theta_g^{t-1};$
%     \State Establish a ray with Eq. () for each of the $t'$ most recent gradients, $t' = \max\{t-T+1, 1\}, \ldots, t$;
% \EndFor

% \State \textbf{Step 2: Obtain the Purpose Intention}
% \For {Client $i$}
%     \State Initialize center $O_{i,0}$ and radius $r_{i,0}$
%     \While {Not Converged}
%         \State Update center $O_{i,k+1}$ and radius $r_{i,k+1}$
%     \EndWhile
%     \State Calculate confidence $cre_i = \frac{1}{r_i + \rho}$
% \EndFor

% \State \textbf{Step 3: Abnormal Detection}
% \For {Client $i$}
%     \For {Each point $O_j \neq O_i$}
%         \State Calculate distance $\|O_i - O_j\|$
%     \EndFor
%     \State Determine $q$-distance $\widetilde{dis_i^q}$ for $O_i$
%     \State Find neighbors $Nei_i$ within $\widetilde{dis_i^q}$
%     \State Compute reachability distance $rea_{i,j} = \max\{\widetilde{dis_i^q}, \|O_i - O_j\|\}$ for $O_j \in Nei_i$
%     \State Calculate local reachability density $lrd_i = \frac{|Nei_i|}{\sum_{j \in Nei_i} rea_{i,j}}$
% \EndFor
% % \For {Client $i$}
% %     \State Compute $lof_i = \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$
% %     \If {$lof_i > 1$}
% %         \State Mark client $i$ as malicious, add to $U_{mal}$
% %     \Else
% %         \State Mark client $i$ as normal, add to $U_{nor}$
% %     \EndIf
% % \EndFor
% \State Calculate $lof_i = \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$ for each client $i$
% % \State $U_{mal} = \{i \,|\, lof_i > 1\}$
% % \State $U_{nor} = \{i \,|\, lof_i \leq 1\}$
% \State $U_{mal}, U_{nor} = \{i \,|\, lof_i > 1\}, \{i \,|\, lof_i \leq 1\}$

% \State \textbf{Step 4: Gradients Aggregation}
% \For {Client $i\in U_{nor}$}
%         \State Compute adjusted confidence $cre_i' = \tanh(cre_i)$
%         \State Normalize weights $w_i = \frac{cre_i'}{\sum_{i \in U_{nor}} cre_i'}$
% \EndFor

% \State \textbf{Output:} Aggregated global model update $\theta_g^t = \theta_g^{t-1} + \sum_{i \in U_{nor}} w_i \cdot \triangledown \theta_i^t$
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}
% \caption{Malicious Node Detection via DCT}
% \label{alg:malicious-node-detection}
% \begin{algorithmic}[1]
% \State \textbf{Input:} $d$, $n$, $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_n^t) \in \mathbb{R}^{n \times d}$, $m$ \Comment{$d$ is the dimension of each node update; $n$ is the number of the nodes participating during each round; $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_n^t) \in \mathbb{R}^{n \times d}$is the local updates from nodes during the $t$-th round; $m$ is the length of low-frequency components}
% \State \textbf{Output:} $U_{nor}$, $U_{mal}$ \Comment{benign nodes, malicious nodes}

% \State Step 1: Frequency Domain Transformation
% \For {Node $R_i$}
%     \State $\bar{\theta_i^t} \gets Flatten(\triangledown \theta_i^t)$
%     \State $G_i^t = Trunc(DCT(\bar{\theta_i^t}), m)$ \Comment{Compute DCT and retain only the top $m$ low-frequency components}
% \EndFor

% \State

% \State Step 2: Clean Ingredient Extraction
% \State $H^t \gets (G_0^t, G_1^t, \ldots, G_{n}^t) \in \mathbb{R}^{d \times m}$ \Comment{Stacking to form Matrix $H^t$.}

% \State $\hat{H}^t \gets (H^t)^{T} H^t$
% \State $\lambda_{max}^t, \xi_{max}^t \gets \text{eig}(\hat{H}^t)$ \Comment{Calculating the maximum singular value and its corresponding eigenvector}
% \State $\tilde{G}^t \gets \frac{H^t \xi_{max}^t}{\sqrt{\lambda_{max}^t}}$ \Comment{The clean ingredient}

% \State

% \State Step 3: Kullback-Leibler Divergence Calculation
% \State $P_i^t \gets Softmax(G_i^t), \, Q^t \gets Softmax(\tilde{G}^t)$
% \For {Node $R_i$}
%     \State $Ki \gets \sum_{k=0}^{m-1} P_i^t[k] \log \left( \frac{P_i^t[k]}{Q^t[k]} \right)$
% \EndFor
% \State $S \gets \{KL_1, KL_2, \ldots, KL_n\}$ \Comment{The distribution differences calculated by KL divergence.}

% \State

% \State Step 4: Malicious Node Detection
% \State $\{C_1, C_2, \ldots, C_K\} \gets \text{HDBSCAN}(S)$
% \State $U_{nor} \gets C_{\text{max}}$, $U_{mal} \gets \{C_i \, | \, i \neq \text{max}\}$

% \end{algorithmic}
% \end{algorithm}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \section{Community-based credit evaluation of UAV nodes}
% In this section, we design a community-based credit evaluation method with a modified three-valued subjective logic model (SLM) \cite{al2021subjective}, to eliminate malicious attackers hiding in heterogeneous UAV networks. By integrating credits from both similarity-dominated intra-community (peer) and performance-dominated inter-community (colleague), multiple poisoning paradigms can be efficiently thwarted. 
% \subsection{Similarity-dominated peer credit evaluation}
% %首先，同一community内的用户在训练过程中上传的weights往往相似性较高。因此，通过社区内相似度比较，可以快速识别出离群的恶意用户。
% UAV nodes' weight updates $\Delta\widetilde{\omega}^{c_k, i}_{t}$ within the same peer community $c_k$ often exhibit a high degree of similarity during the training process. Therefore, by leveraging community-based similarity, one can promptly identify malicious nodes that deviate significantly from the average norm.

% \subsubsection{Basic setting}
% For $\forall U_i \in c_k$, we first calculate the cosine similarity $\alpha_{c,i}^{t} \in [-1,1]$ between weight updates $\Delta\widetilde{\omega}^{c_k, i}_{t}$ from $U_i$ and average weight updates $\Delta\widetilde{\omega}^{c_k}_{t}$ from its peer community $c_k$:
% \begin{equation}
%     	  \alpha^{c_k,i}_{t} = \alpha( \Delta\widetilde{\omega}^{c_k}_{t-1}, \Delta\widetilde{\omega}^{i}_{t}) = \frac{\langle \Delta\widetilde{\omega}^{c_k}_{t-1},\Delta\widetilde{\omega}^{i}_{t}\rangle}{\Vert \Delta\widetilde{\omega}^{c_k}_{t-1}\Vert\cdot\Vert \Delta\widetilde{\omega}^{i}_{t}\Vert },\forall c_k \cap S.
% \end{equation}

% We further define the positive interaction $p^{c \rightarrow i}_{t} \in [0,2]$ as:
% \begin{equation}
%     	 PI^{c_k \rightarrow i}_{t} = \alpha^{c_k,i}_{t} -(-1),
% \end{equation}
% and the negative interaction $n^{c_k \rightarrow i}_{t} \in [0,2]$ as:
% \begin{equation}
%     	 NI^{c_k \rightarrow i}_{t} = 1-\alpha^{c_k,j}_{t}.
% \end{equation}

% %在FL的过程中，客户与簇的交互作用影响客户的信誉评估。诚实的交互行为将为客户的信誉评估带来正向的影响，具有攻击性的或不诚实的交互则会降低客户的信誉评分。我们分别用系数$b$和$c$表示内客户间正负交互作用对信任评价的影响比例，其中，$b>0,c>0$ 且 $b+c=1$。为了惩罚恶意客户，我们为客户间的负面交互设置更大的权重,即$b>c$。
% During the FFL process, benign behaviors positively impact the reputation assessment, while aggressive or deceptive interactions diminish the client's reputation. We use coefficients $b$ and $c$ to quantify the impact of positive/negative interactions in credit evaluation, respectively. $b>0$ and $c>0$, $b+c=1$. To penalize malicious UAV nodes, we assign a greater weight $b>c$ to negative interactions among clients. 
% Hence, we obtain the temporary three-valued peer reputation opinion \cite{liu2019trust} vector $\Upsilon^{c_k \rightarrow i}_{t,temp}\triangleq \{b^{c_k \rightarrow i}_{t,temp}, d^{c_k \rightarrow i}_{t,temp}, u^{c_k \rightarrow i}_{t,temp}\}$ based on SLM as:
% \begin{equation}
% \Upsilon^{c_k \rightarrow i}_{t,temp}=
% \left  \{
%       \begin{array}{ll}%ll按顺序是公式左对齐和条件左对齐
%         b^{c_k \rightarrow i}_{t,temp}=(1-u^{c_k \rightarrow i}_{t})\frac{bPI^{c_k \rightarrow i}_{t}}{ bPI^{c_k \rightarrow i}_{t}+cNI^{c_k \rightarrow i}_{t}},\\
%         d^{c_k \rightarrow i}_{t,temp}=(1-u^{c_k \rightarrow i}_{t})\frac{cNI^{c_k \rightarrow i}_{t}}{ bPI^{c_k \rightarrow i}_{t}+cNI^{c_k \rightarrow i}_{t}},\\
%         u^{c_k \rightarrow i}_{t,temp}=\frac{\sigma_{c_k}-\sigma_{min}}{\sigma_{max}-\sigma_{min}},                
%     \end{array}
% \right.
% \end{equation}
% %$ \sigma_{c}$为簇c中满足$\varepsilon-DP$所加噪声的标准差，体现了根据客户上传加噪梯度计算可信度的不确定性，$ \sigma^{C}_{max}$和$\sigma^{C}_{min}$分别是所有簇$c\in C$中为满足$\varepsilon-DP$所添加的最大噪声和最小噪声。
% where the standard deviation $ \sigma_{c_k}$ of peer community $c_k$ depicts the uncertainty in the credit calculation based on the noisy $\Delta\widetilde{\omega}^{c_k}_{t}$ to achieve DP guarantee. $ \sigma_{max}=\max_{c_k \in C}{\sigma_{c_k}}, \sigma_{min}=\min{c_k \in C}{\sigma_{c_k}}$. %Furthermore, $ \sigma^{C}{max}$ and $ \sigma^{C}{min}$ denote the maximum and minimum noise added, respectively, among all clusters $c\in C$ to satisfy $\varepsilon-DP$.
% Besides, $b^{c_k \rightarrow i}_{t,temp}$, $d^{c_k \rightarrow i}_{t,temp}$, $u^{c_k \rightarrow i}_{t,temp}$ denote \textit{belief}, \textit{disbelief}, and \textit{uncertainty}, respectively. We have $b^{c_k \rightarrow i}_{t,temp}+d^{c_k \rightarrow i}_{t,temp}+u^{c_k \rightarrow i}_{t,temp}=1$ and $b^{c_k \rightarrow i}_{t,temp}$, $d^{c_k \rightarrow i}_{t,temp}$, $u^{c_k \rightarrow i}_{t,temp} \in [0,1]$.

% Then $c_k$'s temporary credit evaluation towards UAV $U_i$ is:
% \begin{equation}
% \Phi^{c_k \rightarrow i}_{t}=b^{c_k \rightarrow i}_{t} + a u^{c_k \rightarrow i}_{t}, \forall c_k \cap S,
% \end{equation}
% %其中$a\in[0,1]$是信誉不确定影响程度的系数。基于上式，根据客户的信誉度可以更明显地区分出恶意客户，从而抑制客户间的负面交互。
% where $a\in[0,1]$ is a coefficient regulating the importance of uncertainty. 
% Based on the above equation, malicious clients can be distinctly distinguished via reputation scores, thereby mitigating negative interactions among clients. 

% \subsubsection{Long-term consideration}
% %在r个同步轮次内，客户的信誉不总是一成不变的。由于客户的信誉随着时间的推移而变化，我们考虑客户间历史信誉的影响。定义信誉的时间衰减因子为：
% During the iterative training, clients' reputations may not remain constant. Some sophisticated attackers even take advantage of this phenomenon and conduct more stealthy poisoning behaviors \cite{credit1-kang2019IOT}. Therefore, we take into account the influence of historical reputation. The time decay factor $v_{\tau}$ is defined as:
% \begin{equation}
% v_{\tau}=\frac{1}{e^{\iota(Y-\tau)}}=e^{-z(Y-\tau)},
% \end{equation}
% %其中$z>0$为冷却系数, $\tau \in [1,Y]$为历史交互时间的时隙,在内部通信中当前时隙$Y=r$。由于过于久远的信誉的时间衰减因子接近0，并且考虑到信誉交互中的内存与计算成本，我们只保留$\vert Y-\tau \vert \leq T$的历史信誉 ,即只记录并维护距离当前通信轮次的$T$轮历史信誉$\Phi^{c \rightarrow i}_{\tau}$。公式(7)表示，越接近当前同步轮次的信誉的时效性越高，即更相信近期交互的信誉度，而不是历史交互。
% where $\iota>0$ is the cooling coefficient, $\tau \in [1,Y]$ represents the time slot of historical interaction, and $Y$ in the current time slot of internal communication. Since the time decay factor for too-old reputations approaches 0, and considering the memory and computational costs in reputation interactions, we set an expiration threshold and retain only $T$ historical reputations $\Phi^{c_ \rightarrow i}_{\tau}$, i.e., $\vert Y-\tau \vert \leq T$. %Formula (7) indicates that reputations closer to the current synchronization round are more timely, placing higher trust in recent interactions rather than historical ones.

% \subsubsection{Stability consideration} 
% %\item \textbf{更新：}在联合学习的迭代交互$r\in[1,R]$中，服务器选择参与本地训练的随机客户子集为$Set_{t}$,在第$r$轮迭代中，只有集合$Set_{t}$中的客户上传模型更新量并彼此交互评估信誉。然而，由于参与训练和客户数量远少于客户总数,即$\vert Set_{t}\vert \ll N$，当前轮次的评估结果不足以给出完整的评估结果。因此，我们使用每个客户端的最新信誉更新值来更新其当前信誉值。设$\left\{ \Phi^{c \rightarrow i}_{t} \right\}_{i}^N$表示在服务器上维护的每个客户的簇内直接信誉。在每一轮交互后，全部客户执行以下更新操作：
% Moreover, as only chosen UAV nodes $U_i\in S$ participate in the FFL at round $t$, cross-slot reputation values can have erratic fluctuation or asynchronous obsolescence problems. Hence, inspired by \cite{jhunjhunwala2022fedvarp}, We introduce the momentum term to the reputation updating as: 
% \begin{equation}
% \Upsilon^{c_k \rightarrow i}_{t}=
% \left\{\begin{array}{ll}
% \Upsilon^{c_k \rightarrow i}_{t} ,& \text { if } U_i \in S\\
% \Upsilon^{c_k \rightarrow i}_{t-1},& \text { otherwise }
% \end{array}\right.
% \end{equation}

% %在训练开始前，初始化所有客户$\forall i \in [N]$的信誉评价$\Upsilon^{c \rightarrow i}_{0}$可以表示为：
% %可以看出我们提供较高的初始信誉并保证非参与客户历史信誉的连续性。
% Then, in the initialization phase $t=0$, we have:
% \begin{equation}
% \Upsilon^{c_k \rightarrow i}_{0}=
% \left  \{
%       \begin{array}{ll}%ll按顺序是公式左对齐和条件左对齐
%         b^{c_k \rightarrow i}_{0}=1-u^{c_k \rightarrow i}_{0},\\
%         d^{c_k \rightarrow i}_{0}=0,\\
%         u^{c_k \rightarrow i}_{0}=\frac{\sigma_{c_k}-\sigma_{min}}{\sigma_{max}-\sigma_{min}}
%       \end{array}
% \right.
% \forall U_i\in c_k.
% \end{equation}


% %上式确保了客户簇内直接信誉的实时性，即维护了包括参与和非参与交互客户在内的全部客户的当前信誉均为其最近的信誉更新值。
% The above design ensures the stability of credit evaluation for both participating and non-participating UAV nodes in the current round.

% By integrating both stability and long-term consideration, we obtain the final peer reputation opinion: 
% \begin{equation}
% \Upsilon^{c_k \rightarrow i}_{t}=
% \left  \{
%       \begin{array}{ll}%ll按顺序是公式左对齐和条件左对齐
%         b^{c_k \rightarrow i}_{t}=\frac{\sum_{\tau=r-T}^{t}{v_{\tau} b^{c_k \rightarrow i}_{\tau}}}{\sum_{\tau=r-T}^{t}{v_{\tau}}},\\
%         d^{c_k \rightarrow i}_{t}=\frac{\sum_{\tau=r-T}^{t}{v_{\tau} d^{c_k \rightarrow i}_{\tau}}}{\sum_{\tau=r-T}^{t}{v_{\tau}}},\\
%         u^{c_k \rightarrow i}_{t}=\frac{\sum_{\tau=r-T}^{t}{v_{\tau} u^{c_k \rightarrow i}_{\tau}}}{\sum_{\tau=r-T}^{t}{v_{\tau}}}  ,              
%     \end{array}
% \right.
% \forall U_i\in c_k,
% \end{equation}
% %第r轮同步，簇$c$中客户i的信誉评价为：
% and $c_k$'s credit evaluation towards UAV node $U_i$ at round $t$:
% \begin{equation}
% \Phi^{c_k \rightarrow i}_{t}=\frac{\sum_{\tau=r-T}^{t}{v_{\tau} \Phi^{c \rightarrow i}_{\tau}}}{\sum_{\tau=r-T}^{t}{v_{\tau}}}, \forall U_i\in c_k.             
% \end{equation}

% \subsection{Performance-dominated colleague credit evaluation}
% Performance-dominated colleague credit evaluation generates the general judgment $\Phi^{s_m}_{t}, \forall s_m\in S$ from other colleague communities. 
% As colleague communities are regrouped after every iteration, different from peer credit, colleague credit pays more attention to comprehensive consideration of both performance and similarity between $s_m$ and $s_{m^{\prime}}, \forall s_{m^{\prime}} \in S_{\neg s_m}$. 

% Hence, we first calculate the similarity between $s_m$ and $s_{m^{\prime}}$:
% \begin{equation}
%     	  \alpha^{s_{m},s_{m^{\prime}}}_{t}= \alpha( \Delta \widetilde{\omega}^{s_{m}}_{t},  \Delta\widetilde{\omega}^{s_{m^{\prime}}}_{t}) = \frac{\langle  \Delta\widetilde{\omega}^{s_{m}}_{t}, \Delta\widetilde{\omega}^{s_{m^{\prime}}}_{t}\rangle}{\Vert  \Delta\widetilde{\omega}^{s_{m}}_{t}\Vert\cdot\Vert  \Delta\widetilde{\omega}^{s_{m^{\prime}}}_{t}\Vert }.
% \end{equation}

% The positive and negative interactions are $PI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} = \alpha^{s_{m},s_{m^{\prime}}} -(-1)$ and $NI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} = 1-\alpha^{s_{m},s_{m^{\prime}}}_{t}$, respectively. $PI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} + NI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} = 2$. 

% Thereafter, the \textit{belief} $b^{s_{m} \rightarrow s_{m^{\prime}}}_{t}$ is $$b^{s_{m} \rightarrow s_{m^{\prime}}}_{t}=(1-u_t^{s_{m} \rightarrow s_{m^{\prime}}})\frac{bPI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}}{ bPI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}+cNI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}},$$ 
% \textit{disbelief} $u^{s_{m} \rightarrow s_{m^{\prime}}}_{t}$ is $$u^{s_{m} \rightarrow s_{m^{\prime}}}_{t}=(1-u^{s_{m} \rightarrow s_{m^{\prime}}}_{t})\frac{cNI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}}{ bPI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}+cNI^{s_{m} \rightarrow s_{m^{\prime}}}_{t}},$$ and \textit{uncertainty} $u^{s_{m} \rightarrow s_{m^{\prime}}}_{t}$ is $$u^{s_{m} \rightarrow s_{m^{\prime}}}_{t}=\Vert PI^{s_{m}}-PI^{s_{m^{\prime}}}\Vert/2.$$ 

% For round $t$, the reputation opinion vector can be defined as follows:

% \begin{equation}
% \Upsilon^{s_m}_{t}=
% \left  \{
%       \begin{array}{ll}%ll按顺序是公式左对齐和条件左对齐
%         b^{s_m}_{t}=\frac{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}  b^{s_{m^{\prime}} \rightarrow s_m}_{t}}}{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}}},\\
%         d^{s_m}_{t}=\frac{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}  d^{s_{m^{\prime}} \rightarrow s_m}_{t}}}{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}}},\\
%         u^{s_m}_{t}=\frac{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}  u^{s_{m^{\prime}} \rightarrow s_m}_{t}}}{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}}},                
%     \end{array}
% \right.
% \end{equation}
% where $\rho^{s_m}_{t}=acc^{s_m}_{t}$ is the accuracy of colleague community $s_m$. From the perspective of model security, we assign lower weights to attackers who dishonestly report data distributions based on the model accuracy $acc^{s_m}_{t}$ of $s_m$. Therefore, as the model accuracy $acc^{s_m}_{t}$ increases, the weight assigned to $s_m$ also increases, making the reputation opinion from $s_m$ more reliable.

% The final colleague credit evaluation for $\forall U_i \in s_m$ can be calculated as:
% \begin{equation}
% \Phi^{s_m \rightarrow i}_{t}=\Phi^{s_m}_{t}=\frac{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{(\rho^{s_{m^{\prime}}}_{t} b^{s_{m^{\prime}} \rightarrow s_{m}}_{t}+ a u^{s_{m^{\prime}} \rightarrow s_{m}}_{t})}}{\sum_{s_{m^{\prime}}\in S_{\neg s_m}}{\rho^{s_{m^{\prime}}}_{t}}},   
% \end{equation}

% \subsection{UAV nodes selection with comprehensive
% community-based credit}
% \subsubsection{Comprehensive community-based credit} 
% Finally, by merging peer credit and colleague credit evaluation results, we can obtain comprehensive evaluations of participant UAV nodes based on similarity and performance jointly. 
% The comprehensive reputation opinion $\Upsilon^{i}_{t}$ can be calculated by conducting consensus mechanism between $\Upsilon^{c_k\rightarrow i}_{t}$ and $\Upsilon^{s_m\rightarrow i}_{t}$ as:
% \begin{equation}
% \Upsilon^{i}_{t}=
% \left  \{
%       \begin{array}{ll}%ll按顺序是公式左对齐和条件左对齐
%         b^{i}_{t}=\frac{b^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}+b^{s_m \rightarrow i}_{t}u^{c_k \rightarrow i}_{t}}
%         {u^{c_k \rightarrow i}_{t}+u^{s_m \rightarrow i}_{t}-u^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}},\\
%         d^{i}_{t}=\frac{d^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}+d^{s_m \rightarrow i}_{t}u^{c_k \rightarrow i}_{t}}
%         {u^{c_k \rightarrow i}_{t}+u^{s_m \rightarrow i}_{t}-u^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}},\\
%         u^{i}_{t}=\frac{u^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}}
%         {u^{c_k \rightarrow i}_{t}+u^{s_m \rightarrow i}_{t}-u^{c_k \rightarrow i}_{t}u^{s_m \rightarrow i}_{t}}         
%     \end{array}
% \right.
% \end{equation}

% %因此，可得客户 $j$ 的综合信任度为：
% The comprehensive community-based credit of $U_i$ is: 
% \begin{equation}
% \Phi^{i}_{t}=b^{i}_{t}+a u^{i}_{t}
% \end{equation}

% %通过上述信誉评估过程，服务器可以从簇和super node两个维度综合选择具有高性能和可靠数据的高信誉候选客户作为联邦学习任务中的参与者。该方法能够与FEDGS框架紧密结合，在FEDGS内部同步和外部同步的过程中分别从簇内和super node间评估客户信誉，将信誉评估细化到每轮迭代中，能够及时发现并排除攻击者，尽可能地减少其对联合学习的干扰。


% Similar to peer credit evaluation, the updating rule of $\Phi^{i}_{t}$ is also designed with stability consideration as follows:
% %\textbf{更新：}第$r$轮迭代，被选中参与联合学习的客户集合为$Set_{t}$。设$\left\{ \Phi^{i}_{t} \right\}_{i=1}^N$表示维护的第$r$轮每个客户的综合信誉。在迭代学习的过程中，对于未被选中构建supernode并参与训练的客户，保持其最近轮次的信用评分，并根据最近的综合信任度计算其下一轮次的选择概率：
% \begin{equation}
% \Phi^{i}_{t}=
% \left\{\begin{array}{ll}
% \Phi^{i}_{t} & \text { if } i \in Set_{t} \\
% \Phi^{i}_{t-1}& \text { otherwise }
% \end{array}, \text { for all } i\in[N]\right.
% \end{equation}

% \textbf{Resistance ability against collusion attack:} 
% %当攻击者拥有多个compromised节点时，多个节点可以进行共谋攻击。MR-FFL可以通过简单的设置实现对共谋攻击的阻断。具体来说，在MR-FFL中，攻击者可以采取“集中合谋”或者“分散合谋”策略：（1）分散合谋的攻击者上报不同的数据分布，从而隐藏进不同的异构Peer社区中。显然，这一策略面对传统防御方法或许能够实现绕过，面对MR-FFL时则会被社区内其他用户发现；（2）顾名思义，集中合谋下的攻击者攻击者通过汇报相同的分布而集中在同一个peer社区中。显然，由于我们的综合信用评价同时综合相似度和性能的影响，因此攻击者仍会因为性能不佳而降低评价。我们可以设定一个参与FFL的最低信用值，拥有过多恶意用户的peer社区也会被排除出后续训练。
% When attackers possess multiple compromised UAV nodes, these nodes can conspire to launch collusion attacks. MR-FFL can effectively thwart collusion attacks through simple configurations. Specifically, within MR-FFL, attackers may adopt either a "distributed collusion" or a "centralized collusion" strategy: (a) Attackers engaged in distributed collusion report distinct data distributions, thereby concealing themselves within different heterogeneous peer communities. While this strategy might potentially evade traditional defense methods, when facing MR-FFL, it becomes detectable by other users within the community; (b) As the name implies, attackers engaging in centralized collusion report identical distributions and concentrate within the same peer community. However, due to our comprehensive credit evaluation, which considers both similarity and performance impacts, attackers are still subject to diminished evaluations due to poor performance. A minimum credit threshold for participation in FFL can be set, and peer communities with an excess of malicious users can be excluded from subsequent training.

% \subsubsection{UAV nodes selection}
% %在每轮外部同步结束，我们重新选择客户构建下一轮参与联合学习的super node。
% %为了尽可能地消除攻击者的干扰，我们设计簇内客户选择机制，客户被选中参与联合学习的概率由其上一轮次的综合信用评价决定。在簇$c$中，用sigmoid函数量化客户$i$被选中的概率：
% After each round of FFL training, we reconstruct colleague communities as participants for the next round. To mitigate the impact of potential attacks, we introduce a client selection mechanism within the peer community. The probability of a client being chosen to participate in FFL is determined by its current comprehensive credit evaluation. Drawing inspiration from \cite{zhou2022defta}, we employ a Sigmoid-like function to quantify this probability of UAV $U_i$:
% \begin{equation}
% \psi^{i}_t=\frac{1}{1+e^{-k (\Phi^{i}_{t}-\gamma)}},\forall U_i \in \mathbf{U}, \forall t
% \end{equation}
% %其中$k$为控制sigmoid斜率的参数。由于$\Phi^{i}_{t}\in [0,1]$,我们规定选择概率函数的定义域在[0,1]区间内。可以看出选择概率函数在定义域内的值域$[\frac{1}{1+e^{0.5k}},\frac{1}{1+e^{-0.5k}}]$取决于参数$k$。在实际应用中，为了使选择概率在定义域内尽可能接近0和1，一般选择较大的斜率$k$。
% where $k$ controls the slope of the Sigmoid function. As $\Phi^{i}_{t}\in [0,1]$, we stipulate that the domain of the probability function $\psi^{i}_t$ lies within $[0,1]$. It can be observed that the range of $\psi^{i}_t$ is $[\frac{1}{1+e^{\gamma k}},\frac{1}{1+e^{-\gamma k}}]$, depending on $k$. In practical applications, to ensure that the selection probability function closely approaches 0 (malicious clients) and 1 (benign yet heterogeneous clients) within its domain, a larger slope parameter $k$ is usually chosen.

% \textbf{Positive assumption for fairness among benign UAVs:} It is worth mentioning that, different from existing methods' negative assumption, we initiate the selection with positive assumption, i.e., $\Phi^{i}_{0}=1 ,\forall U_i\in \mathbf{U}$, which provides high selective probability for inexperienced new participants. Therefore, this approach can achieve more fair selection results among benign UAV nodes and maximize client participation. Besides, we obtain a more comprehensive evaluation of credit, drastically mitigating the potential impact of adversarial behavior.

% %服务器基于本轮综合信用评分选择客户参与下一轮次的训练，为了尽可能地提高客户的参与率，得到更全面、完整的客户信誉评估结果，将综合信誉作为客户属性进行持久化存储，服务器将赋予客户乐观的初始综合信誉并在每轮交互中更新客户的最新综合信誉。
% %The server selects clients for the next training round based on the current comprehensive credit score. In order to maximize client participation, achieve a more comprehensive and complete client credit assessment, and persistently store the comprehensive credit as a client attribute, the server endows clients with an optimistic initial comprehensive credit. 
% %乐观的初始信誉和时间延迟的信誉更新增加了参与训练次数较少的客户被选中的概率，能够更全面、完善地评估所有客户的信誉，避免潜在攻击的影响。
% %This initial credit, along with delayed credit updates over time, increases the probability of selecting clients with fewer training participations. This approach aims to provide a more comprehensive and thorough evaluation of all clients' reputations, mitigating the potential impact of adversarial behavior.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % \begin{algorithm}[t]
% % \caption{algorithm credit} %算法的名字
% % \begin{algorithmic}[1]
% %  \State \textbf{\bf Input:Model Variation of Client i $\Delta\widetilde{\omega^{i}_{t}}$, Model Variation of Cluster c $\Delta\widetilde{\omega^{c}_{t-1}}$}
% % \State\textbf{Output:Comprehensive Credit of Client $\Phi^{i}_{t}$,Peputation Opinion Vector $\Upsilon^{i}_{t}$} 
% % \State \textbf{Initialize:$u^{c \rightarrow i}_{0}=\frac{\sigma_{c}-\sigma_{min}}{\sigma_{max}-\sigma_{min}}$,$b^{c \rightarrow i}_{0}=1-u^{c \rightarrow i}_{0}$,$d^{c \rightarrow i}_{0}=0$}
% % \For{$r \in 1,\cdots,R$}
% %     \State {\color{CadetBlue}/*\textbf{Credit in cluster $c$ */}}
% %         \For{each client $i \in c$ }
% %             \If{client $i \in C \cap S$ }
% %                 \State $ \alpha^{c,i}_{t} = \alpha( \Delta\widetilde{\omega^{c}_{t-1}}, \Delta\widetilde{\omega^{i}_{t}}) = \frac{\langle \Delta\widetilde{\omega^{c}_{t-1}},\Delta\widetilde{\omega^{i}_{t}}\rangle}{\Vert \Delta\widetilde{\omega^{c}_{t-1}}\Vert\cdot\Vert \Delta\widetilde{\omega^{i}_{t}}\Vert }$,
% %                 \State$p^{c \rightarrow i}_{t} = \alpha^{c,i}_{t} -(-1)$,$n^{c \rightarrow i}_{t} = 1-\alpha^{i,j}_{t}$,
% %                 \State \textbf{update  $\Upsilon^{c \rightarrow i}_{t},\Phi^{c \rightarrow i}_{r,time}$ with equation}
% %                 \State $\Phi^{c \rightarrow j}_{t}=\Phi^{c \rightarrow i}_{r,time}$
% %             \Else
% %                 \State$\Phi^{c \rightarrow j}_{t}=\Phi^{c \rightarrow i}_{t-1}$
% %             \EndIf
% %          \EndFor
% %     \State {\color{CadetBlue}/*\textbf{Credit in supernode $s$ */}}
% %     \For{each supernode $s_{m} \in S-s_{m}$}
% %         \State $\alpha^{s_{m},s_{m^{\prime}}}_{t}= \alpha( \Delta \widetilde{\omega^{s_{m}}_{t}},  \Delta\widetilde{\omega^{s_{m^{\prime}}}_{t}}) = \frac{\langle  \Delta\widetilde{\omega^{s_{m}}_{t}}, \Delta\widetilde{\omega^{s_{m^{\prime}}}_{t}}\rangle}{\Vert  \Delta\widetilde{\omega^{s_{m}}_{t}}\Vert\cdot\Vert  \Delta\widetilde{\omega^{s_{m^{\prime}}}_{t}}\Vert }$,
% %         \State $PI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} = \alpha^{s_{m},s_{m^{\prime}}} -(-1)$,$ NI^{s_{m} \rightarrow s_{m^{\prime}}}_{t} = 1-\alpha^{s_{m},s_{m^{\prime}}}_{t}$
% %         \State \textbf{update $\UpsiloNI^{s_{m} \rightarrow s}_{t},\Phi^{s}_{t}$ with equation}
% %     \EndFor
% %     \For{each client $i \in S$}
% %         \State $\Phi^{s \rightarrow i}_{t}=\Phi^{s}_{t} $
% %     \EndFor
% %     \State {\color{CadetBlue} /*\textbf{Comprehensive credit */}}
% %     \For{each client $i \in Clients$}
% %         \If{client $i \in C\cap S$ }
% %         \State \textbf{update $\Upsilon^{i}_{t},\Phi^{i}_{t}$ with equation}
% %         \Else 
% %         \State $\Phi^{i}_{t} = \Phi^{i}_{t-1}$
% %         \EndIf
% %     \EndFor
% % \EndFor
% % \end{algorithmic}
% % \end{algorithm}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure}[tb]
% 	\begin{minipage}[!t]{0.49\linewidth}
% 		\centering
% 		\includegraphics[width=\linewidth]{results/SCC_diff.pdf}
% 		%\vspace{-2em}
% 		\caption{$L_2$-divergence}
% 		\label{results:1-diff}
% 	\end{minipage}
%         \begin{minipage}[!t]{0.49\linewidth}
% 		\centering
% 		\includegraphics[width=\linewidth]{results/SCC_time.pdf}
% 		%\vspace{-2em}
% 		\caption{Running time}
% 		\label{results:1-time}
% 	\end{minipage}
% \end{figure} 

% \begin{figure}[!t]
% \centering
% \includegraphics[width=\linewidth]{results/SCC_acc.pdf}
% \caption{The accuracy comparison between MR-FFL with existing heterogeneity-robust methods.}
% \label{results:1-acc}
% \end{figure}

% \section{Experimental results}
% \subsection{Experimental settings}
% Experiments were conducted using the PyTorch deep learning framework, employing two widely adopted benchmark datasets (EMNIST and CIFAR). To demonstrate the defense performance of the proposed MR-FFL scheme, we conduct both explicit (Flipping attack) and implicit (Backdoor attack) attack paradigms. %The EMNIST dataset encompasses 10 categories for digits and 52 categories for uppercase and lowercase English letters, totaling 62 categories. All images have dimensions of 28x28 pixels. 
% In line with the methodologies of previous studies \cite{mohri2019agnostic,tan2022fedproto, zeng2022heterogeneous}, our experiments were conducted under a non-iid setting, implementing non-uniform sampling within the dataset. 
% To create an equitable but dissimilar distribution among clients, we extracted 12,0000 training samples and 30,000 testing samples, allocating them in an 8:2 ratio between the training set and the validation set. This ensured that each client possessed an equal number of samples in the training dataset, albeit with distinct data distributions. %Two neural network architectures, a simple CNN and an MLP, were employed to undertake the Federated Learning (FL) task on the EMNIST dataset. The detailed configurations of the local network models are delineated in Tables 2 and 3.
% Throughout our experiments, we configured $200\sim 500$ UAV nodes. A total of 200 communication rounds were executed, where the local training epoch for each $U_i$ is 5, the batch size is 128, the learning rate $\eta$ is 0.1, and the momentum is 0.9. 


% \subsection{The effectiveness of MR-FFL in heterogeneous UAV network}

% To verify the effectiveness of our stratified community construction mechanism, we compare it with existing heterogeneity-robust methods in terms of divergence reduction, running time, and learning performance. We choose three benchmark methods (\textbf{Random}, \textbf{Bayesian}, \textbf{Generic algorithms}) and two latest methods (\textbf{Cohort} \cite{hiessl2022cohort} and \textbf{GBP-CS} \cite{li2022data}). 
% In terms of divergence reduction, as shown in Figure \ref{results:1-diff}, our method significantly reduces both the average maximum divergences and deviation among clients, which indicates better robustness. 
% Regarding execution time, SCC requires only one operation to generate a sampling template. Subsequently, it performs random sampling based on the template, resulting in a short execution time. This advantage becomes more pronounced with increasing rounds. As shown in Figure \ref{results:1-time}, our method is more time-saving than other alternative methods.%On the other hand, Bayesian sampling and Genetic Algorithm have excessively long execution times, which are not acceptable. The Cohort algorithm has a relatively short runtime, but it suffers from a large deviation from the target distribution. GBP-CS algorithm needs sampling before each iteration, and its runtime is not as efficient as the QIP algorithm.



% In terms of learning performance, we also compared three representative algorithms (\textbf{FedAvg} \cite{li2019convergence-fedavg}, \textbf{FedNova} \cite{wang2020tackling-fednova}, \textbf{FedProx} \cite{yuan2022convergence-fedprox}) with MR-FFL. As illustrated in Figure \ref{results:1-acc}, vanilla FL algorithms exhibit slow convergence rates and poor performance with large fluctuations in heterogeneous environments. In comparison to heterogeneous FL algorithms like FedNova and FedProx, MR-FFL continues to achieve better convergence speed, stability, and accuracy.

% \subsection{The performance of MR-FFL against poisoning attacks}
% \begin{figure*}[!t]
% \centering
% \subfloat[EMNIST (Flipping)]{\includegraphics[width=0.25\linewidth]{results-new/accuracy/Flip_MINIST_acc.pdf}%
% \label{result0:acc-EMNIST-FLIP}}
% \hfil
% \subfloat[CIFAR (Flipping)]{\includegraphics[width=0.25\linewidth]{results-new/accuracy/Flip_Cifar_acc.pdf}%
% \label{result0:acc-CIFAR-FLIP}}
% \hfil
% \subfloat[EMNIST (Backdoor)]{\includegraphics[width=0.25\linewidth]{results-new/accuracy/BACKDOOR_MINIST_att_acc.pdf}%
% \label{result0:acc-EMNIST-Backdoor}}
% \hfil
% \subfloat[CIFAR (Backdoor)]{\includegraphics[width=0.25\linewidth]{results-new/accuracy/BACKDOOR_Cifar_att_acc.pdf}%
% \label{result0:acc-CIFAR-Backdoor}}
% \caption{The defense performance comparison between MR-FFL with existing poisoning-resistant methods against Flipping and Backdoor attacks.}
% \label{results:0-acc}
% \end{figure*}



% % %%%%%%%%%%%%EMNIST+Flip%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % \begin{figure}[!t]
% % \centering
% % \subfloat[Credit (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/AAD_Flip_MINIST_cr_1.pdf}%
% % \label{result1:credit-AAD}}
% % \hfil
% % \subfloat[PR (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/AAD_Flip_MINIST_pr_1.pdf}%
% % \label{result1:prob-AAD}}
% % \hfil
% % \subfloat[Credit (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/FL_Flip_MINIST_cr_1.pdf}%
% % \label{result1:credit-FLtrust}}
% % \hfil
% % \subfloat[PR (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/FL_Flip_MINIST_pr_1.pdf}%
% % \label{result1:prob-FLtrust}}
% % \hfil
% % \subfloat[Credit (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/MRFLL_Flip_MINIST_cr_1.pdf}%
% % \label{result1:credit-MRFFL}}
% % \hfil
% % \subfloat[PR (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/MRFLL_Flip_MINIST_pr_1.pdf}%
% % \label{result1:prob-MRFFL}}
% % \caption{The credit scores (after 200 rounds) and selection probabilities of different methods (AAD, FLTrust, MR-FFL) against Flipping on EMNIST.}
% % \label{results_EMNIST_flip}
% % \end{figure}

% % %%%%%%%%%%%EMNIST+Backdoor%%%%%%%%%%%%%%%%%%%%%%%
% % \begin{figure}[!t]
% % \centering
% % \subfloat[Credit (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/AAD_BACKDOOR_MINIST_cr_1.pdf}%
% % \label{result2:credit-AAD}}
% % \hfil
% % \subfloat[PR (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/AAD_BACKDOOR_MINIST_pr_1.pdf}%
% % \label{result2:prob-AAD}}
% % \hfil
% % \subfloat[Credit (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/FL_BACKDOOR_MINIST_cr_1.pdf}%
% % \label{result2:credit-FLtrust}}
% % \hfil
% % \subfloat[PR (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/FL_BACKDOOR_MINIST_pr_1.pdf}%
% % \label{result2:prob-FLtrust}}
% % \hfil
% % \subfloat[Credit (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/MRFLL_BACKDOOR_MINIST_cr_1.pdf}%
% % \label{result2:credit-MRFFL}}
% % \hfil
% % \subfloat[PR (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/MRFLL_BACKDOOR_MINIST_pr_1.pdf}%
% % \label{result2:prob-MRFFL}}
% % \caption{The credit scores (after 200 rounds) and selection probabilities of different methods (AAD, FLTrust, MR-FFL) against Backdoor on EMNIST.}
% % \label{results_EMNIST_Backdoor}
% % \end{figure}
% % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % %%%%%%%%%%%%CIFAR+Flip%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % \begin{figure}[!t]
% % \centering
% % \subfloat[Credit (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/AAD_Flip_Cifar_cr_1.pdf}%
% % \label{result3:credit-AAD}}
% % \hfil
% % \subfloat[PR (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/AAD_Flip_Cifar_pr_1.pdf}%
% % \label{result3:prob-AAD}}
% % \hfil
% % \subfloat[Credit (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/FL_Flip_Cifar_cr_1.pdf}%
% % \label{result3:credit-FLtrust}}
% % \hfil
% % \subfloat[PR (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/FL_Flip_Cifar_pr_1.pdf}%
% % \label{result3:prob-FLtrust}}
% % \hfil
% % \subfloat[Credit (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/MRFLL_Flip_Cifar_cr_1.pdf}%
% % \label{result3:credit-MRFFL}}
% % \hfil
% % \subfloat[PR (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/MRFFL_Flip_Cifar_pr_1.pdf}%
% % \label{result3:prob-MRFFL}}
% % \caption{The credit scores (after 200 rounds) and selection probabilities of different methods (AAD, FLTrust, MR-FFL) against Flipping on CIFAR.}
% % \label{results_Cifar_flip}
% % \end{figure}
% % %%%%%%%%%%%CIFAR+Backdoor%%%%%%%%%%%%%%%%%%%%%%%
% % \begin{figure}[!t]
% % \centering
% % \subfloat[Credit (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/AAD_BACKDOOR_Cifar_cr_1.pdf}%
% % \label{result4:credit-AAD}}
% % \hfil
% % \subfloat[PR (AAD)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/AAD_BACKDOOR_Cifar_pr_1.pdf}%
% % \label{result4:prob-AAD}}
% % \hfil
% % \subfloat[Credit (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/FL_BACKDOOR_Cifar_cr_1.pdf}%
% % \label{result4:credit-FLtrust}}
% % \hfil
% % \subfloat[PR (FLTrust)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/FL_BACKDOOR_Cifar_pr_1.pdf}%
% % \label{result4:prob-FLtrust}}
% % \hfil
% % \subfloat[Credit (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Credit/MRFLL_BACKDOOR_Cifar_cr_1.pdf}%
% % \label{result4:credit-MRFFL}}
% % \hfil
% % \subfloat[PR (MR-FFL)]{\includegraphics[width=0.5\linewidth]{results-new/Prob/MRFFL_BACKDOOR_Cifar_pr_1.pdf}%
% % \label{result4:prob-MRFFL}}
% % \caption{The credit scores (after 200 rounds) and selection probabilities of different methods (AAD, FLTrust, MR-FFL) against Backdoor on CIFAR.}
% % \label{results_Cifar_Backdoor}
% % \end{figure}
% % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Subsequently, to further demonstrate the advantages of the MR-FFL method in ensuring model integrity, we compare our approach with existing representative reliable FL algorithms, including \textit{mitigation-oriented} \cite{blanchard2017machine-krum,yin2018byzantine-trimmedmean}, \textit{detection-oriented} \cite{andreina2021baffle}, and \textit{credit-oriented} \cite{li2019abnormal,cao2020fltrust}. The total number of UAV ndoes is set to 200. As shown in Figure \ref{results:0-acc}, we conduct explicit attacks (flipping) and compare the training accuracy in Figure \ref{result0:acc-EMNIST-FLIP} and \ref{result0:acc-CIFAR-FLIP}. Higher accuracy means better defense effect. Meanwhile, the backdoor task accuracy (implicit attack) on EMNIST and CIFAR is demonstrated in Figure \ref{result0:acc-EMNIST-Backdoor} and \ref{result0:acc-CIFAR-Backdoor}, respectively. Lower backdoor accuracy indicates better defense performance. 
% Based on the results, it is evident that mitigation-oriented schemes such as \textbf{Trimmed-mean} \cite{yin2018byzantine-trimmedmean} exhibit significant deviations from the global objectives in heterogeneous environments, resulting in lower accuracy. \textbf{BaFFLe} \cite{andreina2021baffle}, as a detection-oriented method, struggles to converge rapidly and requires additional validation rounds, incurring substantial communication and time overhead. For credit-oriented methods \textbf{AAD} \cite{li2019abnormal} and \textbf{FLTrust} \cite{cao2020fltrust}, although AAD can permanently ban attackers, the gap between heterogeneous gradients and attacker gradients relative to the pre-trained global model leads to erroneous elimination, resulting in an overall performance decline. Similarly, in FLTrust, heterogeneous UAVs with gradients opposite to the direction of server-side model updates face challenges participating in the global model aggregation, causing a decline in model performance.


% Furthermore, in Figure \ref{results_EMNIST_flip} to \ref{results_Cifar_Backdoor}, through a comparative analysis of credit assessment values and selection probabilities with existing methods such as AAD (based on autoencoder) and FLTrust (based on bootstrapping), we validate the effectiveness of the credit evaluation mechanism in the MR-FFL scheme. This validation is crucial for guiding subsequent hyperparameter tuning and adaptive configurations. As illustrated in the first rows of those figures, the AAD method lacks adaptation to highly heterogeneous environments, leading to the misclassification of numerous legitimate UAV nodes. Under FLTrust, as shown in the second rows of above figures, both the credit of normal UAV participants and their selection probabilities exhibit significant fluctuations, with a lack of robustness in detecting certain covert attacks. In contrast, MR-FFL evaluates the integrity of UAV nodes in terms of both community-wide similarity and performance. As shown in the third rows of Figure \ref{results_EMNIST_flip} to \ref{results_Cifar_Backdoor}, our method can accurately identify the stealthy malicious attackers from benign nodes.


% \subsection{The fairness of MR-FFL under adversarial environments}
% One of the important drawbacks of existing security technologies is unfairness. As shown in the second columns of Figure \ref{results_EMNIST_flip} to \ref{results_Cifar_Backdoor}, except for the low accuracy, AAD and FLTrust also assign vastly different selection probabilities to benign UAV nodes. Different from existing methods, MR-FFL employs a Sigmoid function to optimize the selection strategy, resulting in a clearer distinction between attackers and normal users (e.g., Figure \ref{result3:credit-MRFFL} and \ref{result4:credit-MRFFL}). Hence, the probabilities of legitimate clients being selected are approximate (e.g., Figure \ref{result1:prob-MRFFL} and \ref{result2:prob-MRFFL}), ensuring fairness among benign UAV nodes.

\section{Conclusion}
%。本文聚焦于Covert backdoor attacks对于IoRT网络中进行视觉大模型联邦微调过程的威胁，针对性地提出了SecFFT防御架构。不同于现有的浅层信息捕捉的防御方法，我们抓住了频域分布差异中隐含的深层语义进行攻击感知，在此基础上创新地重构出攻击者的意图，从而在保障微调业务模型精度的同时，有效识别和阻断后门攻击，提升可靠性和完整性。在公有数据集上的系列实验表明，我们的方案相比现有技术，在性能提升、误判控制和污染防治方面均取得明显提升。未来方向方面，尽管SecFFT实现了对攻击意图的良好捕捉，但是目前仅仅是较为单一的网络场景。真实IoRT网络中的诸多特性，比如异构、多模态等因素并未纳入考虑，可能对防御性能产生影响。因此，未来将会更加贴近真实网络环境，设计实现异构容忍、抗噪声扰动的强鲁棒意图识别和防御方案。
This paper focuses on the threat posed by covert backdoor attacks during the federated fine-tuning of large vision language models within IoRT networks and proposes the SecFFT defense framework. Unlike existing defense methods that capture only shallow-level information, our approach leverages the latent deep semantic differences in frequency-domain distributions to enhance attack detection. Building on this, we innovatively reconstruct the attacker’s intent, enabling effective backdoor attack detection while preserving the fine-tuning model's accuracy and improving its reliability and integrity. 
A series of experiments demonstrate that our approach significantly outperforms existing techniques. %in terms of performance improvement, false-positive control, and backdoor mitigation. 

Regarding future directions, although SecFFT demonstrates effective intent detection, it currently targets relatively homogeneous network scenarios. Real-world IoRT networks exhibit characteristics such as heterogeneity and multimodality, which are not yet fully considered and may impact defense performance. Hence, future work will focus on designing and implementing robust intent recognition and defense strategies that are tolerant to heterogeneity and resilient to noise disturbances, closely aligning with real network environments.



\section*{Acknowledgments}
This work is partially supported by China Postdoctoral Science Foundation (grant No. 2024M750259), Beijing Natural Science Foundation (grant No. 4244084), National Natural Science Foundation of China (grant No. 62401075, 62394322).


\bibliographystyle{IEEEtran}
\bibliography{ref}

% {\appendix[Proof of the Zonklar Equations]
% Use $\backslash${\tt{appendix}} if you have a single appendix:
% Do not use $\backslash${\tt{section}} anymore after $\backslash${\tt{appendix}}, only $\backslash${\tt{section*}}.
% If you have multiple appendixes use $\backslash${\tt{appendices}} then use $\backslash${\tt{section}} to start each appendix.
% You must declare a $\backslash${\tt{section}} before using any $\backslash${\tt{subsection}} or using $\backslash${\tt{label}} ($\backslash${\tt{appendices}} by itself
%  starts a section numbered zero.)}



%{\appendices
%\section*{Proof of the First Zonklar Equation}
%Appendix one text goes here.
% You can choose not to have a title for an appendix if you want by leaving the argument blank
%\section*{Proof of the Second Zonklar Equation}
%Appendix two text goes here.}



% \section{References Section}
% You can use a bibliography generated by BibTeX as a .bbl file.
%  BibTeX documentation can be easily obtained at:
%  http://mirror.ctan.org/biblio/bibtex/contrib/doc/
%  The IEEEtran BibTeX style support page is:
%  http://www.michaelshell.org/tex/ieeetran/bibtex/
 
 % argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% \section{Simple References}
% You can manually copy in the resultant .bbl file and set second argument of $\backslash${\tt{begin}} to the number of references
%  (used to reserve space for the reference number labels box).

% \begin{thebibliography}{1}
% \bibliographystyle{IEEEtran}

% \bibitem{ref1}
% {\it{Mathematics Into Type}}. American Mathematical Society. [Online]. Available: https://www.ams.org/arc/styleguide/mit-2.pdf

% \bibitem{ref2}
% T. W. Chaundy, P. R. Barrett and C. Batey, {\it{The Printing of Mathematics}}. London, U.K., Oxford Univ. Press, 1954.

% \bibitem{ref3}
% F. Mittelbach and M. Goossens, {\it{The \LaTeX Companion}}, 2nd ed. Boston, MA, USA: Pearson, 2004.

% \bibitem{ref4}
% G. Gr\"atzer, {\it{More Math Into LaTeX}}, New York, NY, USA: Springer, 2007.

% \bibitem{ref5}M. Letourneau and J. W. Sharp, {\it{AMS-StyleGuide-online.pdf,}} American Mathematical Society, Providence, RI, USA, [Online]. Available: http://www.ams.org/arc/styleguide/index.html

% \bibitem{ref6}
% H. Sira-Ramirez, ``On the sliding mode control of nonlinear systems,'' \textit{Syst. Control Lett.}, vol. 19, pp. 303--312, 1992.

% \bibitem{ref7}
% A. Levant, ``Exact differentiation of signals with unbounded higher derivatives,''  in \textit{Proc. 45th IEEE Conf. Decis.
% Control}, San Diego, CA, USA, 2006, pp. 5585--5590. DOI: 10.1109/CDC.2006.377165.

% \bibitem{ref8}
% M. Fliess, C. Join, and H. Sira-Ramirez, ``Non-linear estimation is easy,'' \textit{Int. J. Model., Ident. Control}, vol. 4, no. 1, pp. 12--27, 2008.

% \bibitem{ref9}
% R. Ortega, A. Astolfi, G. Bastin, and H. Rodriguez, ``Stabilization of food-chain systems using a port-controlled Hamiltonian description,'' in \textit{Proc. Amer. Control Conf.}, Chicago, IL, USA,
% 2000, pp. 2245--2249.

% \end{thebibliography}


\newpage

%\section{Biography Section}
% If you have an EPS/PDF photo (graphicx package needed), extra braces are
%  needed around the contents of the optional argument to biography to prevent
%  the LaTeX parser from getting confused when it sees the complicated
%  $\backslash${\tt{includegraphics}} command within an optional argument. (You can create
%  your own custom macro containing the $\backslash${\tt{includegraphics}} command to make things
%  simpler here.)

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/Zan Zhou.jpg}}]{Zan Zhou} received his Ph.D. degree in Computer Science from the Beijing University of Posts and Telecommunications (BUPT) in 2022. 
From 2021 to 2022, he was a visiting student at Nanyang Technology University (NTU), Singapore. 
He is currently a Postdoc researcher with the State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, China. His research interests include data privacy, active defense, and federated learning. %He is Student member of IEEE.
\end{IEEEbiography}

\vspace{11pt}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/changqiao xu.jpg}}]{Changqiao Xu}
(Senior Member, IEEE) received the Ph.D. degree from the Institute of Software, Chinese Academy of Sciences (ISCAS) in Jan. 2009. He was a researcher at Athlone Institute of Technology and Joint Training PhD at Dublin City University, Ireland during 2007-2009. %He joined BUPT in Dec. 2009. 
Currently, he is a Professor with the State Key Laboratory of Networking and Switching Technology, and Director of the Network Architecture Research Center at BUPT. His research interests include Network Security, Mobile Networking, Multimedia Communications, and Future Internet Technology. He has edited two books and published over 200 technical papers in prestigious international journals and conferences, including IEEE Comm. Magazine, IEEE/ACM ToN, IEEE TMC, INFOCOM, ACM Multimedia, etc. He has served a number of international conferences and workshops as a Co-Chair and TPC member. He is currently serving as the Editor-in-Chief of Transactions on Emerging Telecommunications Technologies (Wiley).
\end{IEEEbiography}

\vspace{11pt}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/bowang.jpg}}]{Bo Wang} received his B.E. degree from the School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China, in 2023. He is currently pursuing the Ph.D. degree at the same institution. His major research interests include network security and artificial intelligence.
\end{IEEEbiography}

\vspace{11pt}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/tengfeili.jpg}}]{Tengfei Li} received his B.E. degree from Beijing University of Chemical Technology, Beijing, China, in 2023. He is currently pursuing the M.E. degree at the School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China. His major research interests include network security and artificial intelligence.
\end{IEEEbiography}

\vspace{11pt}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/Sizhe Huang.jpg}}]{Sizhe Huang} is currently pursuing a Bachelor's degree in the School of Computer Science, BUPT. He is also a research assistant with the State Key Laboratory of Networking and Switching Technology, BUPT. His research interests include network security and active defense.  
\end{IEEEbiography}

\vspace{11pt}



\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photos/Shujie Yang.jpg}}]{Shujie Yang} received the Ph.D. degree from the Institute of Network Technology, Beijing University of Posts and Telecommunications, Beijing, China, in 2017. He is currently a lecturer with the State Key Laboratory of Networking and Switching Technology. His major research interests include network security and artificial intelligence.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, clip,keepaspectratio]{photos/Su Yao.jpg}}]{Su Yao} received the Ph.D. degree from the National Engineering Laboratory for Next Generation Internet Interconnection Devices, Beijing Jiaotong University. Currently, he is with the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, as an Assistant Research Fellow. His research interests include future network architecture, IoT security, and artificial intelligence for network systems.
\end{IEEEbiography}

% \bf{If you include a photo:}\vspace{-33pt}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig1}}]{Michael Shell}
% Use $\backslash${\tt{begin\{IEEEbiography\}}} and then for the 1st argument use $\backslash${\tt{includegraphics}} to declare and link the author photo.
% Use the author name as the 3rd argument followed by the biography text.
% \end{IEEEbiography}

% \vspace{11pt}

% \bf{If you will not include a photo:}\vspace{-33pt}
% \begin{IEEEbiographynophoto}{John Doe}
% Use $\backslash${\tt{begin\{IEEEbiographynophoto\}}} and the author name as the argument followed by the biography text.
% \end{IEEEbiographynophoto}



\vfill

% \newpage
% \onecolumn
% \begin{longtable}{|c|p{3cm}|c|p{12cm}|} 
%     \caption{This is the caption for the long table}
%     \label{tabl:attack} \\ \hline
%     Title & Conference & Year & Main Content \\ \hline
%     \endfirsthead \hline
%     Title & Conference & Year & Main Content \\ \hline 
%     \endhead \hline
%    \cite{jha2023label} & neurips & 2023 &  本文提出了一种新颖的标签投毒攻击方法，称为FLIP。与传统的后门攻击不同，FLIP仅通过修改训练数据的标签即可实现对模型的控制，而无需更改图像本身。这种方法特别适用于当训练标签可能来自潜在恶意的第三方（如众包标注或知识蒸馏）的场景。本文通过实验展示了FLIP在多个数据集和模型架构上的高效性，证明了在仅污染少量标签的情况下，FLIP能够显著影响模型的预测结果。 \\ \hline
%    \cite{yang2023data} & International Conference on Machine Learning & 2023 & 本文首次研究了针对多模态模型的投毒攻击，包括视觉和语言两种模态。研究的主要问题是：（1）语言模态是否也容易受到投毒攻击？（2）哪种模态更易受攻击？本文提出了三种针对多模态模型的投毒攻击，并通过在不同数据集和模型架构上的广泛评估，表明这些攻击可以在保持模型实用性的同时实现显著的攻击效果。为缓解这些攻击，本文还提出了预训练和后训练的防御措施，并证明这些防御措施能够显著降低攻击效果，同时保持模型的效用。\\ \hline
%    \cite{dai2023chameleon} & International Conference on Machine Learning & 2023 & 这篇文章的主要贡献在于提出了Chameleon攻击方法，这是一种通过利用正常图像与被污染图像之间的关系，来增强后门在联邦学习（FL）系统中持久性的策略。通过对比学习调整图像嵌入距离，Chameleon成功延长了后门的存续时间，使其在多种数据集、后门类型和模型架构下的耐久性提高了1.2至4倍，显著优于现有方法。 \\ \hline
%    \cite{gu2023gradient} & ACL & 2023 & 这篇文章提出了一种新的梯度控制方法，旨在解决参数高效调优（PET）过程中后门攻击的遗忘问题。通过将后门注入过程视为多任务学习，文章引入了跨层梯度幅度归一化和层内梯度方向投影两种策略，以减少不同任务之间的梯度冲突和梯度大小的不平衡，从而增强后门攻击在用户微调模型后的效果。实验结果表明，该方法在情感分类和垃圾邮件检测任务中显著提高了后门攻击的持久性和有效性。 \\ \hline
%    \cite{zhang2024a3fl} & neurips & 2024 & 这篇文章的主要贡献是提出了一种新的后门攻击方法A3FL，它通过对抗性自适应策略优化后门触发器，使其在联邦学习的全局训练动态中更持久、更难被检测到。与现有方法相比，A3FL显著提高了攻击的成功率和隐蔽性，并在多种防御机制下展现了出色的效果，揭示了现有防御方法的不足，强调了开发新防御策略的必要性。\\ \hline
%    \cite{xu2024shadowcast} & arxiv  & 2024 & 这篇文章主要介绍了一种针对视觉语言模型（VLMs）的隐蔽数据投毒攻击方法，称为Shadowcast。该方法通过向模型的训练数据中注入视觉上与正常图像几乎无法区分的投毒样本，从而误导模型在推理时生成错误或误导性的信息。文章探讨了两种攻击类型：标签攻击（Label Attack）和说服攻击（Persuasion Attack），前者旨在让模型错误识别图像类别，而后者通过生成具有说服力但错误的文本，改变用户对图像的认知。实验结果表明，Shadowcast攻击在多种VLM架构下都非常有效，且在不同的提示词和数据增强条件下依然保持攻击效果。\\ \hline
%    \cite{liang2024badclip} & CVPR & 2024 & 这篇文章提出了一种针对多模态对比学习模型（如CLIP）的双嵌入引导后门攻击方法，称为BadCLIP。BadCLIP通过优化视觉触发模式，使其在嵌入空间中接近目标文本语义，从而在不显著改变模型参数的情况下，植入难以被检测到的后门。此外，该方法通过对抗性训练，增强了中毒样本的视觉特征，使得后门在模型经过清洁数据微调后仍能保持有效。实验结果显示，BadCLIP在多种防御机制下都表现出显著的攻击成功率，展示了其对现有防御方法的强大威胁。\\ \hline

    
%    \cite{attack01} & arXiv preprint & 2024 & 本篇文章次揭示了在联邦学习环境下对大语言模型（LLM）进行指令调优时存在的安全漏洞。文章提出了一种简洁但有效的安全攻击方法，恶意客户端通过使用未对齐的数据来训练本地模型，从而大幅度削弱了全球模型的安全对齐性（“未对齐的数据”，是指那些与预期的安全或伦理规范不一致的数据。例如，未对齐的数据可能包含有害的、误导性的或是不道德的信息，而这些信息在普通情况下不会被用于训练模型）。实验表明，该攻击方法能够将模型的安全性降低高达70\%，而现有的防御方法在应对此类攻击时几乎无效，仅能提高4\%的安全性。为了解决这一问题，作者进一步提出了一种新的事后防御方法，即通过服务器端生成对齐数据并进一步对全局模型进行微调，从而增强模型的安全性（中央服务器在接收到各个客户端的更新后，会主动生成一组对齐的数据。这些对齐的数据是预先定义好的，确保与预期的安全和伦理规范一致。这些数据可能包含严格筛选过的内容，如道德上中立或积极的文本片段）。实验结果显示，这种防御方法能够将模型的安全性提高最多69\%，且不显著降低模型的有效性。（这篇看完了发现不是视觉大模型） \\ \hline
%    \cite{attack02} & arXiv preprint & 2024 & 本篇文章探讨了一种针对大语言模型（LLMs）的新型训练方法，称为目标潜在对抗性训练（Targeted Latent Adversarial Training, LAT），文章提出了通过在模型的潜在表示（latent representations）中引入针对性的扰动，来更有效地消除模型中顽固的不良行为（如后门攻击和模型“越狱”）。(潜在表示是指在神经网络的中间层中，数据通过多层非线性变换后所形成的特征表示。这些表示通常处于更高的抽象层次，与原始输入相比，能够捕捉到数据的深层次特征。在视觉大模型中，这些潜在表示可能包括图像的边缘、形状、纹理等更抽象的特征，而不再是具体的像素值。潜在表示在模型中扮演着至关重要的角色，因为它们是模型用来进行预测和决策的核心特征。)(针对性的扰动是指在训练或评估过程中，特意对模型的输入或潜在表示进行细微的修改或扰动，以诱导模型产生特定的（通常是不希望的）行为。通过这种方法，可以测试和增强模型在面对各种攻击时的鲁棒性。在本文中，作者使用潜在空间中的针对性扰动来模拟攻击，目的是强化模型的防御能力，使其能够抵抗类似的实际攻击，如后门攻击或越狱行为。)研究表明，与传统的对抗性训练相比，目标潜在对抗性训练可以显著提高模型抵抗这些攻击的能力，同时对模型的整体性能影响较小。文章通过实验验证了该方法在增强模型鲁棒性方面的有效性，尤其是在面对未知触发条件的后门攻击时，表现出色。  \\ \hline
%    \cite{attack03} & arXiv preprint & 2024 & 本文探讨了开放权重大语言模型（LLMs）在面对篡改攻击时的脆弱性，并提出了一种名为TAR（Tampering Attack Resistance）的方法，旨在增强这些模型的抗篡改能力。文章指出，现有的安全防护措施，如拒绝机制和偏好训练，容易在少量微调步骤后被攻击者绕过，导致模型被恶意修改。为此，TAR方法通过对抗性训练和元学习，设计了一种新的防护机制，使得即使在经历数千步的微调攻击后，模型仍能保持其原有的安全防护功能。实验结果显示，与现有方法相比，TAR显著提高了模型的抗篡改能力，同时保留了模型的正常功能。研究还通过大量红队评估验证了TAR方法的有效性，展示了其在应对各种复杂攻击时的鲁棒性。(红队评估是一种在网络安全和机器学习领域常用的测试方法，它通过模拟攻击者的行为来评估系统或模型的安全性和防御能力。红队通常扮演“敌方”角色，主动寻找和利用系统的漏洞，以测试系统在真实攻击场景下的表现。这种方法帮助识别和修复安全漏洞，使系统在面对潜在的实际攻击时更加稳健。这篇文章中研究人员通过设计多个测试对手，这些对手模拟了各种可能的攻击策略，试图篡改或破坏大语言模型的功能。文章中提到进行了28个不同的红队评估测试，每个测试都旨在突破TAR的防护机制。)文章中的攻击方式涉及通过微调大语言模型的权重来篡改其行为。攻击者可以在模型的开放权重上进行少量微调，使其在特定情况下产生不希望的输出。例如，攻击者可能会在输入特定触发词时，让模型生成有害内容或偏离其正常功能。\\ \hline
%    \cite{attack04} & arXiv preprint & 2024 & 这是一篇综述。本文主要介绍了以下攻击方式：\begin{itemize}
%     \item 对抗性攻击：通过对输入数据进行微小的扰动，这些扰动虽然对人类几乎不可见，但会导致模型产生显著错误的输出，例如在图像分类中，可能会使模型将一个正常的图像误分类为完全不同的类别；
%     \item 后门攻击：和之前咱做的一样；
%     \item 数据中毒攻击：攻击者向模型的训练数据中注入恶意样本，这些样本会导致模型在遇到类似数据时输出错误结果，例如在物体识别任务中，中毒数据可能会导致模型误将无害物体识别为威胁；
%     \item 模型逃逸：攻击者通过调整输入或模型参数，试图找到绕过模型防御机制的方法，使模型输出不受控制的内容，这种攻击常用于测试模型的防御效果；
%     \item 多模态攻击：针对处理多种类型输入（如文本和图像）的模型，攻击者通过操纵一种模态的输入来影响另一种模态的输出，例如在多模态对话系统中，通过改变图像输入可能会影响系统的文本回应；
%     \item 跨语言攻击：在多语言任务中，攻击者通过在一种语言中引入扰动来影响模型在另一种语言中的表现，这类攻击特别针对多语言翻译或生成模型，可能导致不同语言间的翻译不准确或失真。
%     \end{itemize}\\ \hline
%    \cite{attack05} &  Advances in Neural Information Processing Systems 34 (NeurIPS 2021) & 2021 & 本篇文章讨了如何保护通过“彩票假设”（Lottery Ticket Hypothesis, LTH）找到的稀疏子网络（即“中奖票”）的所有权。文章提出了一种新的基于稀疏结构信息的验证方法，通过在网络的稀疏结构中嵌入签名来进行所有权验证。这种方法能够在白盒和黑盒场景下保护模型的知识产权，并且对细微调整（如微调和剪枝）具有很强的鲁棒性。研究还通过大量实验验证了该方法在多种模型（如ResNet-20、ResNet-18、ResNet-50）和数据集（如CIFAR-10和CIFAR-100）上的有效性，展示了其在应对移除攻击和模糊攻击时的坚韧性。具体攻击方式有：细微调整（Fine-tuning）攻击：对模型进行微调来改变模型的权重值，同时希望不改变网络的稀疏结构。这种攻击旨在通过调整权重，试图使嵌入的签名信息变得不可辨认或无效。然而，由于嵌入的信息是基于网络的稀疏结构（即被剪枝后的模型结构），细微调整难以改变这一基础结构，从而无法有效移除签名。剪枝（Pruning）攻击：攻击者尝试通过进一步剪枝来移除嵌入的签名信息。这种攻击的目的是通过减少模型的非零参数，使得嵌入的结构信息丢失。然而，文章中提出的嵌入方法确保了签名信息在极端稀疏的情况下仍能保留，即使剪枝比例达到一定程度，签名依然可以从稀疏结构中提取出来。模糊攻击（Ambiguity Attacks）：攻击者试图通过制造伪签名或模糊原有签名的信息来混淆所有权验证。这种攻击可能包括添加噪声、篡改稀疏结构等手段，旨在使得验证机制无法区分真实的所有权签名和伪造的信息。然而，文章中的验证方法通过设计稳健的结构嵌入机制，使得这种模糊攻击难以成功。(“签名”指的是嵌入到神经网络稀疏结构中的一种独特的标识信息。这种签名通过在模型的剪枝过程中，利用网络的稀疏性来实现。具体而言，当模型被剪枝后，一部分神经元和连接被移除，剩余的结构会呈现出一种特定的稀疏模式。作者通过在这种稀疏模式中嵌入一个特定的结构或模式，这个模式就是所谓的“签名”。这种签名是不可见的，但可以通过特定的验证过程来提取和识别。其主要功能是为网络的所有权提供证据，类似于给模型打上了一个“水印”。当有人试图非法复制或篡改模型时，这个嵌入的签名仍然可以被识别出来，从而验证模型的归属。签名的鲁棒性设计使其能够抵抗常见的攻击方式（如微调和进一步的剪枝），即使模型经历了这些操作，签名依然可以从其稀疏结构中被提取出来，证明模型的所有权。)(模型的所有权是指对一个机器学习模型（如神经网络模型）所拥有的法律和知识产权。所有权通常由开发者或公司拥有，表示他们对模型的设计、训练数据、训练方法以及最终生成的模型参数等有控制权和排他性使用权。这意味着只有模型的所有者有权利决定如何使用、修改、发布或授权使用该模型。（可能涉及到知识产权保护、商业机密的保密）)\\ \hline
%    \cite{attack06} & Portail HAL theses(theses.hal.science) & 2022 & 这篇文章有185页。本篇文章讨论了如何通过数字水印技术来保护机器学习模型的知识产权，防止模型被盗用。文章首先提供了当前水印技术的概述，并进一步扩展了这些技术在图像分类任务之外的应用，涵盖了回归、机器翻译和强化学习模型。作者还提出了针对模型托管平台的伪造攻击（即试图通过伪造水印来绕过验证）并介绍了一种基于公平性的水印技术，以增强模型在黑盒环境中的安全性。实验结果表明，这些水印技术不仅可以有效防止模型盗用，还能够在面对各种攻击时保持鲁棒性。
%    数字水印是一种嵌入信息的技术，用于在数字内容（如图像、音频、视频或机器学习模型）中隐藏特定的信息，以表明所有权或版权。对于机器学习模型来说，数字水印是一种通过特定算法将标识信息嵌入到模型的权重、结构或输出中的技术。这种标识信息通常是不可见或难以察觉的，但可以通过特定的提取过程来验证。（数字水印的目的有：知识产权保护：开发者可以通过在模型中嵌入水印来证明模型的所有权，防止未经授权的复制和使用；盗版检测：如果一个模型被盗用或未经许可发布，水印可以作为证据，证明模型的来源和合法所有者；内容跟踪：水印可以帮助追踪模型的使用情况，尤其是在多个平台或用户之间共享时，确保模型的使用符合许可协议。） \\ \hline
%     % \endfoot
%     % \hline
%     % \endlastfoot
%     % \hline
% \end{longtable}

% \begin{figure}[!t]
% \centering
% \includegraphics[width=\linewidth]{figures/fig4-history.jpg}
% \caption{Combining multiple rounds of historical identification to identify malicious nodes
% }
% \label{fig4:history}
% \end{figure}


% \begin{figure}[!t]
% \centering
% \includegraphics[width=\linewidth]{img/SecFFT-场景.pdf}
% \caption{Combining multiple rounds of historical identification to identify malicious nodes
% }
% \label{fig4:history}
% \end{figure}


% \begin{figure}[!t]
% \centering
% \includegraphics[width=\linewidth]{img/SecFFT-算法1.pdf}
% \caption{Combining multiple rounds of historical identification to identify malicious nodes
% }
% \label{fig4:history}
% \end{figure}

\end{document}
