% !TeX encoding = UTF-8
\documentclass[a4paper,twoside,11pt,dvipsnames]{reviewresponse}
\usepackage{subcaption}
% 1. Load and set up proper language packages
\usepackage{amsbsy,amssymb,epsfig,bbm,mathrsfs,multirow,amsthm}
\usepackage{algorithm,algpseudocode}
\usepackage{amsmath}
\usepackage{graphicx}
% \usepackage[english]{babel}
\usepackage{mathtools,xparse}
\usepackage{array, multirow, graphicx}
\usepackage{graphicx}
\usepackage{graphics}
% \usepackage{subfigure}
\usepackage{epstopdf}
\usepackage{color}
\usepackage{natbib}
\setcitestyle{numbers,square}
\usepackage{bbm}
\usepackage{comment}
\usepackage{makecell}
\usepackage{xcolor}

\usepackage{listings}

% \usepackage{multirow}
% \usepackage{amsmath}

\usepackage{mathtools}

\usepackage{caption}
%\usepackage{vntex} 
%\usepackage[vietnamese]{babel}
%\usepackage[utf8]{vietnam}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newcommand{\clU}{{\cal U}}
\newcommand{\clI}{{\mathbf I}}
\newcommand{\clD}{{\cal D}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\bo}{\boldsymbol{\omega}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bz}{\mathbf{q}}
\newcommand{\rw}{\rm{w}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bp}{\mathbf{p}_i}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\clS}{{\cal S}}
\newcommand{\ds}{\displaystyle}
\newcommand{\pik}{p_i^{(\kappa)}}
\newcommand{\pjk}{p_j^{(\kappa)}}
\newcommand{\rhok}{\rho^{(\kappa)}}
\newcommand{\bpk}{\mathbf{p}_i^{(\kappa)}}
\newtheorem{assumption}{Assumption}[section]

\newtheorem{Definition}{\hskip 0pt Definition}%[section]
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{\textbf{\textsc{Theorem}}}
\newtheorem{mypro}{Proposition}
\hyphenation{lists}


\graphicspath{ {./figures/} }

% 2. Complete the paper data
\newcommand{\myAuthors}{{Tran The Anh$^{\displaystyle 1}$, ~Nguyen Cong Luong$^{\displaystyle 2}$, } \\ {~Dusit Niyato$^{\displaystyle 2}$}}
\newcommand{\myAuthorsShort}{The Anh.~Tran et. al}
\newcommand{\myEmail}{theanh.tran@ntu.edu.sg}
\newcommand{\myTitle}{A Deep Reinforcement Learning Approach for Backscatter-Assisted Relay Communications}
\newcommand{\myShortTitle}{}
 \newcommand{\myJournal}{}
\newcommand{\myDept}{{$^{\displaystyle 1}$School of Computer Science and Engineering, Nanyang Technological University, Singapore. \\ \url{}}\\
{$^{\displaystyle 2}$School of Computer Science and Engineering, Nanyang Technological University. }\\}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[linktoc=all,bookmarks,bookmarksopen=true,bookmarksnumbered=true]{hyperref}

\hypersetup{
pdfauthor = {\myAuthorsShort},
pdftitle = {\myTitle},
pdfsubject = {\myJournal\xspace},
colorlinks = true,
linkcolor=black!70!green, 
citecolor=black!70!green,       
filecolor=magenta,      
urlcolor=black!70!black           
}

\begin{document}


\thispagestyle{plain}


 {\Large We would like to thank the editor for the time and effort to gather insightful reviews for our submission to IEEE Transactions on Network Science and Engineering (TNSESI-2023-01-0074: \textit{Combating ``Drug Resistance" of Intelligent Attack: Hierarchical Network Traffic Moving Target Defense with Endogenous Security Enhancement}). In response to the comments from the Editor and the reviewers, we have revised the paper extensively. We also would like to thank the Editor and the reviewers for the valuable and constructive comments that help us improve the quality of the paper significantly. The followings are the detailed answers to the comments. %It is also noted that, we add the letter ` `R'' (i.e., Response) before the reference number of references which are added in this response, e.g., ``[R1]'', and ``[R2]''. This is to distinguish references in this response letter and those in the revised paper.
 It is also noted that, as the whole manuscript has undergone substantial and comprehensive revisions, to facilitate clarity for the reviewers, we have marked the newly added or completely rewritten parts in {\color{blue}blue\color{black}} within the revised manuscript. The remaining sections, where only language and expression changes have been made, are still presented in black text.
 }

%\end{abstract}

\newpage

%=================================
%=================================
\section{Summary of changes}
Based on the valuable feedback from the reviewers, we have made significant improvements to the manuscript in the following areas:
\color{red}
\begin{itemize}

% 根据Reviewer 1's Comment 1，Comment 2以及Reviewer 2's Comment 1，我们修改了文章的部分公式以及重新构建了符号表，使文章的公式符号的意义更加清晰，优化阅读体验。
\item \textbf{[Writing and expression:]} Based on \textbf{Reviewer 1's Comment 1, Comment 2}, and \textbf{Reviewer 2's Comment 1}, we have revised some of the formulas in the paper and reconstructed the symbol table to make the meanings of the formula symbols clearer and to enhance the overall reading experience.

% 根据Reviewer 1's Comment 3，我们对Threat models部分的基本假设做了进一步的假设，使得本文提出的概念更便于理解。
\item \textbf{[Threat Models:]} Based on \textbf{Reviewer 1's Comment 3}, we made further assumptions in the \textbf{Threat Models} section regarding the basic assumptions, making the concepts proposed in this paper easier to understand.

% 根据Reviewer 1's Comment 4，我们增加了额外的实验来说明了采样大小和模型准确率之间的关系。   

% 根据Reviewer 1's Comment 5, 我们对DUPLEX PRIVACY AMPLIFICATION的auxiliary downlink privacy obfuscation部分做了修改，澄清了“社区导向框架”与"异质性情景下提高效率的意义“”之间联系。
\item \textbf{[Duplex privacy amplification:]} Based on \textbf{Reviewer 1's Comment 5}, we revised the \textbf{Auxiliary downlink privacy obfuscation} section of \textbf{Duplex privacy amplification}, clarifying the connection between the \textbf{community-oriented framework} and the \textbf{significance of improving efficiency in heterogeneous scenarios}.


% 根据Reviewer 2's Comment 2，
\item \textbf{[Credit-based active poisoning resistance:]} Based on \textbf{Reviewer 2's Comment 5}, we supplemented the consideration of resource consumption by adding an analysis of communication efficiency and computational time complexity.


% 根据Reviewer 2's Comment 3，我们对experimental Environment部分进行了相应的修改，解释了实验部分针对不同数据集选择对应模型结构和超参数的原因。根据Reviewer 2's Comment 4， 我们在实验结果描述部分添加了对CIFAR-100的实验结果以及相应的分析。
\item \textbf{[Performance evaluation:]} Based on \textbf{Reviewer 2's Comment 3}, we made corresponding revisions to the \textbf{Experimental environment} section of \textbf{Performance evaluation}, explaining the rationale behind selecting the appropriate model structures and hyperparameters for different datasets in the experiments. Additionally, in response to \textbf{Reviewer 2's Comment 4}, we added the experimental results for CIFAR-100, along with the corresponding analysis, to the experimental results description section. Furthermore, in response to \textbf{Reviewer 1's Comment 4}, We conducted additional experiments to illustrate the relationship between sample size and model accuracy.

\end{itemize}

\color{black}
The detailed responses to the comments are as follows. Thank you very much for your time again.

\newpage

%=================================
\section{Responses to the Comments from Reviewer 3}
%=================================
%=================================
%========================================================
\rcomment{
\color{red} The technical framework lacks sufficient explanatory detail. For example, the steps in Fig. 2 are explained too briefly, making them difficult to understand.
}
% 问题：技术框架解释性不足，比如Fig2步骤解释过于粗略，难以理解。
\textbf{Response:} 
We thanks the Reviewer for the comment.




%========================================================
\rcomment{
\color{red} There are several errors and linguistic issues throughout the paper. For instance, on page 5, at the end of the second paragraph, citation [36] is repeated consecutively. Please carefully review and correct these issues.
}
% 问题：文中存在部分错误和语病，如在P5页第二段末尾，引用[36]连续重复出现，请认真检查
\textbf{Response:} Thank you for your valuable feedback on our paper. We greatly appreciate the time and effort you have taken to review our work.

Regarding the issue of errors and linguistic problems throughout the paper, especially the repeated citation [36] at the end of the second paragraph on page 5, we have carefully reviewed the entire manuscript and made the necessary corrections. The repeated citation has been removed, and we have conducted a thorough proofreading process to address any other linguistic issues that may have affected the clarity and quality of the paper.
% 对存在的这类问题，我们深表歉意。我们已经删除了该处存在的重复引用的问题，同时，我们也修改了本文其他地方存在的表述不清或者语法错误等问题。以下为详细的修改内容：

The following are the detailed modifications:

\textcolor{blue}{
To address the limitations faced by defense methods based on shallow semantic features in high-dimensional spaces, we propose a new defense strategy rooted in the essence of backdoor attacks [34], which leverages deep semantic features by focusing on the differences in model updates in the frequency domain. According to our experimental results, by transforming local model updates into the frequency domain, we can more accurately capture the abnormal behavior of malicious updates which is typically difficult to detect using traditional shallow feature-based defenses in low-frequency components. By analyzing the relevant features in the frequency domain, we can effectively distinguish between malicious and benign nodes, thereby enhancing the robustness and accuracy of federated learning in the face of sophisticated backdoor attacks.
}

\textcolor{blue}{......}

\textcolor{blue}{
Due to the curse of dimensionality in high-dimensional spaces, traditional methods based on shallow semantic
feature can no longer effectively identify malicious nodes. In contrast, once model updates are transformed into the frequency domain, their differences are primarily concentrated in the low-frequency components. Focusing on the analysis of these low-frequency components not only improves identification accuracy but also significantly reduces computational overhead. For each update \(\triangledown \theta_i^t\), we apply one-dimensional DCT-II[35] to obtain its corresponding frequency distribution. Then we extract $m$ low-frequency components[36], such as 5000, yielding the low-frequency vector $G_i^t$.
}






%========================================================
\rcomment{
\color{red} In Algorithm 1, there are unused variables in line 5.
}
% 问题：算法1第5行出现未使用变量。

\textbf{Response:} We thank the Reviewer for the constructive comment, and
% 非常抱歉，因为我们的疏忽，导致该算法出现让人无法理解的地方。根据您的建议，我们修改了该算法的相关部分，删除了未使用的变量。同时为了使整个算法过程更易理解，我们修改了另外一些跟原文不一致的地方，\ref{alg:malicious-node-detection}展示了修改后的结果。
we sincerely apologize for the confusion caused by the oversight in our algorithm.
Following your suggestion, we revised the relevant parts of the algorithm and removed unused variables.
Additionally, to make the entire algorithm process easier to understand, we adjusted some parts that were inconsistent with the original text, and algorithm \ref{alg:malicious-node-detection} shows the modified result.
% 最后，为了表现算法中某些变量会随训练轮次所变化，我们给一些变量添加时间$t$的上标，比如修改$C_{max},Chi_i^2,{C_1}', {C_2}'$至$C^t_{max},{Chi^t_i}^2,{C^t_1}', {C^t_2}'$
Finally, to represent that certain variables in the algorithm change with the training rounds, we added the superscript of round $t$ to some variables, such as modifying $C_{max}, Chi_i^2, {C'_1}, {C'_2}$ to $C^t_{max}, {Chi^t_i}^2, {C^t_1}', {C^t_2}'$.

% 图1展示了算法修改后的结果
The Algorithm \ref{alg:malicious-node-detection} shows the result of the modified algorithm.


\begin{algorithm}
\caption{Instantaneous Attack Behavior Perception}
\label{alg:malicious-node-detection}
\begin{algorithmic}[1]
\State \textbf{Input:} $d$, $N$, $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$, $m$ \Comment{$d$ is the dimension of each update; $N$ is the number of nodes participating during each round; $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$ is the local updates from robot nodes during the $t$-th round; $m$ is the length of low-frequency components}
\State \textbf{Output:} $U_{nor}$, $U_{mal}$ \Comment{benign nodes, malicious nodes}
\State{\color{CadetBlue}/* \textbf{Frequency Domain Transformation */}} 
% \State Step 1: Frequency Domain Transformation
\For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
    \State \textcolor{blue}{$G_i^t \gets Trunc(DCT(Flatten(\triangledown \theta_i^t))), m)$}
\EndFor

% \State
\State{\color{CadetBlue}/* \textbf{Clean Ingredient Extraction */}} 
% \State Step 2: Clean Ingredient Extraction
\State $(C_0^t, C_1^t, \ldots, C_{\kappa}^t) \gets Clustering\textcolor{blue}{ (G_0^t, G_1^t, \ldots, G_N^t)}$ \Comment{$\kappa$ denotes the number of clusters}
\State \textcolor{blue}{$ C^t_{max} \gets \underset{C^t_j}{\arg\max} \, |C^t_j|$ \Comment{$|C^t_j|$ denotes the number of nodes in cluster $C^t_j$, $j = 1, 2, \ldots, \kappa $}}
\State $H^t \gets (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n} $ \Comment{Stacking to form Matrix $H^t$, where $R_{i_0}, R_{i_1}, \ldots, R_{i_n} \in C^t_{max}$.}

\State $\hat{H}^t \gets (H^t)^{T} H^t$
\State $\lambda_{max}^t, \xi_{max}^t \gets eig(\hat{H}^t)$ \Comment{Calculating the maximum singular value and its corresponding eigenvector}
\State $\tilde{G}^t \gets \frac{H^t \xi_{max}^t}{\sqrt{\lambda_{max}^t}}$ \Comment{The clean ingredient}

% \State
\State{\color{CadetBlue}/* \textbf{Chi-square distance calculation */}} 
% \State Step 3: Chi-square distance calculation
% \State $P_i^t \gets Softmax(G_i^t), \, Q^t \gets Softmax(\tilde{G}^t)$
\For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
    \State $Chi^t_i \gets \sqrt{\sum_{k=0}^{m-1}\frac{(G_i^t[k] - {\tilde G}^t[k])^2}{{\tilde G}^t[k] + \epsilon}}$
\EndFor
\State \textcolor{blue}{$S^t \gets \{Chi^t_1, Chi^t_2, \ldots, Chi^t_N\}$} \Comment{The Distance differences calculated by Chi-square distance.}

% \State
\State{\color{CadetBlue}/* \textbf{Single-round malicious behavior perception */}} 
% \State Step 4: Single-round malicious behavior perception
\State $\textcolor{blue}{\{{C^t_1}', {C^t_2}'\}} \gets KMeans(S^t, 2)$ \Comment{Cluster $S$ into 2 clusters using KMeans.}
\State \textcolor{blue}{$U_{nor} \gets C'_{max}$, $U_{mal} \gets \{C'_i \, | \, i \neq max\}$}

\end{algorithmic}
\end{algorithm}

%========================================================
\rcomment{
\color{red} Section 4 uses various metrics to demonstrate the improved defense performance of the proposed method against different types of attacks. However, there is insufficient explanation of the origin and calculation methods for these metrics, which makes it hard for readers to follow. It is recommended to add a brief explanation.
}
% 问题：实验数据大小的代表性引起了关注。应阐明所选值背后的基本原理，以加强实验结果的有效性和可靠性。（就是说实验设置为啥这样选，比如超参数啥的，需要说明道理，不然的话是不合理的）
% 回复：确实应该写一段话描述一下这些指标都是什么意思。
% 感谢你的建议，在实验四的部分，我们使用了ACC、Rec、FPR、FNR、AUC、MCC等指标作为我们方法的有效性验证依据。虽然这些指标是这些类似实验中常见的指标，但是为了论文的普适性以及为了方便更多读者的理解，还是应该简要介绍一下这些指标的含义。因此我们新增了一些描述，用来简要介绍这些指标的含义。 我们增加了如下的简单描述：

% 这些指标用于评估模型性能。“Acc”表示准确率，衡量预测正确的比例；“Rec”是召回率，表示模型正确识别正例的能力；“FPR”是假阳性率，指错误将负例预测为正例的比例；“FNR”是假阴性率，指错误将正例预测为负例的比例；“AUC”是曲线下面积，表示模型区分正负例的整体能力；“MCC”是马修斯相关系数，综合评估模型预测结果的平衡性。

\textbf{Response:} Thank you for your suggestion. In Section 4 of our experiments, we used metrics such as ACC, Rec, FPR, FNR, AUC, and MCC as the basis for validating the effectiveness of our method. Although these metrics are commonly used in similar experiments, for the sake of the paper's generality and to facilitate understanding for a broader audience, we believe it is necessary to briefly introduce the meaning of these metrics. Therefore, we have added some descriptions to provide a concise explanation of these metrics. The added description is as follows:

\textcolor{blue}{
"Acc" refers to accuracy, which measures the proportion of correct predictions; "Rec" stands for recall, representing the model's ability to correctly identify positive instances; "FPR" denotes the false positive rate, indicating the proportion of negative instances incorrectly predicted as positive; "FNR" refers to the false negative rate, which represents the proportion of positive instances incorrectly predicted as negative; "AUC" stands for the area under the curve, reflecting the model's overall ability to distinguish between positive and negative instances; and "MCC" represents the Matthews correlation coefficient, which provides a balanced evaluation of the model's predictions.
}
%========================================================
% 表格2的内容太长，超出了双栏的空间了，建议重新进行调整规划
\rcomment{
\color{red} The content in Table 2 is too long and exceeds the space available for a two-column layout. Please revise and reformat accordingly.
}

% 我将每次给你一个审稿意见，请你对于该审稿意见写一个回复（回复要包括中文版本和英文版本）。回复要展现自己良好的态度，越详细越好。
% 你了解司法人工智能吗？请解释之。

% 谢谢你的建议，表格2的宽度确实有些过长，已经超出了半栏的范围，甚至已经与右侧栏目的内容产生了融合。我们对这个表格进行了调整，适当缩小了表格的宽度，使得表格在不影响整体观感的同时，保证了表格格式符合要求，且不超过单栏范围。

Thank you for your suggestion. The width of Table 2 is indeed somewhat excessive, exceeding the single-column limit and even merging with the content in the adjacent column. We have made adjustments to the table, reducing its width appropriately to ensure that the table fits within the required format while maintaining the overall visual quality without exceeding the single-column range.

\newpage
%=================================
%=================================
% 我给你一些审稿意见，请你按照格式返回latex源码：

% ```
% \section{Responses to the Comments from Reviewer 2}

% % comment6
% \rcomment{
% \color{red} 审稿意见6
% }

% Thank you for your suggestion. 

% % comment7
% %...

% \newpage
% ```
\section{Responses to the Comments from Reviewer 1}

% comment6
\rcomment{
\color{red} The text in some experimental result figures is too small to be legible. Improving the clarity and resolution is recommended.
}

Thank you for your suggestion.
% 待定

% comment7
\rcomment{
\color{red} Figure 3 is not cited in the manuscript. It is suggested to reference and explain the figure in the relevant section, as its absence hinders understanding.
}

% 感谢你指出这一点，我们的图3对应\ref{\section{Methodology}}部分的B部分的2)，我们只将图片放在了对应的文字介绍部分，但是并未对图片内容进行描述，甚至没有在文章中引用这段文字。现在，我们
% 系统中断：先写合同去了
% Log：昨天早上去答辩，在外面等待的时候背了会儿单词，B同学看我在看手机就说是不是在和兔米尼聊天，我说早上已经聊过了[害羞]，然后他“诶(撇嘴[撇嘴])”
% 第二次是他说飞哥衣服好帅，然后我说对象送的[害羞]
Thank you for pointing this out.

% comment8
\rcomment{
\color{red} The steps in the final paragraph of Section 5 do not align with Algorithm 2. Please revise for consistency.
}

Thank you for your suggestion.

% comment9
\rcomment{
\color{red} Some conditions in Algorithm 2 are unclear, such as "for Client i do", "while Not Converged do", and "for Each point Oj $\neq$ Oi do". Clarification and revision are needed.
}

Thank you for your suggestion.

% comment10
\rcomment{
\color{red} Section VI-C lacks quantitative analysis of the experimental results. The partitioning results in Fig. 6 are hard to distinguish, and the font size is too small. Moreover, the four subplots lack necessary labels, and the same issues are present in Fig. 7.
}

Thank you for your suggestion.

% comment11
\rcomment{
\color{red} Some of the English expressions are difficult to understand. Improving the overall quality of writing is recommended.
}
Thank you for your feedback and suggestions for improving the clarity of our paper. We acknowledge that some English expressions may have been difficult to understand, and we appreciate your recommendation to enhance the overall quality of writing.To address this concern, we have revised the manuscript, focusing on improving the fluency and readability of the text. We have rephrased complex or unclear expressions to ensure that the language is more straightforward and easier to follow. Additionally, we have performed a detailed grammar and style check to improve the overall quality of writing.

The following are some of the modifications:

\textcolor{blue}{The attacker has complete control over the local training process of the malicious robot nodes, meaning they can manipulate local data, trigger patterns, optimization strategies, and local updates at will. Additionally, the attacker may adopt a stealthy attack strategy, where the backdoor is not implanted in a single training round but gradually embedded into the global model through the cumulative effect of multiple rounds of training. This scenario is plausible in practice, as the central server only receives the updates uploaded by robot nodes and has no insight into the specific training process of each node. However, the attacker cannot interfere with the aggregation process of the central server (i.e., altering the global model aggregation rules) or tamper with the local updates of benign nodes.}

\textcolor{blue}{......}

\textcolor{blue}{Despite the increasingly sophisticated strategies employed by attackers, it is important to note that the essence of backdoor attacks lies in establishing a link between the predefined trigger and the target within the model. Thus, regardless of how attackers adjust their attack strategies, their updates will always exhibit some distributional shift compared to benign nodes.}

\newpage

\section{Responses to the Comments from Reviewer 4}

% comment12
\rcomment{
\color{red} Why does the section on "Instantaneous Attack Behavior Perception" use the chi-square distribution to calculate outlier differences instead of cosine similarity? The manuscript lacks an explanation for this choice.
}

We appreciate the reviewer’s insightful feedback. The decision to use the chi-square distribution instead of cosine similarity is rooted in the nature of the feature distribution in the frequency domain. Cosine similarity, while useful for comparing the angle between two vectors, would not appropriately capture the frequency domain’s distributional features in our model, where the outlier differences are more pronounced in the low-frequency components rather than in directional changes. The chi-square distribution allows us to better distinguish between malicious updates, which tend to introduce subtle but consistent deviations in these low-frequency features, and benign updates. This approach enhances detection accuracy by weighting the significant deviations while minimizing the impact of noise in the higher-frequency components. 

To accurately explain the reasons for using the chi-square distribution in this paper, we have made the following modifications:


% 卡方距离通常用来衡量某一种观测分布是不是符合某一类典型的理论分布，这一点与我们的方法非常契合，因为我们将计算出来的干净成分来作为衡量良性与恶意用户的标准。与传统的欧几里得距离相比，卡方距离根据干净分量分配权重，赋予较小分量更大的重要性。另一方面，余弦相似度测量两个向量之间的角度，通常用于评估它们的方向一致性，忽略数值差异。然而，在我们的方法中，我们关心的是每个用户的低频分量与干净分量的偏离程度，包括了数值差异，因此卡方距离比余弦相似度更适合捕捉隐蔽的恶意攻击。
\textcolor{blue}{
% Compared to traditional Euclidean distance, Chi-square distance assigns weights based on the magnitude of the corresponding components of two vectors, giving greater importance to components with larger feature values. This leads to a more accurate representation of differences in significant features within low-frequency vectors, while filtering out unimportant noise. On the other hand, Cosine similarity measures the angle between two vectors and is commonly used to evaluate their directional alignment in high-dimensional space. However, in our case, where the focus is on the magnitude and distribution of frequency-domain features, this method is less effective at capturing subtle variations in low-frequency components. These variations, which represent key differences between benign and malicious updates, are reflected more in the distribution and intensity of specific feature deviations than in directional alignment. As a result, Cosine similarity may overlook small but crucial frequency-based anomalies that can greatly affect the detection process. In contrast, the Chi-square distance emphasizes the magnitude of these differences, allowing for the detection of subtle yet meaningful shifts in data that signal covert attacks.
Chi-square distribution is usually used to measure whether a certain observed distribution conforms to a typical theoretical distribution, which is very consistent with our method because we use the calculated clean ingredient as a criterion for measuring benign and malicious nodes. Compared with the traditional Euclidean distance, the chi-square distribution assigns weights according to the clean ingredient, giving greater importance to smaller components. On the other hand, cosine similarity measures the angle between two vectors and is usually used to evaluate their directional consistency, ignoring magnitude differences. However, in our method, we are concerned with the degree of deviation of each user's low-frequency vector $G_i^t$ from the clean ingredient $\tilde{G}^t$, including magnitude differences, so the chi-square distribution is more suitable for capturing hidden malicious attacks than cosine similarity.
}

% comment13
\rcomment{
\color{red} The manuscript uses inconsistent figure referencing styles (e.g., "Fig. 7" vs. "Figure 6"). Please standardize the citation format.
}

Thank you for pointing out the inconsistency in figure referencing throughout the manuscript. We have carefully reviewed all figure references and standardized the citation format. Going forward, we have consistently used the term "Figure" when referencing figures, ensuring uniformity across the entire paper.

% comment14
\rcomment{
\color{red} Several hyperparameters are used in the experiments, but their rationale and appropriateness are not explained. Please provide a justification for their settings.
}
`
Thank you for your suggestion.
% 1. 为啥只对visual-encoder部分进行lora微调
% 我们的工作专注于联邦学习过程中的抗后门攻击，因此在CLIP模型微调这方面，我们采用了最基础的设置。参考CLIP-Adapter这篇文章，因为本文设定的场景是增加视觉大模型在zero-shot下对图像的识别能力，因此我们只对CLIP模型的visual-encoder部分进行lora微调，而对于text-encoder这部分，我们采用“a photo of a {CLASS}"作为文本方面的提示词模板。
% 2. 为什么使用lora微调，而不用其他微调方式
% 因为受限的计算资源导致对CLIP模型进行全量微调的时间成本非常之大，同时，我们的研究重点也不强调微调后的模型具有极高的性能，因此我们放弃了全量微调。目前也存在一些针对CLIP模型的微调方式，比如prompt engineering层面的CoOp、CoCoOp、MaPLe以及adapter层面的CLIP Adapter、TIP-Adapter，但这几个工作微调涉及到的参数量较小，与我们工作假设的高维场景不太契合。综上，我们选择了使用lora方式对CLIP模型进行微调，在微调成本和涉及到的参数量之间能够达到平衡。
% 3. 使用lora对CLIP模型进行微调，相应超参数设置的理由
% 我们所使用的超参数设置参考了CLIP-LORA这篇文章，

% lora微调设置
% comment15
\rcomment{
\color{red} Why is the condition $\zeta T$ set in the optimization problem in Section V.2? Clarification is needed.
}

Thank you for your suggestion.

% comment16
\rcomment{
\color{red} There are numerous instances of incorrect symbol usage throughout the manuscript. A thorough review and correction are necessary.
}
Thank you for your valuable feedback regarding the incorrect symbol usage in the manuscript. We have conducted a thorough review and carefully corrected all instances of improper symbol usage to ensure accuracy and consistency throughout the paper.

The following are the detailed modifications: 

\textcolor{blue}{Assume there are $N$ robot nodes in the system model, with each node denoted as $R_i$, where $i \in {1, 2, \ldots, N}$. Each robot node $R_i$ possesses a local dataset $D_i = {x_{i,j}, y_{i,j}}{j=1}^{|D_i|}$, where $x{i,j}$ represents a training sample, $y_{i,j}$ represents the corresponding label, and $|D_i|$ denotes the size of the dataset. The union of all local datasets across the nodes, $D = \bigcup_{i=1}^{N} D_i$, constitutes the overall dataset.}

\textcolor{blue}{......}

\textcolor{blue}{Based on this observation, we select the largest cluster \(C^t_{max} = \{G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}\}\) as the primary subject for analysis. To further extract the main characteristics of this cluster, we perform singular value decomposition (SVD)[38] on the matrix $H^t = (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n}$ formed by all nodes in this cluster. Since the left singular vectors of the SVD, denoted as \(\tilde{G}^t\), represent the principal directions of these vectors, \(\tilde{G}^t\) can be regarded as the principal component of benign nodes in the low-frequency domain.}


\newpage

\section{Responses to the Comments from Reviewer 2}

% comment17
\rcomment{
\color{red} The concept of intent recognition is a key innovation in this manuscript’s. However, the definition and construction of attacker intent are vague and need further elaboration to help readers better understand the core idea.
}

Thank you for your suggestion.

% comment18
\rcomment{
\color{red} The description of the experiments is unclear. The titles and text in the figures are too small, making them difficult to read. For example, in Fig. 5, the data curves are hard to distinguish. It is recommended to enlarge key areas to better present the experimental results and analysis. Additionally, many figures lack sufficient explanation.
}

Thank you for your suggestion.

% comment19
\rcomment{
\color{red} For the third paragraph of left column on page 9, several "steps" are mentioned but not explained in the text.
}

Thank you for your suggestion.

% comment20
\rcomment{
\color{red} The manuscript’s language requires improvement, as there are multiple grammatical errors and unclear expressions. A thorough revision is suggested to enhance overall readability.
}

Thank you for your valuable feedback. We appreciate your comments regarding the grammatical errors and unclear expressions in the manuscript.

In response, we have undertaken a comprehensive revision of the paper, with particular attention to correcting grammatical mistakes and improving the clarity of the text. We have also simplified complex expressions and enhanced the overall readability to ensure the content is more accessible and coherent.

\newpage

\textbf{\hspace{6.5cm}References:}
\bibliographystyle{IEEEtran}
\bibliography{reference}

% [R1] Achituve I, Shamsian A, Navon A, et al. Personalized federated learning with gaussian processes[J]. Advances in Neural Information Processing Systems, 2021, 34: 8392-8406.

% [R2] Wei K, Li J, Ding M, et al. User-level privacy-preserving federated learning: Analysis and performance optimization[J]. IEEE Transactions on Mobile Computing, 2021, 21(9): 3388-3401.

% [R3] Sun J, Li A, DiValentin L, et al. Fl-wbc: Enhancing robustness against model poisoning attacks in federated learning from a client perspective[J]. Advances in neural information processing systems, 2021, 34: 12613-12624.

% [R4] Zhu J, Yao J, Liu T, et al. Combating exacerbated heterogeneity for robust models in federated learning[J]. arXiv preprint arXiv:2303.00250, 2023.

% [R5] Zhang J, Hua Y, Wang H, et al. Fedala: Adaptive local aggregation for personalized federated learning[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(9): 11237-11244.

% [R6] Han S, Buyukates B, Hu Z, et al. FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs[C]//Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024: 5070-5081.

% [R7] Liu Z, He W, Chang C H, et al. SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks[J]. IEEE Transactions on Information Forensics and Security, 2024.

% [R8] Wei K, Li J, Ma C, et al. Personalized federated learning with differential privacy and convergence guarantee[J]. IEEE Transactions on Information Forensics and Security, 2023.

% [R9] Ilhan F, Su G, Liu L. Scalefl: Resource-adaptive federated learning with heterogeneous clients[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 24532-24541.

% [R10] Wu X, Huang F, Hu Z, et al. Faster adaptive federated learning[C]//Proceedings of the AAAI conference on artificial intelligence. 2023, 37(9): 10379-10387.

% [R11] Ye R, Wang W, Chai J, et al. Openfedllm: Training large language models on decentralized private data via federated learning[C]//Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024: 6137-6147.

% [R12] Nguyen T D, Rieger P, De Viti R, et al. {FLAME}: Taming backdoors in federated learning[C]//31st USENIX Security Symposium (USENIX Security 22). 2022: 1415-1432.

% [R13] Yang H, Xi W, Shen Y, et al. RoseAgg: Robust Defense Against Targeted Collusion Attacks in Federated Learning[J]. IEEE Transactions on Information Forensics and Security, 2024.





% \end{comment}


\end{document}



% FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs
% SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks
% Personalized Federated Learning With Differential Privacy and Convergence Guarantee
% ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients
% Faster Adaptive Federated Learning
% FedALA: Adaptive Local Aggregation for Personalized Federated Learning
% OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning
% Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction
% FLAME: Taming Backdoors in Federated Learning
% RoseAgg: Robust Defense Against Targeted Collusion Attacks in Federated Learning