% !TeX encoding = UTF-8
\documentclass[a4paper,twoside,11pt,dvipsnames]{reviewresponse}
\usepackage{subcaption}
% 1. Load and set up proper language packages
\usepackage{amsbsy,amssymb,epsfig,bbm,mathrsfs,multirow,amsthm}
\usepackage{algorithm,algpseudocode}
\usepackage{amsmath}
\usepackage{graphicx}
% \usepackage[english]{babel}
\usepackage{mathtools,xparse}
\usepackage{array, multirow, graphicx}
\usepackage{graphicx}
\usepackage{graphics}
% \usepackage{subfigure}
\usepackage{epstopdf}
\usepackage{color}
\usepackage{natbib}
\setcitestyle{numbers,square}
\usepackage{bbm}
\usepackage{comment}
\usepackage{makecell}
\PassOptionsToPackage{dvipsnames, svgnames, x11names}{xcolor}
\usepackage{xcolor}
\usepackage{threeparttable}

\usepackage{listings}

% \usepackage{multirow}
% \usepackage{amsmath}

\usepackage{mathtools}

\usepackage{caption}
%\usepackage{vntex} 
%\usepackage[vietnamese]{babel}
%\usepackage[utf8]{vietnam}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newcommand{\clU}{{\cal U}}
\newcommand{\clI}{{\mathbf I}}
\newcommand{\clD}{{\cal D}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\bo}{\boldsymbol{\omega}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bz}{\mathbf{q}}
\newcommand{\rw}{\rm{w}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bp}{\mathbf{p}_i}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\clS}{{\cal S}}
\newcommand{\ds}{\displaystyle}
\newcommand{\pik}{p_i^{(\kappa)}}
\newcommand{\pjk}{p_j^{(\kappa)}}
\newcommand{\rhok}{\rho^{(\kappa)}}
\newcommand{\bpk}{\mathbf{p}_i^{(\kappa)}}
\newtheorem{assumption}{Assumption}[section]

\newtheorem{Definition}{\hskip 0pt Definition}%[section]
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{\textbf{\textsc{Theorem}}}
\newtheorem{mypro}{Proposition}
\hyphenation{lists}


\graphicspath{ {./figures/} }

% 2. Complete the paper data
\newcommand{\myAuthors}{{Tran The Anh$^{\displaystyle 1}$, ~Nguyen Cong Luong$^{\displaystyle 2}$, } \\ {~Dusit Niyato$^{\displaystyle 2}$}}
\newcommand{\myAuthorsShort}{The Anh.~Tran et. al}
\newcommand{\myEmail}{theanh.tran@ntu.edu.sg}
\newcommand{\myTitle}{A Deep Reinforcement Learning Approach for Backscatter-Assisted Relay Communications}
\newcommand{\myShortTitle}{}
 \newcommand{\myJournal}{}
\newcommand{\myDept}{{$^{\displaystyle 1}$School of Computer Science and Engineering, Nanyang Technological University, Singapore. \\ \url{}}\\
{$^{\displaystyle 2}$School of Computer Science and Engineering, Nanyang Technological University. }\\}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[linktoc=all,bookmarks,bookmarksopen=true,bookmarksnumbered=true]{hyperref}

\hypersetup{
pdfauthor = {\myAuthorsShort},
pdftitle = {\myTitle},
pdfsubject = {\myJournal\xspace},
colorlinks = true,
linkcolor=black!70!green, 
citecolor=black!70!green,       
filecolor=magenta,      
urlcolor=black!70!black           
}

\begin{document}


\thispagestyle{plain}


 {\Large We would like to thank the editor for the time and effort to gather insightful reviews for our submission to IEEE Transactions on Network Science and Engineering (TNSESI-2023-01-0074: \textit{Combating ``Drug Resistance" of Intelligent Attack: Hierarchical Network Traffic Moving Target Defense with Endogenous Security Enhancement}). In response to the comments from the Editor and the reviewers, we have revised the paper extensively. We also would like to thank the Editor and the reviewers for the valuable and constructive comments that help us improve the quality of the paper significantly. The followings are the detailed answers to the comments. %It is also noted that, we add the letter ` `R'' (i.e., Response) before the reference number of references which are added in this response, e.g., ``[R1]'', and ``[R2]''. This is to distinguish references in this response letter and those in the revised paper.
 It is also noted that, as the whole manuscript has undergone substantial and comprehensive revisions, to facilitate clarity for the reviewers, we have marked the newly added or completely rewritten parts in {\color{blue}blue\color{black}} within the revised manuscript. The remaining sections, where only language and expression changes have been made, are still presented in black text.
 }

%\end{abstract}

\newpage

%=================================
%=================================
\section{Summary of changes}
Based on the valuable feedback from the reviewers, we have made significant improvements to the manuscript in the following areas:
\color{red}
\begin{itemize}

% 根据Reviewer 1's Comment 1，Comment 2以及Reviewer 2's Comment 1，我们修改了文章的部分公式以及重新构建了符号表，使文章的公式符号的意义更加清晰，优化阅读体验。
\item \textbf{[Writing and expression:]} Based on \textbf{Reviewer 1's Comment 1, Comment 2}, and \textbf{Reviewer 2's Comment 1}, we have revised some of the formulas in the paper and reconstructed the symbol table to make the meanings of the formula symbols clearer and to enhance the overall reading experience.

% 根据Reviewer 1's Comment 3，我们对Threat models部分的基本假设做了进一步的假设，使得本文提出的概念更便于理解。
\item \textbf{[Threat Models:]} Based on \textbf{Reviewer 1's Comment 3}, we made further assumptions in the \textbf{Threat Models} section regarding the basic assumptions, making the concepts proposed in this paper easier to understand.

% 根据Reviewer 1's Comment 4，我们增加了额外的实验来说明了采样大小和模型准确率之间的关系。   

% 根据Reviewer 1's Comment 5, 我们对DUPLEX PRIVACY AMPLIFICATION的auxiliary downlink privacy obfuscation部分做了修改，澄清了“社区导向框架”与"异质性情景下提高效率的意义“”之间联系。
\item \textbf{[Duplex privacy amplification:]} Based on \textbf{Reviewer 1's Comment 5}, we revised the \textbf{Auxiliary downlink privacy obfuscation} section of \textbf{Duplex privacy amplification}, clarifying the connection between the \textbf{community-oriented framework} and the \textbf{significance of improving efficiency in heterogeneous scenarios}.


% 根据Reviewer 2's Comment 2，
\item \textbf{[Credit-based active poisoning resistance:]} Based on \textbf{Reviewer 2's Comment 5}, we supplemented the consideration of resource consumption by adding an analysis of communication efficiency and computational time complexity.


% 根据Reviewer 2's Comment 3，我们对experimental Environment部分进行了相应的修改，解释了实验部分针对不同数据集选择对应模型结构和超参数的原因。根据Reviewer 2's Comment 4， 我们在实验结果描述部分添加了对CIFAR-100的实验结果以及相应的分析。
\item \textbf{[Performance evaluation:]} Based on \textbf{Reviewer 2's Comment 3}, we made corresponding revisions to the \textbf{Experimental environment} section of \textbf{Performance evaluation}, explaining the rationale behind selecting the appropriate model structures and hyperparameters for different datasets in the experiments. Additionally, in response to \textbf{Reviewer 2's Comment 4}, we added the experimental results for CIFAR-100, along with the corresponding analysis, to the experimental results description section. Furthermore, in response to \textbf{Reviewer 1's Comment 4}, We conducted additional experiments to illustrate the relationship between sample size and model accuracy.

\end{itemize}

\color{black}
The detailed responses to the comments are as follows. Thank you very much for your time again.



\newpage
%=================================
%=================================
% 我给你一些审稿意见，请你按照格式返回latex源码：

% ```
% \section{Responses to the Comments from Reviewer 2}

% % comment6
% \rcomment{
% \color{red} 审稿意见6
% }

% Thank you for your suggestion. 

% % comment7
% %...

% \newpage
% ```
\section{Responses to the Comments from Reviewer 1}

% comment6
\rcomment{
\color{red} The text in some experimental result figures is too small to be legible. Improving the clarity and resolution is recommended.
}

Thank you for your valuable feedback regarding the legibility of the experimental result figures. We have reviewed each figure in the manuscript and enhanced the resolution and clarity to ensure that all text and details are easily readable. Specifically, we have increased the font size within the figures and adjusted the image quality to provide a sharper, more distinct presentation of the experimental results.

% 修改后的结果如图\ref{fig:lab2}所示，同时我们也修改了文章中相应的分析部分，使其更易符合实验结果并且更易理解。
\begin{figure*}[!h]
    \centering
    \includegraphics[width=1\linewidth]{figures/lab2-combined.pdf}
    \caption{Visualization of node identification results under three attack scenarios (MR, EDGE CASE, NEUR) for four defense mechanisms (SecFFT, Flame, FLTrust, FoolsGold) using t-SNE. The red dots represent misidentified nodes, including both malicious nodes incorrectly identified as benign, or vice versa. }
    \label{fig:lab2}
\end{figure*}

Figure \ref{fig:lab2} shows the image after modification. We also updated the corresponding analysis section in the article to better align with the experimental findings and enhance readability. The revised analysis is shown below:

\textcolor{blue}{SecFFT outperforms other mechanisms in handling various attack. SecFFT achieves the lowest misidentification rate, at only 0.2\%, indicating its superior defense capability and robustness across various attack scenarios, accurately distinguishing between malicious and benign nodes. Conversely, the misidentification rates of Flame, FLTrust, and FoolsGold are 8\%, 3.9\%, and 9.5\%, respectively, with misidentified nodes more broadly distributed. Among them, FoolsGold exhibits the highest misidentification rate. It is worth noting that these statistical results align precisely with the findings from the previous experiment, further validating SecFFT's superior performance in instantaneous Attack Behavior Perception.}

% comment7
\rcomment{
\color{red} Figure 3 is not cited in the manuscript. It is suggested to reference and explain the figure in the relevant section, as its absence hinders understanding.
}

% 系统中断：先写合同去了
% 这是我回复的其中一个审稿意见，使用文章中的术语翻译这段话为英文
% 感谢你指出这一点，我们的图3对应\ref{\section{Methodology}}部分的B部分的2)，我们只将图片放在了对应的文字介绍部分，但是并未对图片内容进行描述，甚至没有在文章中引用这段文字。现在，我们在文章中引用了该图片并对齐进行了一个简单的描述：
% 图片3展示了Long-term Attack Intention Detection的前两步。这张图片总体上一共有3行，第一行展示了联邦学习的过程，很多机器人节点各自在下发的全局模型$G_{t-1}$的基础上训练并得到新的局部模型$\theta^t_{l_1}$，之后每个参与训练的客户端将自己的梯度变化上传到中央服务器的全局模型并聚合，从而形成新一轮的全局模型。第二行分为左右两个部分，左边部分展示了客户端多轮次中将更新的梯度展平后的结果，第一列代表某轮次的梯度更新，第二列代表$n$个客户端一轮次梯度更新展平后的结果，第三列则代表$n$个客户端$T$轮次梯度更新展平后的结果；右侧的图代表了每一轮次的全局模型。第三行则代表了如何根据多轮次的历史数据计算单个客户端的意图点，其中每条射线代表了模型更新展平后的结果，超球的球心则代表了当前客户端的意图点。

\textbf{Response:} Thank you for pointing this out. Our Figure 3 corresponds to Section B, 2) of the Methodology section. We placed the image alongside the related text but did not provide a description of the content, nor was the image referenced in the article. We have now cited this image in the text and provided a brief description:

Figure 3 illustrates the first two steps of the Long-term Attack Intention Detection. The figure comprises three rows overall. The first row demonstrates the process of federated learning, where many robot nodes independently train their local models \( \theta^t_{l_1} \) based on the distributed global model \( G_{t-1} \). Each participating client then uploads its gradient updates to the central server's global model, which are aggregated to form the next global model iteration. The second row is divided into two sections: the left section shows the flattened gradients updated across multiple rounds for clients. The first column represents the gradient update of a specific round, the second column shows the flattened gradient updates from \( n \) clients in one round, and the third column displays the flattened updates across \( T \) rounds for \( n \) clients. The right section of the image represents the global model in each round. The third row depicts how a single client's intention point is calculated based on multi-round historical data, where each ray signifies the flattened results of the model updates, and the hypersphere's center represents the current client's intention point.

% comment8
\rcomment{
\color{red} The steps in the final paragraph of Section 5 do not align with Algorithm 2. Please revise for consistency.
}

% 感谢您指出文本中描述行数与算法不一致的问题。我们已根据算法的最新修改，仔细检查并修正了第五节最后一段中的行数描述，确保其与算法2的步骤完全对齐。具体来说，我们逐条对照了算法中的每个步骤，确保每个操作、条件和循环都在文本中得到了准确反映。

% 此外，我们在修订过程中还增强了描述的清晰度，以便读者能够更容易理解算法的执行流程。我们还添加了必要的背景信息和解释，以帮助读者在上下文中更好地理解每一步的意义和目的。

% 这些修改不仅提高了文本的准确性，也增强了整篇论文的逻辑连贯性。我们非常感谢您对此问题的关注，这使我们能够提升稿件的整体质量和可读性。

Thank you for pointing out the inconsistency between the line numbers described in the text and those in Algorithm 2. We have carefully reviewed and revised the final paragraph of Section 5 to ensure that it aligns perfectly with the updated steps in the algorithm. Specifically, we compared each step in the algorithm with the corresponding actions, conditions, and loops described in the text to ensure accurate representation.

In addition to correcting the line numbers, we enhanced the clarity of the descriptions during the revision process. This makes it easier for readers to understand the execution flow of the algorithm. We also added necessary background information and explanations to help readers grasp the significance and purpose of each step within the context.

These modifications not only improve the accuracy of the text but also enhance the logical coherence of the entire paper. We greatly appreciate your attention to this issue, which has allowed us to elevate the overall quality and readability of the manuscript.

\textcolor{blue}{We summarize the algorithm in the form of pseudocode, as shown in Algorithm \ref{alg:malicious-node-detection-history}. Lines 4 to 6 correspond to Step 1, which outlines the method for retaining historical records for \(T\) rounds. Lines 7 to 12 correspond to Step 2, which describes the use of the minimum enclosing hypersphere algorithm to determine each robot node's intent point and confidence level. Lines 13 to 22 correspond to Step 3, which explains how to identify normal and abnormal nodes using the LOF algorithm. Finally, lines 23 to 25 correspond to Step 4, which illustrates the method for performing weighted aggregation based on each robot node's confidence level.
}

% comment9
\rcomment{
\color{red} Some conditions in Algorithm 2 are unclear, such as "for Client i do", "while Not Converged do", and "for Each point Oj $\neq$ Oi do". Clarification and revision are needed.
}

\textbf{Response:} Thank you for your valuable feedback on Algorithm 2. We have reviewed the conditions and updated the descriptions to ensure they are clear and unambiguous. Specifically:

\begin{itemize}
    \item \textbf{"for Client $i$ do"}: We clarified this condition to indicate that the algorithm iterates over each client in the dataset, specifying how Client $i$ is selected and what actions are taken for each client.

    \item \textbf{"while Not Converged do"}: We revised this condition to include the specific convergence criteria used in the algorithm. This provides a clear stopping condition of $\|O_{i,k}-O_{i,k+1}\|\geq \lambda$ and $k\leq k_{max}$, ensuring that readers understand when the loop will terminate.

    \item \textbf{"for Each point $O_j \neq O_i$ do"}: We clarified that this loop iterates over all points in the dataset except for point $O_i$, and we specified the purpose of comparing each $O_j$ with $O_i$ in the context of the algorithm’s objective.
\end{itemize}

% 除此之外，我们还发现了一个小细节，即原本的注释中注释符号和注释内容左右空格数量不一致，我们顺便修复了这个错误。

In addition, we also discovered a small detail that the number of spaces left and right in the original comments was inconsistent between the comment symbols and the comment content. We also fixed this error.

These modifications provide a more detailed and precise description of the algorithm’s flow. We appreciate your insights and believe these clarifications enhance the readability and understanding of Algorithm 2.

% 现在的算法2伪代码如下所示：

% TODO: 现在有一个问题就是，文章中的算法2在Response中出现更早，因此编号变成了Algorithm 1
The pseudocode for Algorithm 2 is as follows:

\begin{algorithm}
\caption{Attack intention detection and secure aggregation}
\label{alg:malicious-node-detection-history}
\begin{algorithmic}[1]
\State \textbf{Input:} Global model history $\{\theta_g^{t-T}, \dots, \theta_g^{t-1}\}$, historical gradient updates for each client $\{\triangledown \theta_{i}^{t-T}, \dots, \triangledown \theta_{i}^{t-1}\}$
\State \textbf{Output:} Sets of normal clients $U_{nor}$ and malicious clients $U_{mal}$


\For {Client \textcolor{blue}{$i\in \{1\ldots N\}$}}

\State{\color{CadetBlue}/* \textbf{Construction of updates and model databases */}} 
    \State Record flattened gradients $\bar{\theta_i^t}$ and models $\theta_g^{t-1}$
    % \State $\widetilde{\theta_{i}^{t'-1}}  \gets Flatten(\theta_g^{t'-1})$, ${v}_{i}^{t'}  \gets \overline{\triangledown\theta_{i}^{t'}}$ for $t'  \gets \max\{t-T+1, 1\}, \ldots, t$ \Comment{Construct rays}
    \State Construct rays for each $'$, $\max\{t-T+1, 1\}\leq t' \leq t$


\State{\color{CadetBlue}/* \textbf{Construction of attack intention */}} 

    \State Initialize center $O_{i,0}$ and radius $r_{i,0}$
    \While {\textcolor{blue}{$\|O_{i,k}-O_{i,k+1}\|\geq \lambda$ and $k\leq k_{max}$}}
        \State Update center $O_{i,k+1}$ and radius $r_{i,k+1}$
    \EndWhile
    \State  $cre_i  \gets \frac{1}{r_i + \rho}$ \Comment{Calculate confidence}


\State{\color{CadetBlue}/* \textbf{LOF-driven malicious intention detection */}} 

    \For {Each point $O_j \neq O_i$\textcolor{blue}{, $j\in\{1\ldots N\}$}}
        \State Calculate distance $\|O_i - O_j\|$
    \EndFor
    \State Determine $q$-distance $\widetilde{dis_i^q}$ for $O_i$
    \State Find neighbors $Nei_i$ within $\widetilde{dis_i^q}$
    \State $rea_{i,j}  \gets \max\{\widetilde{dis_i^q}, \|O_i - O_j\|\}$ for $O_j \in Nei_i$  \Comment{Compute reachability distance}
    \State  $lrd_i  \gets \frac{|Nei_i|}{\sum_{j \in Nei_i} rea_{i,j}}$ \Comment{Calculate reachability density}
    \State $lof_i  \gets \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$

% \For {Client $i$}
%     \State Compute $lof_i = \frac{\sum_{j \in Nei_i} \frac{lrd_j}{lrd_i}}{|Nei_i|}$
%     \If {$lof_i > 1$}
%         \State Mark client $i$ as malicious, add to $U_{mal}$
%     \Else
%         \State Mark client $i$ as normal, add to $U_{nor}$
%     \EndIf
% \EndFor
% \State $U_{mal} = \{i \,|\, lof_i > 1\}$
% \State $U_{nor} = \{i \,|\, lof_i \leq 1\}$
\State $U_{mal}, U_{nor}  \gets \{i \,|\, lof_i > 1\}, \{i \,|\, lof_i \leq 1\}$

\State{\color{CadetBlue}/* \textbf{Secure aggregation of global FFT model */}} 
        \State $cre_i'  \gets \tanh(cre_i)$\Comment{Compute adjusted confidence}
        \State $w_i  \gets \frac{cre_i'}{\sum_{i \in U_{nor}} cre_i'}$\Comment{Normalize weights}
\EndFor

\State \textbf{Output:} $\theta_g^t \gets \theta_g^{t-1} + \sum_{i \in U_{nor}} w_i \cdot \triangledown \theta_i^t$\Comment{Aggregate global model}
\end{algorithmic}
\end{algorithm}

% comment10
\rcomment{
\color{red} Section VI-C lacks quantitative analysis of the experimental results. The partitioning results in Fig. 6 are hard to distinguish, and the font size is too small. Moreover, the four subplots lack necessary labels, and the same issues are present in Fig. 7.
}
\textbf{Response:} 
Thank you for your valuable comments and suggestions, which have greatly helped us to improve our paper. We have carefully addressed each of the issues you raised and made the following modifications:

First, we recognized the need for a more in-depth quantitative analysis in this section. We have now included additional statistical data to provide a comprehensive analysis of the experimental results, including metrics that better quantify the effectiveness of our partitioning method. This has been added to enhance the clarity and significance of our findings.
The following are the corresponding modifications in the article: 

\textcolor{blue}{This indicates that SecFFT effectively defends against attacks by accurately identifying and neutralizing malicious users, all while preserving the performance and accuracy of the global model. In contrast, other defense mechanisms perform less effectively. Although Flame also shows strong performance in reducing ASR and mitigating malicious attack, it introduces considerable noise in the identification process, leading to a decrease in TSR, especially under MR attacks, where the performance degradation is more pronounced. FLTrust fails to defend effectively, with ASR initially low in MR attacks but quickly rising after several iterations, ultimately proving ineffective; against NEUR and EDGE CASE attacks, ASR remains high from the outset, demonstrating inadequate defense. Foolsgold also shows poor performance in defending against all three types of attacks, maintaining a high ASR from the beginning. Overall, the comparison highlights that other defense mechanisms either fail to effectively resist attacks or compromise model performance during defense. This further underscores SecFFT's significant advantage in federated fine-tuning for backdoor attack resistance, making it the optimal defense choice.}

\textcolor{blue}{......}

\textcolor{blue}{SecFFT outperforms other mechanisms in handling various attack. SecFFT achieves the lowest misidentification rate, at only 0.2\%, indicating its superior defense capability and robustness across various attack scenarios, accurately distinguishing between malicious and benign nodes. Conversely, the misidentification rates of Flame, FLTrust, and FoolsGold are 8\%, 3.9\%, and 9.5\%, respectively, with misidentified nodes more broadly distributed. Among them, FoolsGold exhibits the highest misidentification rate. It is worth noting that these statistical results align precisely with the findings from the previous experiment, further validating SecFFT's superior performance in instantaneous Attack Behavior Perception.}


Second, to improve the visibility and distinguish-ability of the partitioning results in Figure 6, we have added a supplementary sub-image that provides a clearer presentation of the partitioned sections. We also increased the font size to enhance readability, ensuring that key features are visible and easy to interpret. For details, please refer to Figure \ref{fig:lab1} and responses to the comment 2 from Reviewer 2.

Third, we re-adjusted the layout of Figure 7 to address the issues you pointed out. Specifically, we improved the font sizes, added necessary labels, and modified the legend for better comprehension. These adjustments were made to ensure that the experimental data in Figure 7 are both readable and visually clear. For details, please refer to Figure \ref{fig:lab2} and responses to the comment 1 from Reviewer 1.

% comment11
\rcomment{
\color{red} Some of the English expressions are difficult to understand. Improving the overall quality of writing is recommended.
}
\textbf{Response:} 
Thank you for your feedback and suggestions for improving the clarity of our paper. We acknowledge that some English expressions may have been difficult to understand, and we appreciate your recommendation to enhance the overall quality of writing.To address this concern, we have revised the manuscript, focusing on improving the fluency and readability of the text. We have rephrased complex or unclear expressions to ensure that the language is more straightforward and easier to follow. Additionally, we have performed a detailed grammar and style check to improve the overall quality of writing.

The following are some of the modifications:

\textcolor{blue}{The attacker has complete control over the local training process of the malicious robot nodes, meaning they can manipulate local data, trigger patterns, optimization strategies, and local updates at will. Additionally, the attacker may adopt a stealthy attack strategy, where the backdoor is not implanted in a single training round but gradually embedded into the global model through the cumulative effect of multiple rounds of training. This scenario is plausible in practice, as the central server only receives the updates uploaded by robot nodes and has no insight into the specific training process of each node. However, the attacker cannot interfere with the aggregation process of the central server (i.e., altering the global model aggregation rules) or tamper with the local updates of benign nodes.}

\textcolor{blue}{......}

\textcolor{blue}{Despite the increasingly sophisticated strategies employed by attackers, it is important to note that the essence of backdoor attacks lies in establishing a link between the predefined trigger and the target within the model. Thus, regardless of how attackers adjust their attack strategies, their updates will always exhibit some distributional shift compared to benign nodes.}


\newpage

\section{Responses to the Comments from Reviewer 2}

% comment17
\rcomment{
\color{red} The concept of intent recognition is a key innovation in this manuscript’s. However, the definition and construction of attacker intent are vague and need further elaboration to help readers better understand the core idea.
}

Thank you for your suggestion.

% comment18
\rcomment{
\color{red} The description of the experiments is unclear. The titles and text in the figures are too small, making them difficult to read. For example, in Fig. 5, the data curves are hard to distinguish. It is recommended to enlarge key areas to better present the experimental results and analysis. Additionally, many figures lack sufficient explanation.
}
\textbf{Response:} 
% 对于第一个实验：Model integrity and poisoning resistance，我们重新整理了相应数据，并修改了图片的表现形式。修改包括对图例字体格式以及大小的修改，同时为图中折现重合的部分加上了子图，使其更容易辨别。同时，我们也修改了原文中对于该实验结果的描述，使其更符合实验数据，同时更易于阅读和理解。
Thank you for your detailed feedback regarding the clarity of our experimental descriptions and figures. We have carefully revised the manuscript to address each of the issues you raised. 

Specifically, for the experiment \textbf{Model Integrity and Poisoning Resistance}, as dipicted in Figure \ref{fig:lab1}, we reorganized the relevant data and revised the presentation of the figures. These modifications include adjustments to the legend font style and size, as well as the addition of subplots for overlapping line segments, enhancing visual clarity. Furthermore, we refined the original description of the experimental results to align more closely with the experimental data, making it easier to read and understand.

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=1\linewidth]{figures/lab1-combined.pdf}
    \caption{ASR and TSR of various defense mechanisms (FedAVG, FLTrust, Foolsgold, Flame, SecFFT) under three attacks (MR, NEUR, EDGE CASE).}
    \label{fig:lab1}
\end{figure*}

The corresponding modifications in the article are as follows:

As depicted in the figure, in all attack scenarios, SecFFT consistently achieves an attack success rate (ASR) close to zero, while the test success accuracy (TSR) remains high. \textcolor{blue}{This indicates that SecFFT effectively defends against attacks by accurately identifying and neutralizing malicious users, all while preserving the performance and accuracy of the global model. In contrast, other defense mechanisms perform less effectively. Although Flame also shows strong performance in reducing ASR and mitigating malicious attack, it introduces considerable noise in the identification process, leading to a decrease in TSR, especially under MR attacks, where the performance degradation is more pronounced. FLTrust fails to defend effectively, with ASR initially low in MR attacks but quickly rising after several iterations, ultimately proving ineffective; against NEUR and EDGE CASE attacks, ASR remains high from the outset, demonstrating inadequate defense. Foolsgold also shows poor performance in defending against all three types of attacks, maintaining a high ASR from the beginning. Overall, the comparison highlights that other defense mechanisms either fail to effectively resist attacks or compromise model performance during defense. This further underscores SecFFT's significant advantage in federated fine-tuning for backdoor attack resistance, making it the optimal defense choice.}



% comment19
\rcomment{
\color{red} For the third paragraph of left column on page 9, several "steps" are mentioned but not explained in the text.
}

Thank you for your suggestion.

% comment20
\rcomment{
\color{red} The manuscript’s language requires improvement, as there are multiple grammatical errors and unclear expressions. A thorough revision is suggested to enhance overall readability.
}
\textbf{Response:} 
Thank you for your valuable feedback. We appreciate your comments regarding the grammatical errors and unclear expressions in the manuscript.

In response, we have undertaken a comprehensive revision of the paper, with particular attention to correcting grammatical mistakes and improving the clarity of the text. We have also simplified complex expressions and enhanced the overall readability to ensure the content is more accessible and coherent.

\newpage

%=================================
\section{Responses to the Comments from Reviewer 3}
%=================================
%=================================
%========================================================
\rcomment{
\color{red} The technical framework lacks sufficient explanatory detail. For example, the steps in Fig. 2 are explained too briefly, making them difficult to understand.
}

\textbf{Response:} 
Thank you for your valuable feedback. We appreciate your insights, especially regarding the need for further detail in the technical framework explanation and the steps illustrated in Figure 2.

In response, we have carefully considered your suggestions and revised the framework diagram to enhance clarity and detail. The new version of Figure 2 (which depicted as Figure \ref{fig2:instant}) has been redrawn to illustrate each step in the algorithm more thoroughly, ensuring that readers can understand the entire process without ambiguity. We have added comprehensive explanations for each step, including intermediate processes and transitions, to provide a clearer and more accessible description of the framework. These changes are intended to ensure that the entire flow of the framework is presented in a more intuitive and informative manner.

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\linewidth]{figures/secfft-1.pdf}
    \caption{SecFFT's instantaneous attack behavior perception module with frequency-domain deep outlier feature semantics extraction}
    \label{fig2:instant}
\end{figure}


%========================================================
\rcomment{
\color{red} There are several errors and linguistic issues throughout the paper. For instance, on page 5, at the end of the second paragraph, citation [36] is repeated consecutively. Please carefully review and correct these issues.
}
% 问题：文中存在部分错误和语病，如在P5页第二段末尾，引用[36]连续重复出现，请认真检查
\textbf{Response:} Thank you for your valuable feedback on our paper. We greatly appreciate the time and effort you have taken to review our work.

Regarding the issue of errors and linguistic problems throughout the paper, especially the repeated citation [36] at the end of the second paragraph on page 5, we have carefully reviewed the entire manuscript and made the necessary corrections. The repeated citation has been removed, and we have conducted a thorough proofreading process to address any other linguistic issues that may have affected the clarity and quality of the paper.
% 对存在的这类问题，我们深表歉意。我们已经删除了该处存在的重复引用的问题，同时，我们也修改了本文其他地方存在的表述不清或者语法错误等问题。以下为详细的修改内容：

The following are the detailed modifications:

\textcolor{blue}{
To address the limitations faced by defense methods based on shallow semantic features in high-dimensional spaces, we propose a new defense strategy rooted in the essence of backdoor attacks [34], which leverages deep semantic features by focusing on the differences in model updates in the frequency domain. According to our experimental results, by transforming local model updates into the frequency domain, we can more accurately capture the abnormal behavior of malicious updates which is typically difficult to detect using traditional shallow feature-based defenses in low-frequency components. By analyzing the relevant features in the frequency domain, we can effectively distinguish between malicious and benign nodes, thereby enhancing the robustness and accuracy of federated learning in the face of sophisticated backdoor attacks.
}

\textcolor{blue}{......}

\textcolor{blue}{
Due to the curse of dimensionality in high-dimensional spaces, traditional methods based on shallow semantic
feature can no longer effectively identify malicious nodes. In contrast, once model updates are transformed into the frequency domain, their differences are primarily concentrated in the low-frequency components. Focusing on the analysis of these low-frequency components not only improves identification accuracy but also significantly reduces computational overhead. For each update \(\triangledown \theta_i^t\), we apply one-dimensional DCT-II[35] to obtain its corresponding frequency distribution. Then we extract $m$ low-frequency components[36], such as 5000, yielding the low-frequency vector $G_i^t$.
}






%========================================================
\rcomment{
\color{red} In Algorithm 1, there are unused variables in line 5.
}
% 问题：算法1第5行出现未使用变量。

\textbf{Response:} We thank the Reviewer for the constructive comment, and
% 非常抱歉，因为我们的疏忽，导致该算法出现让人无法理解的地方。根据您的建议，我们修改了该算法的相关部分，删除了未使用的变量。同时为了使整个算法过程更易理解，我们修改了另外一些跟原文不一致的地方，\ref{alg:malicious-node-detection}展示了修改后的结果。
we sincerely apologize for the confusion caused by the oversight in our algorithm.
Following your suggestion, we revised the relevant parts of the algorithm and removed unused variables.
Additionally, to make the entire algorithm process easier to understand, we adjusted some parts that were inconsistent with the original text, and algorithm \ref{alg:malicious-node-detection} shows the modified result.
% 最后，为了表现算法中某些变量会随训练轮次所变化，我们给一些变量添加时间$t$的上标，比如修改$C_{max},Chi_i^2,{C_1}', {C_2}'$至$C^t_{max},{Chi^t_i}^2,{C^t_1}', {C^t_2}'$
Finally, to represent that certain variables in the algorithm change with the training rounds, we added the superscript of round $t$ to some variables, such as modifying $C_{max}, Chi_i^2, {C'_1}, {C'_2}$ to $C^t_{max}, {Chi^t_i}^2, {C^t_1}', {C^t_2}'$.

% 图1展示了算法修改后的结果
The Algorithm \ref{alg:malicious-node-detection} shows the result of the modified algorithm.


% \begin{algorithm}
% \caption{Instantaneous Attack Behavior Perception}
% \label{alg:malicious-node-detection}
% \begin{algorithmic}[1]
% \State \textbf{Input:} $d$, $N$, $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$, $m$ \Comment{$d$ is the dimension of each update; $N$ is the number of nodes participating during each round; $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$ is the local updates from robot nodes during the $t$-th round; $m$ is the length of low-frequency components}
% \State \textbf{Output:} $U_{nor}$, $U_{mal}$ \Comment{benign nodes, malicious nodes}
% \State{\color{CadetBlue}/* \textbf{Frequency Domain Transformation */}} 
% % \State Step 1: Frequency Domain Transformation
% \For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
%     \State \textcolor{blue}{$G_i^t \gets Trunc(DCT(Flatten(\triangledown \theta_i^t))), m)$}
% \EndFor

% % \State
% \State{\color{CadetBlue}/* \textbf{Clean Ingredient Extraction */}} 
% % \State Step 2: Clean Ingredient Extraction
% \State $(C_0^t, C_1^t, \ldots, C_{\kappa}^t) \gets Clustering\textcolor{blue}{ (G_0^t, G_1^t, \ldots, G_N^t)}$ \Comment{$\kappa$ denotes the number of clusters}
% \State \textcolor{blue}{$ C^t_{max} \gets \underset{C^t_j}{\arg\max} \, |C^t_j|$ \Comment{$|C^t_j|$ denotes the number of nodes in cluster $C^t_j$, $j = 1, 2, \ldots, \kappa $}}
% \State $H^t \gets (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n} $ \Comment{Stacking to form Matrix $H^t$, where $R_{i_0}, R_{i_1}, \ldots, R_{i_n} \in C^t_{max}$.}

% \State $\hat{H}^t \gets (H^t)^{T} H^t$
% \State $\lambda_{max}^t, \xi_{max}^t \gets eig(\hat{H}^t)$ \Comment{Calculating the maximum singular value and its corresponding eigenvector}
% \State $\tilde{G}^t \gets \frac{H^t \xi_{max}^t}{\sqrt{\lambda_{max}^t}}$ \Comment{The clean ingredient}

% % \State
% \State{\color{CadetBlue}/* \textbf{Chi-square distance calculation */}} 
% % \State Step 3: Chi-square distance calculation
% % \State $P_i^t \gets Softmax(G_i^t), \, Q^t \gets Softmax(\tilde{G}^t)$
% \For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
% \State \textcolor{blue}{$Chi^t_i \gets \sqrt{\sum_{k=0}^{m-1}\frac{(G_i^t[k] - {\tilde G}^t[k])^2}{{|\tilde G}^t[k]| + \epsilon}}$}
% \EndFor
% \State \textcolor{blue}{$S^t \gets \{Chi^t_1, Chi^t_2, \ldots, Chi^t_N\}$} \Comment{The Distance differences calculated by Chi-square distance.}

% % \State
% \State{\color{CadetBlue}/* \textbf{Single-round malicious behavior perception */}} 
% % \State Step 4: Single-round malicious behavior perception
% \State $\textcolor{blue}{\{{C^t_1}', {C^t_2}'\}} \gets KMeans(S^t, 2)$ \Comment{Cluster $S$ into 2 clusters using KMeans.}
% \State \textcolor{blue}{$U_{nor} \gets C'_{max}$, $U_{mal} \gets \{C'_i \, | \, i \neq max\}$}

% \end{algorithmic}
% \end{algorithm}

\begin{algorithm}
\caption{Instantaneous Attack Behavior Perception}
\label{alg:malicious-node-detection}
\begin{algorithmic}[1]
\State \textbf{Input:} $d$, $N$, $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$, $m$ \Comment{$d$ is the dimension of each update; $N$ is the number of nodes participating during each round; $(\triangledown \theta_0^t, \triangledown \theta_1^t, \ldots, \triangledown \theta_N^t) \in \mathbb{R}^{N \times d}$ is the local updates from robot nodes during the $t$-th round; $m$ is the length of low-frequency vector}
\State \textbf{Output:} $U_{nor}$, $U_{mal}$ \Comment{benign nodes, malicious nodes}
\State{\color{CadetBlue}/* \textbf{Frequency Domain Transformation */}} 
% \State Step 1: Frequency Domain Transformation
\For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
    \State \textcolor{blue}{$G_i^t \gets Trunc(DCT(Flatten(\triangledown \theta_i^t))), m)$}
\EndFor

% \State
\State{\color{CadetBlue}/* \textbf{Clean Ingredient Extraction */}} 
% \State Step 2: Clean Ingredient Extraction
\State $(C_0^t, C_1^t, \ldots, C_{\kappa}^t) \gets Clustering\textcolor{blue}{ (G_0^t, G_1^t, \ldots, G_N^t)}$ \Comment{$\kappa$ denotes the number of clusters}
\State \textcolor{blue}{$ C^t_{max} \gets \underset{C^t_j}{\arg\max} \, |C^t_j|$ \Comment{$|C^t_j|$ denotes the number of nodes in cluster $C^t_j$, $j = 1, 2, \ldots, \kappa $}}
\State $H^t \gets (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n} $ \Comment{Stacking to form Matrix $H^t$, where $R_{i_0}, R_{i_1}, \ldots, R_{i_n} \in C^t_{max}$.}

\State $\hat{H}^t \gets (H^t)^{T} H^t$
\State $\lambda_{max}^t, \xi_{max}^t \gets eig(\hat{H}^t)$ \Comment{Calculating the maximum singular value and its corresponding eigenvector}
\State $\tilde{G}^t \gets \frac{H^t \xi_{max}^t}{\sqrt{\lambda_{max}^t}}$ \Comment{The clean ingredient}

% \State
\State{\color{CadetBlue}/* \textbf{Chi-square distance calculation */}} 
% \State Step 3: Chi-square distance calculation
% \State $P_i^t \gets Softmax(G_i^t), \, Q^t \gets Softmax(\tilde{G}^t)$
\For {$R_i \in \textcolor{blue}{\{R_1, \ldots, R_N\}}$}
    \State \textcolor{blue}{$Chi^t_i \gets \sqrt{\sum_{k=0}^{m-1}\frac{(G_i^t[k] - {\tilde G}^t[k])^2}{|{\tilde G}^t[k]| + \epsilon}}$}
\EndFor
\State \textcolor{blue}{$S^t \gets \{Chi^t_1, Chi^t_2, \ldots, Chi^t_N\}$} \Comment{The Distance differences calculated by Chi-square distance.}

% \State
\State{\color{CadetBlue}/* \textbf{Single-round malicious behavior perception */}} 
% \State Step 4: Single-round malicious behavior perception
\State $\textcolor{blue}{\{{C^t_1}', {C^t_2}'\}} \gets KMeans(S^t, 2)$ \Comment{Cluster $S$ into 2 clusters using KMeans.}
\State \textcolor{blue}{$U_{nor} \gets C'_{max}$, $U_{mal} \gets \{C'_i \, | \, i \neq max\}$}

\end{algorithmic}
\end{algorithm}

%========================================================
\rcomment{
\color{red} Section 4 uses various metrics to demonstrate the improved defense performance of the proposed method against different types of attacks. However, there is insufficient explanation of the origin and calculation methods for these metrics, which makes it hard for readers to follow. It is recommended to add a brief explanation.
}
% 问题：实验数据大小的代表性引起了关注。应阐明所选值背后的基本原理，以加强实验结果的有效性和可靠性。（就是说实验设置为啥这样选，比如超参数啥的，需要说明道理，不然的话是不合理的）
% 回复：确实应该写一段话描述一下这些指标都是什么意思。
% 感谢你的建议，在实验四的部分，我们使用了ACC、Rec、FPR、FNR、AUC、MCC等指标作为我们方法的有效性验证依据。虽然这些指标是这些类似实验中常见的指标，但是为了论文的普适性以及为了方便更多读者的理解，还是应该简要介绍一下这些指标的含义。因此我们新增了一些描述，用来简要介绍这些指标的含义。 我们增加了如下的简单描述：

% 这些指标用于评估模型性能。“Acc”表示准确率，衡量预测正确的比例；“Rec”是召回率，表示模型正确识别正例的能力；“FPR”是假阳性率，指错误将负例预测为正例的比例；“FNR”是假阴性率，指错误将正例预测为负例的比例；“AUC”是曲线下面积，表示模型区分正负例的整体能力；“MCC”是马修斯相关系数，综合评估模型预测结果的平衡性。

\textbf{Response:} Thank you for your suggestion. In Section 4 of our experiments, we used metrics such as ACC, Rec, FPR, FNR, AUC, and MCC as the basis for validating the effectiveness of our method. Although these metrics are commonly used in similar experiments, for the sake of the paper's generality and to facilitate understanding for a broader audience, we believe it is necessary to briefly introduce the meaning of these metrics. Therefore, we have added some descriptions to provide a concise explanation of these metrics. The added description is as follows:

\textcolor{blue}{
"Acc" refers to accuracy, which measures the proportion of correct predictions; "Rec" stands for recall, representing the model's ability to correctly identify positive instances; "FPR" denotes the false positive rate, indicating the proportion of negative instances incorrectly predicted as positive; "FNR" refers to the false negative rate, which represents the proportion of positive instances incorrectly predicted as negative; "AUC" stands for the area under the curve, reflecting the model's overall ability to distinguish between positive and negative instances; and "MCC" represents the Matthews correlation coefficient, which provides a balanced evaluation of the model's predictions.
}
%========================================================
% 表格2的内容太长，超出了双栏的空间了，建议重新进行调整规划
\rcomment{
\color{red} The content in Table 2 is too long and exceeds the space available for a two-column layout. Please revise and reformat accordingly.
}

% 我将每次给你一个审稿意见，请你对于该审稿意见写一个回复（回复要包括中文版本和英文版本）。回复要展现自己良好的态度，越详细越好。
% 你了解司法人工智能吗？请解释之。

% 谢谢你的建议，表格2的宽度确实有些过长，已经超出了半栏的范围，甚至已经与右侧栏目的内容产生了融合。我们对这个表格进行了调整，适当缩小了表格的宽度，使得表格在不影响整体观感的同时，保证了表格格式符合要求，且不超过单栏范围。
\textbf{Response:} 
Thank you for your suggestion. The width of Table 2 is indeed somewhat excessive, exceeding the single-column limit and even merging with the content in the adjacent column. We have made adjustments to the table, reducing its width appropriately to ensure that the table fits within the required format while maintaining the overall visual quality without exceeding the single-column range.

\begin{table}[h!]
\small
\centering
\caption{\textcolor{blue}{Metrics results with different attack and defense methods.}}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c|c|c|c|c|c}
\hline
\textcolor{blue}{Strategy} & \textcolor{blue}{Defense} & \textcolor{blue}{Acc.} & \textcolor{blue}{Rec.} & \textcolor{blue}{FPR} & \textcolor{blue}{FNR} & \textcolor{blue}{AUC} & \textcolor{blue}{MCC} \\ \hline

\multirow{4}{*}{\textcolor{blue}{None}} & \textcolor{blue}{Foolsgold} & \textcolor{blue}{0.90} & \textcolor{blue}{0.67} & \textcolor{blue}{0.00} & \textcolor{blue}{0.33} & \textcolor{blue}{0.83} & \textcolor{blue}{0.76} \\
                      & \textcolor{blue}{FLTrust}   & \textcolor{blue}{0.82} & \textcolor{blue}{0.40} & \textcolor{blue}{0.00} & \textcolor{blue}{0.60} & \textcolor{blue}{0.70} & \textcolor{blue}{0.56} \\
                      & \textcolor{blue}{Flame}     & \textcolor{blue}{0.90} & \textcolor{blue}{0.67} & \textcolor{blue}{0.00} & \textcolor{blue}{0.33} & \textcolor{blue}{0.83} & \textcolor{blue}{0.76} \\
                      & \textcolor{blue}{SecFFT}    & \textbf{\textcolor{blue}{1.00}} & \textbf{\textcolor{blue}{1.00}} & \textcolor{blue}{0.00} & \textbf{\textcolor{blue}{0.00}} & \textbf{\textcolor{blue}{1.00}} & \textbf{\textcolor{blue}{1.00}} \\ \hline

\multirow{4}{*}{\textcolor{blue}{Size}} & \textcolor{blue}{Foolsgold} & \textcolor{blue}{0.92} & \textcolor{blue}{0.80} & \textcolor{blue}{0.03} & \textcolor{blue}{0.20} & \textcolor{blue}{0.88} & \textcolor{blue}{0.72} \\ 
                      & \textcolor{blue}{FLTrust}   & \textcolor{blue}{0.82} & \textcolor{blue}{0.53} & \textcolor{blue}{0.06} & \textcolor{blue}{0.47} & \textcolor{blue}{0.74} & \textcolor{blue}{0.61} \\ 
                      & \textcolor{blue}{Flame}     & \textcolor{blue}{0.92} & \textcolor{blue}{0.73} & \textbf{\textcolor{blue}{0.00}} & \textcolor{blue}{0.27} & \textcolor{blue}{0.87} & \textcolor{blue}{0.78} \\ 
                      & \textcolor{blue}{SecFFT}    & \textbf{\textcolor{blue}{0.98}} & \textbf{\textcolor{blue}{0.93}} & \textbf{\textcolor{blue}{0.00}} & \textbf{\textcolor{blue}{0.07}} & \textbf{\textcolor{blue}{0.96}} & \textbf{\textcolor{blue}{0.91}} \\ \hline

\multirow{4}{*}{\textcolor{blue}{Angle}} & \textcolor{blue}{Foolsgold} & \textcolor{blue}{0.88} & \textcolor{blue}{0.73} & \textcolor{blue}{0.06} & \textcolor{blue}{0.27} & \textcolor{blue}{0.84} & \textcolor{blue}{0.68} \\ 
                       & \textcolor{blue}{FLTrust}   & \textcolor{blue}{0.86} & \textcolor{blue}{0.60} & \textcolor{blue}{0.03} & \textcolor{blue}{0.40} & \textcolor{blue}{0.80} & \textcolor{blue}{0.65} \\ 
                       & \textcolor{blue}{Flame}     & \textcolor{blue}{0.90} & \textcolor{blue}{0.67} & \textbf{\textcolor{blue}{0.00}} & \textcolor{blue}{0.33} & \textcolor{blue}{0.83} & \textcolor{blue}{0.76} \\ 
                       & \textcolor{blue}{SecFFT}    & \textbf{\textcolor{blue}{0.96}} & \textbf{\textcolor{blue}{0.87}} & \textbf{\textcolor{blue}{0.00}} & \textbf{\textcolor{blue}{0.13}} & \textbf{\textcolor{blue}{0.94}} & \textbf{\textcolor{blue}{0.88}} \\ \hline
\end{tabular}
}
\vspace{1em}
\begin{tablenotes}
\scriptsize
\item ``Acc." stands for Accuracy, ``Rec." for Recall, ``FPR" for False Positive Rate, ``FNR" for False Negative Rate, ``AUC" for Area Under Curve, and ``MCC" for Matthews Correlation Coefficient. The strategies are abbreviated as ``None" (No strategy), ``Size" (Size-limited strategy), and ``Angle" (Angle-limited strategy).
\end{tablenotes}
\label{tab:detect}
\end{table}

\newpage

\section{Responses to the Comments from Reviewer 4}

% comment12
\rcomment{
\color{red} Why does the section on "Instantaneous Attack Behavior Perception" use the chi-square distribution to calculate outlier differences instead of cosine similarity? The manuscript lacks an explanation for this choice.
}
\textbf{Response:} 
We appreciate the reviewer’s insightful feedback. The decision to use the chi-square distribution instead of cosine similarity is rooted in the nature of the feature distribution in the frequency domain. Cosine similarity, while useful for comparing the angle between two vectors, would not appropriately capture the frequency domain’s distributional features in our model, where the outlier differences are more pronounced in the low-frequency components rather than in directional changes. The chi-square distribution allows us to better distinguish between malicious updates, which tend to introduce subtle but consistent deviations in these low-frequency features, and benign updates. This approach enhances detection accuracy by weighting the significant deviations while minimizing the impact of noise in the higher-frequency components. 

To accurately explain the reasons for using the chi-square distribution in this paper, we have made the following modifications:


% 卡方距离通常用来衡量某一种观测分布是不是符合某一类典型的理论分布，这一点与我们的方法非常契合，因为我们将计算出来的干净成分来作为衡量良性与恶意用户的标准。与传统的欧几里得距离相比，卡方距离根据干净分量分配权重，赋予较小分量更大的重要性。另一方面，余弦相似度测量两个向量之间的角度，通常用于评估它们的方向一致性，忽略数值差异。然而，在我们的方法中，我们关心的是每个用户的低频分量与干净分量的偏离程度，包括了数值差异，因此卡方距离比余弦相似度更适合捕捉隐蔽的恶意攻击。
\textcolor{blue}{
% Compared to traditional Euclidean distance, Chi-square distance assigns weights based on the magnitude of the corresponding components of two vectors, giving greater importance to components with larger feature values. This leads to a more accurate representation of differences in significant features within low-frequency vectors, while filtering out unimportant noise. On the other hand, Cosine similarity measures the angle between two vectors and is commonly used to evaluate their directional alignment in high-dimensional space. However, in our case, where the focus is on the magnitude and distribution of frequency-domain features, this method is less effective at capturing subtle variations in low-frequency components. These variations, which represent key differences between benign and malicious updates, are reflected more in the distribution and intensity of specific feature deviations than in directional alignment. As a result, Cosine similarity may overlook small but crucial frequency-based anomalies that can greatly affect the detection process. In contrast, the Chi-square distance emphasizes the magnitude of these differences, allowing for the detection of subtle yet meaningful shifts in data that signal covert attacks.
Chi-square distribution is usually used to measure whether a certain observed distribution conforms to a typical theoretical distribution, which is very consistent with our method because we use the calculated clean ingredient as a criterion for measuring benign and malicious nodes. Compared with the traditional Euclidean distance, the chi-square distribution assigns weights according to the clean ingredient, giving greater importance to smaller components. On the other hand, cosine similarity measures the angle between two vectors and is usually used to evaluate their directional consistency, ignoring magnitude differences. However, in our method, we are concerned with the degree of deviation of each user's low-frequency vector $G_i^t$ from the clean ingredient $\tilde{G}^t$, including magnitude differences, so the chi-square distribution is more suitable for capturing hidden malicious attacks than cosine similarity.
}

% comment13
\rcomment{
\color{red} The manuscript uses inconsistent figure referencing styles (e.g., "Fig. 7" vs. "Figure 6"). Please standardize the citation format.
}
\textbf{Response:} 
Thank you for pointing out the inconsistency in figure referencing throughout the manuscript. We have carefully reviewed all figure references and standardized the citation format. Going forward, we have consistently used the term "Figure" when referencing figures, ensuring uniformity across the entire paper.

% comment14
\rcomment{
\color{red} Several hyperparameters are used in the experiments, but their rationale and appropriateness are not explained. Please provide a justification for their settings.
}
% 1. 为什么使用lora微调，而不用其他微调方式
% 因为受限的计算资源导致对CLIP模型进行全量微调的时间成本非常之大，同时，我们的研究重点也不强调微调后的模型具有极高的性能，因此我们放弃了全量微调。目前也存在一些针对CLIP模型的微调方式，比如prompt engineering层面的CoOp、CoCoOp、MaPLe以及adapter层面的CLIP Adapter、TIP-Adapter，但这几个工作微调涉及到的参数量较小，与我们工作假设的高维场景不太契合。综上，我们选择了使用lora方式对CLIP模型进行微调，在微调成本和涉及到的参数量之间能够达到平衡。
% 2. 为啥只对visual-encoder部分进行lora微调
% 我们的工作专注于联邦学习过程中的抗后门攻击，因此在CLIP模型微调这方面，我们采用了最基础的设置。参考CLIP-Adapter这篇文章，因为本文设定的场景是增加视觉大模型在zero-shot下对图像的识别能力，因此我们只对CLIP模型的visual-encoder部分进行lora微调，而对于text-encoder这部分，我们采用“a photo of a {CLASS}"作为文本方面的提示词模板。
% 3. 使用lora对CLIP模型进行微调，相应超参数设置的理由
% 在使用lora对CLIP模型进行微调时，我们所使用的超参数设置参考了CLIP-LORA这篇文章，相关的超参数例如learning rate, batch size等与该篇论文几乎相符合。而在lora参数秩的设置上，如果按照CLIP-LORA这篇文章进行设置则会导致最终微调涉及到的参数量较少，不符合本文设定的场景，因此我们进行了适当增大。
% 4. 联邦训练过程相应的超参数设置理由
% 对于联邦学习相关的超参数例如节点数量，我们的设置参考了\cite{wei2023personalized}, \cite{ilhan2023scalefl}, \cite{wu2023faster}, \cite{ye2024openfedllm}, \cite{zhou2024every}, \cite{nguyen2022flame}, and \cite{yang2024roseagg}等文章。这些工作所采用的节点数不尽相同，范围从20到200不等。因此，综合考虑时间成本，计算开销以及验证效果等方面，我们才采用相应的超参数设置。
% Thank you for your valuable feedback. We appreciate your comments regarding the need for clarification and justification of the hyperparameter settings used in our experiments. Below, we provide a detailed response to address your concerns:

% \textbf{Rationale behind hyperparameter settings for LoRA fine-tuning of CLIP:}
% We chose LoRA (Low-Rank Adaptation) for fine-tuning the CLIP model due to limited computational resources and the need to balance time cost and parameter efficiency. Full fine-tuning of the CLIP model is computationally expensive, and since our research does not prioritize pushing the fine-tuned model to peak performance, we selected LoRA to maintain computational efficiency while still allowing a sufficient degree of fine-tuning. LoRA enables us to adjust a smaller set of parameters, which is more practical for the high-dimensional data scenarios we explore in our work.
% For the specific hyperparameters used in LoRA fine-tuning, we referred to the values suggested in the CLIP-LORA paper, such as learning rate and batch size. However, we found that the original rank setting of LoRA would have resulted in an insufficient number of parameters for our scenario. Thus, we adjusted the rank to increase the number of tunable parameters, ensuring that the model's capacity aligns with the complexity of the data used in our experiments.

% Rationale behind the hyperparameter settings for federated training
% For the federated training process, we carefully considered the hyperparameters, especially the number of participating nodes, which is a critical factor in federated learning. Informed by recent studies such as \cite{wei2023personalized}, \cite{ilhan2023scalefl}, and \cite{wu2023faster}, which tested node counts ranging from 20 to 200, we aimed to find a balance between computational cost, time efficiency, and model accuracy. After evaluating our available resources and validating our preliminary results, we settled on a configuration that fits the scope of our work while ensuring robust performance.
\textbf{Response:} 
Thank you for your insightful comments. We have carefully considered your concerns regarding the hyperparameter settings and provide a detailed explanation below:

\textbf{LoRA was selected due to computational efficiency and alignment with our research goals:}
Given the limited computational resources available, full-parameter fine-tuning of the CLIP model was impractical due to the substantial time and resource costs. Additionally, our research does not focus on achieving the highest possible performance but rather on efficiently conducting experiments. While other fine-tuning methods like CoOp\cite{zhou2022learning}, CoCoOp\cite{zhou2022conditional}, MaPLe, and adapter-based methods such as CLIP-Adapter\cite{gao2024clip} and TIP-Adapter\cite{zhang2021tip} are available, these involve fewer parameters and do not align well with the high-dimensional scenarios required in our study. LoRA offers a balanced solution, maintaining computational efficiency while optimizing parameter adjustment.

\textbf{The visual encoder of the CLIP model was fine-tuned to meet the core focus of our research:}
Our study primarily addresses backdoor attacks in federated learning, and thus we used a straightforward configuration for fine-tuning the CLIP model. In accordance with the approach from the CLIP-Adapter\cite{gao2024clip} paper, which enhances visual recognition capabilities, we applied LoRA exclusively to the visual encoder. For the text encoder, we retained the default prompt template (“a photo of a \{CLASS\}”) to guide text-based predictions, which met our research needs without introducing unnecessary complexity.

\textbf{The hyperparameters for LoRA were adapted based on the demands of our experimental setup:}
We adopted hyperparameters such as learning rate and batch size from the recommendations in the CLIP-LORA\cite{zanella2024low} paper. However, we determined that the default rank for LoRA parameters was insufficient to meet the high-dimensional requirements of our work. To better accommodate the parameter complexity in our experiments, we adjusted the rank to increase the number of tunable parameters, ensuring better fitting the requirements of our high-dimensional scenario.

\textbf{Federated learning hyperparameters were informed by prior studies and practical considerations:}
For the federated training aspect of our research, we relied on previous studies, including \cite{wei2023personalized}, \cite{ilhan2023scalefl}, and \cite{wu2023faster}, which suggested a participants range from 20 to 200. Considering the time cost, computational overhead, and  the effectiveness of experimental results, we selected the most suitable configuration for our experiments, optimizing both performance and resource use.

% comment15
\rcomment{
\color{red} Why is the condition $\zeta T$ set in the optimization problem in Section V.2? Clarification is needed.
}

Thank you for your suggestion.

% comment16
\rcomment{
\color{red} There are numerous instances of incorrect symbol usage throughout the manuscript. A thorough review and correction are necessary.
}
\textbf{Response:} 
Thank you for your valuable feedback regarding the incorrect symbol usage in the manuscript. We have conducted a thorough review and carefully corrected all instances of improper symbol usage to ensure accuracy and consistency throughout the paper.

The following are some of the detailed modifications: 

\textcolor{blue}{Assume there are $N$ robot nodes in the system model, with each node denoted as $R_i$, where $i \in {1, 2, \ldots, N}$. Each robot node $R_i$ possesses a local dataset $D_i = {x_{i,j}, y_{i,j}}{j=1}^{|D_i|}$, where $x{i,j}$ represents a training sample, $y_{i,j}$ represents the corresponding label, and $|D_i|$ denotes the size of the dataset. The union of all local datasets across the nodes, $D = \bigcup_{i=1}^{N} D_i$, constitutes the overall dataset.}

\textcolor{blue}{......}

\textcolor{blue}{Based on this observation, we select the largest cluster \(C^t_{max} = \{G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}\}\) as the primary subject for analysis. To further extract the main characteristics of this cluster, we perform singular value decomposition (SVD)[38] on the matrix $H^t = (G^t_{i_0}, G^t_{i_1}, \ldots, G^t_{i_n}) \in \mathbb{R}^{m \times n}$ formed by all nodes in this cluster. Since the left singular vectors of the SVD, denoted as \(\tilde{G}^t\), represent the principal directions of these vectors, \(\tilde{G}^t\) can be regarded as the principal component of benign nodes in the low-frequency domain.}



\newpage

\textbf{\hspace{6.5cm}References:}
\bibliographystyle{IEEEtran}
\bibliography{reference}

% [R1] Achituve I, Shamsian A, Navon A, et al. Personalized federated learning with gaussian processes[J]. Advances in Neural Information Processing Systems, 2021, 34: 8392-8406.

% [R2] Wei K, Li J, Ding M, et al. User-level privacy-preserving federated learning: Analysis and performance optimization[J]. IEEE Transactions on Mobile Computing, 2021, 21(9): 3388-3401.

% [R3] Sun J, Li A, DiValentin L, et al. Fl-wbc: Enhancing robustness against model poisoning attacks in federated learning from a client perspective[J]. Advances in neural information processing systems, 2021, 34: 12613-12624.

% [R4] Zhu J, Yao J, Liu T, et al. Combating exacerbated heterogeneity for robust models in federated learning[J]. arXiv preprint arXiv:2303.00250, 2023.

% [R5] Zhang J, Hua Y, Wang H, et al. Fedala: Adaptive local aggregation for personalized federated learning[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(9): 11237-11244.

% [R6] Han S, Buyukates B, Hu Z, et al. FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs[C]//Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024: 5070-5081.

% [R7] Liu Z, He W, Chang C H, et al. SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks[J]. IEEE Transactions on Information Forensics and Security, 2024.

% [R8] Wei K, Li J, Ma C, et al. Personalized federated learning with differential privacy and convergence guarantee[J]. IEEE Transactions on Information Forensics and Security, 2023.

% [R9] Ilhan F, Su G, Liu L. Scalefl: Resource-adaptive federated learning with heterogeneous clients[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 24532-24541.

% [R10] Wu X, Huang F, Hu Z, et al. Faster adaptive federated learning[C]//Proceedings of the AAAI conference on artificial intelligence. 2023, 37(9): 10379-10387.

% [R11] Ye R, Wang W, Chai J, et al. Openfedllm: Training large language models on decentralized private data via federated learning[C]//Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2024: 6137-6147.

% [R12] Nguyen T D, Rieger P, De Viti R, et al. {FLAME}: Taming backdoors in federated learning[C]//31st USENIX Security Symposium (USENIX Security 22). 2022: 1415-1432.

% [R13] Yang H, Xi W, Shen Y, et al. RoseAgg: Robust Defense Against Targeted Collusion Attacks in Federated Learning[J]. IEEE Transactions on Information Forensics and Security, 2024.





% \end{comment}


\end{document}



% FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs
% SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks
% Personalized Federated Learning With Differential Privacy and Convergence Guarantee
% ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients
% Faster Adaptive Federated Learning
% FedALA: Adaptive Local Aggregation for Personalized Federated Learning
% OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning
% Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction
% FLAME: Taming Backdoors in Federated Learning
% RoseAgg: Robust Defense Against Targeted Collusion Attacks in Federated Learning  