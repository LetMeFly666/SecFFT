{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from genReLiTu import plot_detection_heatmaps_3x4, generate_data_1dimension\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fmnist\"\n",
    "\n",
    "files = {\n",
    "    \"MR\": {\n",
    "        \"flame\": \"10020337\",\n",
    "        \"fltrust\": \"10022140\",\n",
    "        \"foolsgold\": \"10271625\",\n",
    "        \"secfft\": \"10292241\",\n",
    "    },\n",
    "    \"EDGE_CASE\": {\n",
    "        \"flame\": \"10020911\",\n",
    "        \"fltrust\": \"10030309\",\n",
    "        \"foolsgold\": \"10280055\",\n",
    "        \"secfft\": \"10300448\",\n",
    "    },\n",
    "    \"NEUROTOXIN\": {\n",
    "        \"flame\": \"10021255\",\n",
    "        \"fltrust\": \"10030648\",\n",
    "        \"foolsgold\": \"10280559\",\n",
    "        \"secfft\": \"10300840\",\n",
    "    },\n",
    "}\n",
    "\n",
    "attack_defense_data = {\n",
    "    \"MR\": {\n",
    "        \"FLAME\": \"FL_Backdoor_CV/2024-10-02_03-37-50/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-10-02_21-40-11/\",\n",
    "        \"FOOLSGOLD\": \"FL_Backdoor_CV/2024-10-27_16-25-41/\",\n",
    "        \"SECFFT\": \"FL_Backdoor_CV/2024-10-29_22-41-06/\",\n",
    "    },\n",
    "    \"EDGE_CASE\": {\n",
    "        \"FLAME\": \"FL_Backdoor_CV/2024-10-02_09-11-28/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-10-03_03-09-36/\",\n",
    "        \"FOOLSGOLD\": \"FL_Backdoor_CV/2024-10-28_00-55-46/\",\n",
    "        \"SECFFT\": \"FL_Backdoor_CV/2024-10-30_04-48-52/\",\n",
    "    },\n",
    "    \"NEUROTOXIN\": {\n",
    "        \"FLAME\": \"FL_Backdoor_CV/2024-10-02_12-55-32/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-10-03_06-48-00/\",\n",
    "        \"FOOLSGOLD\": \"FL_Backdoor_CV/2024-10-28_05-59-22/\",\n",
    "        \"SECFFT\": \"FL_Backdoor_CV/2024-10-30_08-40-55/\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for attack, attack2data in attack_defense_data.items():\n",
    "#     true_labels = []\n",
    "#     labels_get_by_Euclid = []\n",
    "#     labels_get_by_manhattan = []\n",
    "#     labels_get_by_cosine = []\n",
    "#     labels_get_by_chi_square = []\n",
    "#     for denfense, data_folder in attack2data.items():\n",
    "#         if denfense != \"AVG\":\n",
    "#             continue\n",
    "#         participant_file_name = f\"{data_folder}participants/participants.csv\"\n",
    "#         participants = np.genfromtxt(\n",
    "#             participant_file_name, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "#         )\n",
    "#         participants = participants[1:].T\n",
    "#         for i in range(len(participants) - 1):\n",
    "#             file_name = f\"{data_folder}model_updates/{dataset}_{attack}_{i}.pkl\"\n",
    "#             if not os.path.exists(file_name):\n",
    "#                 print(f\"File {file_name} not found\")\n",
    "#                 continue\n",
    "#             with open(file_name, \"rb\") as file:\n",
    "#                 model_updates = pickle.load(file)\n",
    "\n",
    "\n",
    "# roundNum = 10\n",
    "# dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg_NEUROTOXIN-fmnist/'\n",
    "# pklName = os.path.join(dirPath, f'model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl')\n",
    "# participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "# # participantFileDF = pd.read_csv(participantFilePath)\n",
    "# # # 提取参与者数组（第一列）和轮次（从第二列开始的部分）\n",
    "# # clients = participantFileDF.iloc[1:, 0].tolist()  # 客户端列表\n",
    "# # roundsArray = participantFileDF.iloc[1:, 1:].to_numpy()  # 轮次数据（50行x30列）\n",
    "# # print(roundsArray)\n",
    "# participants = np.genfromtxt(\n",
    "#     participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "# )\n",
    "# participants = participants[1:].T\n",
    "# participants_thisRound = participants[roundNum]\n",
    "# print(participants_thisRound)\n",
    "\n",
    "# with open(pklName, 'rb') as f:\n",
    "#     update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "# # print(update)\n",
    "# # weight0 = update['base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight']\n",
    "# # weight0.shape  # torch.Size([50, 12288])\n",
    "# userUpdates = [torch.empty(0) for _ in range(50)]\n",
    "# for layerKey, values in update.items():\n",
    "#     # print(layerKey)\n",
    "#     # print(values)\n",
    "#     # print(values.shape)  # torch.Size([50, 12288])\n",
    "#     for i in range(values.shape[0]):\n",
    "#         trueUser = participants_thisRound[i]\n",
    "#         userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i].cpu()), 0)\n",
    "# print(userUpdates[0].shape)\n",
    "\n",
    "def loadPkl(roundNum: int, dirPath: str) -> Dict[str, torch.Tensor]:  # 把pkl变成{'key1': [[user3], [user5]]}\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "    pklName = os.path.join(dirPath, f'model_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "    return update\n",
    "\n",
    "def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:  # 获取参与者列表\n",
    "    participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "\n",
    "    # 读取参与者数组\n",
    "    participants = np.genfromtxt(\n",
    "        participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "    )\n",
    "    participants = participants[1:].T\n",
    "    participants_thisRound = participants[roundNum]  # 获取当前轮次的参与者\n",
    "    return participants_thisRound\n",
    "\n",
    "def get_all_user_updates(roundNum: int, dirPath: str) -> torch.Tensor:  # 把pkl变成[[user1展平(拼接)后的结果], [user2], ...]\n",
    "    # 设置轮次编号和文件路径\n",
    "    # roundNum = 10\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    # print(participants_thisRound)\n",
    "\n",
    "    # 加载 .pkl 文件\n",
    "    update = loadPkl(roundNum, dirPath)\n",
    "\n",
    "    # 初始化一个列表来存储每个客户端的更新，使用 GPU 张量\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    userUpdates = [torch.empty((0,), device=device) for _ in range(50)]  # 假设50个客户端\n",
    "\n",
    "    # 遍历每个层的更新\n",
    "    for layerKey, values in update.items():\n",
    "        # 将每个值移到 GPU 上\n",
    "        values = values.to(device)\n",
    "        for i in range(values.shape[0]):  # 遍历每个客户端的梯度\n",
    "            trueUser = participants_thisRound[i]  # 获取当前轮次的客户端ID\n",
    "            # 如果为空张量\n",
    "            if userUpdates[trueUser].numel() == 0:\n",
    "                userUpdates[trueUser] = values[i]  # 直接赋值\n",
    "            else:\n",
    "                userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i]), 0)  # 在GPU上拼接\n",
    "\n",
    "    userUpdates = torch.stack(userUpdates)  # 转换为张量\n",
    "    # # 打印第一个用户的更新形状来检查结果\n",
    "    # print(userUpdates[0].shape)\n",
    "    return userUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算一个二维 tensor 中每两个向量之间的余弦相似度矩阵。\n",
    "\n",
    "    参数:\n",
    "    - tensor (torch.Tensor): 形状为 (N, D) 的二维张量，N 是客户端数量，D 是特征维度。\n",
    "\n",
    "    返回:\n",
    "    - similarity_matrix (torch.Tensor): 形状为 (N, N) 的张量，每个元素表示两个向量之间的余弦相似度。\n",
    "    \"\"\"\n",
    "    # 归一化每个向量\n",
    "    normalized_tensor = F.normalize(tensor, p=2, dim=1)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    similarity_matrix = torch.mm(normalized_tensor, normalized_tensor.T)\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userUpdates_avg_NEUR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/')\n",
    "# print(userUpdates_avg_NEUR.shape)\n",
    "# print(userUpdates_avg_NEUR)\n",
    "# userUpdates_avg_MR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_12-02-44-avg-fmnist_MR/')\n",
    "\n",
    "# similarity_matrix_avg_NEUR = cosine_similarity_matrix(userUpdates_avg_NEUR)\n",
    "# print(similarity_matrix_avg_NEUR.shape)\n",
    "# similarity_matrix_avg_MR = cosine_similarity_matrix(userUpdates_avg_MR)\n",
    "# # print(similarity_matrix_avg_MR.shape)\n",
    "# plot_detection_heatmaps(similarity_matrix_avg_NEUR, similarity_matrix_avg_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foolsgold\n",
    "# ChangeFrom https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L203C1-L241C25\n",
    "# foolsgold自身并没有确认哪些是恶意客户端，而是根据权重聚合\n",
    "# def foolsgold_identify_malicious_clients(wv: np.ndarray, threshold: float = 0.25) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     根据权重向量识别潜在的恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - wv (np.ndarray): 客户端的权重向量。\n",
    "#     - threshold (float): 判断恶意客户端的阈值，权重低于此值的客户端将被视为恶意客户端。\n",
    "    \n",
    "#     返回:\n",
    "#     - malicious_clients (np.ndarray): 被识别为恶意的客户端索引。\n",
    "#     \"\"\"\n",
    "#     return np.where(wv < threshold)[0]\n",
    "def foolsgold_identify_malicious_clients(wv: np.ndarray) -> np.ndarray:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(wv.reshape(-1, 1))\n",
    "    clusters = kmeans.labels_\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    max_cluster = unique[np.argmax(counts)]\n",
    "    user_labels = np.zeros(len(clusters), dtype=int)\n",
    "    user_labels[clusters == max_cluster] = 1\n",
    "    return np.where(user_labels == 0)[0]\n",
    "\n",
    "# 返回 聚合后的全局模型、恶意客户端索引、余弦相似度矩阵\n",
    "# def foolsgold(model_updates: Dict[str, torch.Tensor]) -> Tuple[Dict[str, torch.Tensor], np.ndarray, np.ndarray]:\n",
    "def foolsgold_oneRound(roundNum: int, dirPath: str) -> Tuple[Dict[str, torch.Tensor], np.ndarray, torch.Tensor]:\n",
    "    model_updates = loadPkl(roundNum, dirPath)\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    \n",
    "    keys = list(model_updates.keys())\n",
    "    last_layer_updates = model_updates[keys[-2]]\n",
    "    K = len(last_layer_updates)\n",
    "    cs = smp.cosine_similarity(last_layer_updates.cpu().numpy()) - np.eye(K)  # 减去对角线为1的单位矩阵，使得自身与自身的相似度为0\n",
    "    maxcs = np.max(cs, axis=1)\n",
    "    # === pardoning(赦免) ===\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if maxcs[i] < maxcs[j]:\n",
    "                cs[i][j] = cs[i][j] * maxcs[i] / maxcs[j]\n",
    "\n",
    "    alpha = np.max(cs, axis=1)\n",
    "    wv = 1 - alpha\n",
    "    wv[wv > 1] = 1\n",
    "    wv[wv < 0] = 0\n",
    "\n",
    "    # === Rescale so that max value is wv ===\n",
    "    wv = wv / np.max(wv)\n",
    "    wv[(wv == 1)] = .99\n",
    "\n",
    "    # === Logit function ===\n",
    "    wv = (np.log(wv / (1 - wv)) + 0.5)\n",
    "    wv[(np.isinf(wv) + wv > 1)] = 1\n",
    "    wv[(wv < 0)] = 0\n",
    "\n",
    "    malicious_clients = foolsgold_identify_malicious_clients(wv)\n",
    "    malicious_clients = participants_thisRound[malicious_clients]\n",
    "    print(f\"识别出的恶意客户端索引: {malicious_clients}\")\n",
    "\n",
    "    # === calculate global update ===\n",
    "    global_update = defaultdict()\n",
    "    for name in keys:\n",
    "        tmp = None\n",
    "        for i, j in enumerate(range(len(wv))):\n",
    "            if i == 0:\n",
    "                tmp = model_updates[name][j] * wv[j]\n",
    "            else:\n",
    "                tmp += model_updates[name][j] * wv[j]\n",
    "        global_update[name] = 1 / len(wv) * tmp\n",
    "    print(wv)\n",
    "    if True:  # 使用余弦相似度作为热力图依据\n",
    "        cs = smp.cosine_similarity(last_layer_updates.cpu().numpy())  # 这里就不再减去自身了\n",
    "        cs_rearranged = np.zeros((len(participants_thisRound), len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            for j, user_j in enumerate(participants_thisRound):\n",
    "                cs_rearranged[user_i][user_j] = cs[i][j]\n",
    "        cs_tensor = torch.from_numpy(cs_rearranged)\n",
    "    else:  # 使用聚合参数wv作为热力图依据。这样直接很多1，太明显了\n",
    "        cs_tensor = torch.zeros((len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            cs_tensor[user_i] = wv[i]  # tensor([0.2348, 0.2348, 0.8740, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
    "\n",
    "    return global_update, malicious_clients, cs_tensor\n",
    "\n",
    "# 组合多轮，返回恶意客户端索引、余弦相似度矩阵\n",
    "def foolsgold(roundsNum: List[int], dirPath: str) -> Tuple[np.ndarray, torch.Tensor]:\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "            if thisMaliciousIndex < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "            maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    cs = smp.cosine_similarity(gradients_shuffled)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious_shuffled, cs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByGPT - 还是不太行啊看来\n",
    "# import os\n",
    "# import pickle\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "# def fltrust_original(model_updates: Dict[str, torch.Tensor], param_updates: List[torch.Tensor], clean_param_update: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "#     \"\"\"\n",
    "#     使用 FLTrust 方法进行聚合计算。\n",
    "    \n",
    "#     参数:\n",
    "#     - model_updates: 客户端模型更新的字典，键为参数名，值为模型更新的 Tensor。\n",
    "#     - param_updates: 客户端的参数更新列表，包含每个客户端的更新 Tensor。\n",
    "#     - clean_param_update: 干净模型的参数更新，用于计算客户端更新的权重。\n",
    "\n",
    "#     返回:\n",
    "#     - global_update: 聚合后的全局模型更新。\n",
    "#     \"\"\"\n",
    "#     cos = torch.nn.CosineSimilarity(dim=0)\n",
    "#     g0_norm = torch.norm(clean_param_update)\n",
    "#     weights = []\n",
    "    \n",
    "#     # 计算每个客户端更新与 clean_param_update 的余弦相似度\n",
    "#     for param_update in param_updates:\n",
    "#         weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    \n",
    "#     weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "#     weights = weights / weights.sum()\n",
    "#     weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "#     nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "#     nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "#     print(f'g0_norm: {g0_norm}, '\n",
    "#           f'weights_sum: {weights.sum()}, '\n",
    "#           f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "#     normalize_weights = []\n",
    "#     for param_update in param_updates:\n",
    "#         normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "#     global_update = dict()\n",
    "#     for name, params in model_updates.items():\n",
    "#         if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "#             global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "#         else:\n",
    "#             global_update[name] = torch.matmul(\n",
    "#                 weights,\n",
    "#                 params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "#     return global_update\n",
    "\n",
    "\n",
    "# def fltrust(roundsNum: List[int], dirPath: str, modelPath: str) -> Tuple[List[int], np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     根据指定的轮次和目录路径，使用 FLTrust 聚合和识别恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - roundsNum: 需要处理的轮次列表。\n",
    "#     - dirPath: 数据文件所在的目录路径。\n",
    "#     - modelPath: 模型路径（目前没有用到）。\n",
    "\n",
    "#     返回:\n",
    "#     - 恶意客户端的编号列表。\n",
    "#     - 50 个客户端的评分（1x50 数组或 50x50 数组）。\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 加载pkl文件数据\n",
    "#     def loadPkl(roundNum: int, subfolder: str, dirPath: str) -> Dict[str, torch.Tensor]:\n",
    "#         pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "#         pklName = os.path.join(dirPath, f'{subfolder}/{pklPrefix}_{roundNum}.pkl')\n",
    "#         with open(pklName, 'rb') as f:\n",
    "#             update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "#         return update\n",
    "    \n",
    "#     # 合并指定轮次的数据\n",
    "#     all_model_updates = {}\n",
    "#     all_param_updates = []\n",
    "#     for roundNum in roundsNum:\n",
    "#         participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "#         model_updates = loadPkl(roundNum, 'model_updates', dirPath)  # 修正为正确的子文件夹\n",
    "#         clean_param_update = loadPkl(roundNum, 'clean_param_updates', dirPath)[participants_thisRound[0]]  # 修正为正确的子文件夹\n",
    "\n",
    "#         # 拼接恶意客户端（0-2号）和良性客户端（3-9号）\n",
    "#         for key, value in model_updates.items():\n",
    "#             if key not in all_model_updates:\n",
    "#                 all_model_updates[key] = torch.zeros((50, value.shape[1])).to('cuda:0')\n",
    "#             all_model_updates[key][:15] = torch.cat([value[i].unsqueeze(0) for i in range(3)], dim=0).to('cuda:0')  # 恶意客户端\n",
    "#             all_model_updates[key][15:] = torch.cat([value[i].unsqueeze(0) for i in range(3, 10)], dim=0).to('cuda:0')  # 良性客户端\n",
    "\n",
    "#         # 提取参数更新，拼接恶意和良性客户端\n",
    "#         for i in range(3):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "#         for i in range(3, 10):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "    \n",
    "#     # 使用 FLTrust 进行聚合\n",
    "#     global_update = fltrust_original(all_model_updates, all_param_updates, clean_param_update)\n",
    "    \n",
    "#     # 使用 KMeans 聚类来识别恶意客户端\n",
    "#     scores = torch.stack(all_param_updates).cpu().numpy()  # 使用参数更新作为聚类的输入\n",
    "#     kmeans = KMeans(n_clusters=2, random_state=0).fit(scores)\n",
    "#     cluster_labels = kmeans.labels_\n",
    "    \n",
    "#     # 识别恶意客户端\n",
    "#     malicious_clients = [i for i in range(50) if cluster_labels[i] == cluster_labels[:15].max()]\n",
    "\n",
    "#     # 计算 50x50 的余弦相似度矩阵\n",
    "#     cosine_similarity_matrix = np.zeros((50, 50))\n",
    "#     for i in range(50):\n",
    "#         for j in range(50):\n",
    "#             cosine_similarity_matrix[i, j] = F.cosine_similarity(all_param_updates[i].view(-1, 1), all_param_updates[j].view(-1, 1)).item()\n",
    "\n",
    "#     return malicious_clients, cosine_similarity_matrix\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参数更新的向量\n",
    "# def parameters_to_vector(params):\n",
    "#     return torch.cat([p.view(-1) for p in params])\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参与者列表\n",
    "# def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:\n",
    "#     # 实现略\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fltrust\n",
    "# https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L301-L340\n",
    "\n",
    "def fltrust_original(model_updates, param_updates, clean_param_update):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    g0_norm = torch.norm(clean_param_update)\n",
    "    weights = []\n",
    "    for param_update in param_updates:\n",
    "        weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "    weights = weights / weights.sum()\n",
    "    weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "    nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "    nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "    print(f'g0_norm: {g0_norm}, '\n",
    "          f'weights_sum: {weights.sum()}, '\n",
    "          f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "    normalize_weights = []\n",
    "    for param_update in param_updates:\n",
    "        normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "    global_update = dict()\n",
    "    for name, params in model_updates.items():\n",
    "        if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "            global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "        else:\n",
    "            global_update[name] = torch.matmul(\n",
    "                weights,\n",
    "                params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "    return global_update\n",
    "\n",
    "def fltrust_half_maybe(roundsNum: List[int], dirPath: str, modelPath: str):\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    # gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    # maliciouses = []\n",
    "    gradientsList = []  # 里面存放每一轮的梯度，最后再聚合\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        # get model updates\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist/fltrust_{roundNum}.pth'\n",
    "        # print(pklName)\n",
    "        with open(pklName, 'rb') as f:\n",
    "            model_updates: Dict[str, torch.Tensor] = torch.load(f)\n",
    "        print(model_updates)\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            param_updates: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "        param_updates = torch.cat(list(param_updates.values()), dim=1)\n",
    "        # print(param_updates[list(param_updates.keys())[0]].shape)  # torch.Size([10, 12288])\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/clean_param_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            clean_param_update: torch.Tensor = pickle.load(f)\n",
    "        \n",
    "        # global_update = fltrust_original(model_updates, [param_updates[key] for key in param_updates.keys()], clean_param_update)\n",
    "        global_update = fltrust_original(model_updates, param_updates, clean_param_update)\n",
    "\n",
    "        # print(clean_param_update.shape)  # torch.Size([2674688])\n",
    "        thisGradients = [0] * clientPerRound\n",
    "\n",
    "\n",
    "        gradientsList.append(thisGradients)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPkl(roundNum: int, dirPath: str) -> Dict[str, torch.Tensor]:  # 把pkl变成{'key1': [[user3], [user5]]}\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "    print(pklPrefix, roundNum)\n",
    "    pklName = os.path.join(dirPath, f'model_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "    return update\n",
    "\n",
    "\"\"\"把pkl变成torch.Tensor([2674688])，即干净分量展平后的结果\"\"\"\n",
    "def loadPkl_clean(roundNum: int, dirPath: str) ->  torch.Tensor:\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]  # fmnist_EDGE_CASE\n",
    "    pklName = os.path.join(dirPath, f'clean_param_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: torch.Tensor = pickle.load(f)\n",
    "    # print(type(update))  # torch.Tensor\n",
    "    # print(update.shape)  # torch.Size([2674688])\n",
    "    # print(update[list(update.keys())[0]])\n",
    "    return update\n",
    "\n",
    "\"\"\"获取参与者列表\"\"\"\n",
    "def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:\n",
    "    participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "    participants = np.genfromtxt(\n",
    "        participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "    )\n",
    "    participants = participants[1:].T\n",
    "    participants_thisRound = participants[roundNum]  # 获取当前轮次的参与者\n",
    "    return participants_thisRound\n",
    "\n",
    "# # 通过历史记录的梯度计算恶意客户端\n",
    "# def calc_maliciousAndCos_justByGrads(roundsNum: List[int], dirPath: str):\n",
    "#     maliciousUpdates = []\n",
    "#     benignUpdates = []\n",
    "#     for th, roundNum in enumerate(roundsNum):\n",
    "#         update = loadPkl(roundNum, dirPath)\n",
    "#         update = torch.cat(list(update.values()), dim=1)\n",
    "#         participants = getParticipants(roundNum, dirPath)\n",
    "#         temp = torch.zeros(update.shape)\n",
    "#         # print(update.shape)  # torch.Size([10, 2674688])\n",
    "#         # print(temp.shape)\n",
    "#         for i in range(10):\n",
    "#             if participants[i] < 3:\n",
    "#                 maliciousUpdates.append(update[i].cpu().numpy())\n",
    "#             else:\n",
    "#                 benignUpdates.append(update[i].cpu().numpy())\n",
    "#     all = maliciousUpdates + benignUpdates\n",
    "#     cs = cosine_similarity(all)\n",
    "#     return cs\n",
    "\n",
    "def kmeans_clustering(updates_np, n_clusters=2):\n",
    "    return 0, [], 0\n",
    "    # 使用KMeans算法进行聚类\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(updates_np)\n",
    "\n",
    "    # 获取聚类标签\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # 识别被认为是恶意客户端的索引（假设第一个聚类为恶意客户端）\n",
    "    malicious_indices = np.where(labels == 0)[0] if n_clusters == 2 else []\n",
    "\n",
    "    return labels, malicious_indices, kmeans\n",
    "\n",
    "# 通过历史记录的梯度计算恶意客户端\n",
    "def calc_maliciousAndCos_justByGrads(roundsNum: List[int], dirPath: str):\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        # _, foolsgoldMaliciousIndex, _ = kmeans_clustering(gradients)\n",
    "        _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "            if thisMaliciousIndex < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "            maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    cs = smp.cosine_similarity(gradients_shuffled)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious_shuffled, cs_tensor\n",
    "\n",
    "\n",
    "def min_enclosing_ball(points, zeta, eta_prime, max_iter, lambda_thresh):\n",
    "    \"\"\"\n",
    "    使用迭代方法计算最小覆盖超球的球心和半径。\n",
    "    \n",
    "    参数:\n",
    "    - points: 客户端的历史梯度更新，形状为 (T, d)\n",
    "    - zeta: 覆盖比例\n",
    "    - eta_prime: 学习率\n",
    "    - max_iter: 最大迭代次数\n",
    "    - lambda_thresh: 收敛阈值\n",
    "    \n",
    "    返回:\n",
    "    - center: 球心（意图点）\n",
    "    - radius: 球半径\n",
    "    \"\"\"\n",
    "    # 确保 points 是二维数组\n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points.reshape(1, -1)\n",
    "    \n",
    "    # 初始化球心为所有点的均值\n",
    "    O_i = np.mean(points, axis=0)\n",
    "    # 初始化球半径为当前球心到所有点的最大距离\n",
    "    r_i = max(np.linalg.norm(O_i - points, axis=1))\n",
    "    \n",
    "    # 迭代优化球心和半径\n",
    "    for k in range(max_iter):\n",
    "        # 计算球心到每个点的方向向量\n",
    "        projection_points = []\n",
    "        for point in points:\n",
    "            direction = O_i - point\n",
    "            norm_direction = np.linalg.norm(direction)\n",
    "            if norm_direction == 0:\n",
    "                proj_point = point  # 如果球心和点重合，直接使用点作为投影点\n",
    "            else:\n",
    "                # 投影点的计算\n",
    "                proj_point = O_i + eta_prime * (point - O_i) / norm_direction\n",
    "            projection_points.append(proj_point)\n",
    "        \n",
    "        # 确保 projection_points 不为空\n",
    "        if len(projection_points) == 0:\n",
    "            break\n",
    "        \n",
    "        # 计算投影点到球心的距离\n",
    "        projection_points = np.array(projection_points)\n",
    "        distances = np.linalg.norm(O_i - projection_points, axis=1)\n",
    "\n",
    "        # 如果 selected_indices 为空，使用最大距离的点作为替代\n",
    "        if len(distances) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 选择前 zeta*T 个投影点\n",
    "        select_count = max(1, int(zeta * len(projection_points)))  # 确保至少选择一个点\n",
    "        selected_indices = np.argsort(distances)[:select_count]\n",
    "        \n",
    "        if len(selected_indices) == 0:\n",
    "            max_proj_point = projection_points[np.argmax(distances)]  # 使用最大距离的点\n",
    "        else:\n",
    "            max_proj_point = projection_points[selected_indices[-1]]  # 最远的投影点\n",
    "        \n",
    "        # 更新球心\n",
    "        O_i = O_i + eta_prime * (max_proj_point - O_i)\n",
    "        # 计算新的半径\n",
    "        r_new = max(np.linalg.norm(O_i - projection_points[selected_indices], axis=1))\n",
    "        \n",
    "        # 检查收敛条件\n",
    "        if abs(r_new - r_i) < lambda_thresh:\n",
    "            break\n",
    "        \n",
    "        r_i = r_new\n",
    "    \n",
    "    return O_i, r_i\n",
    "\n",
    "def calc_maliciousAndCos_justByGrads_SecFFT(roundsNum: List[int], dirPath: str, zeta=0.8, eta_prime=0.1, max_iter=100, lambda_thresh=1e-4):\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    # maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        # _, foolsgoldMaliciousIndex, _ = kmeans_clustering(gradients)\n",
    "        # _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        # for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "        #     if thisMaliciousIndex < maliciousPerRound:\n",
    "        #         thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "        #     else:\n",
    "        #         thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "        #     maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    # malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    intentions = []\n",
    "    for grad in gradients_shuffled:\n",
    "        grad = np.array(grad)\n",
    "        # 使用最小覆盖球算法计算意图点\n",
    "        center, radius = min_enclosing_ball(grad, zeta, eta_prime, max_iter, lambda_thresh)\n",
    "        intentions.append(center)  # 意图点是球心\n",
    "    # print(intentions)\n",
    "    # print(len(intentions))\n",
    "    # for n_neighbors in range(1, 52):\n",
    "    #     lof = LocalOutlierFactor(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    #     lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    #     detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    #     print(f'n_neighbors = {n_neighbors}, len(detected_malicious) = {len(detected_malicious)}')\n",
    "    # n_neighbors = 1, len(detected_malicious) = 0\n",
    "    # n_neighbors = 2, len(detected_malicious) = 0\n",
    "    # n_neighbors = 3, len(detected_malicious) = 0\n",
    "    # n_neighbors = 4, len(detected_malicious) = 0\n",
    "    # n_neighbors = 5, len(detected_malicious) = 0\n",
    "    # n_neighbors = 6, len(detected_malicious) = 0\n",
    "    # n_neighbors = 7, len(detected_malicious) = 0\n",
    "    # n_neighbors = 8, len(detected_malicious) = 0\n",
    "    # n_neighbors = 9, len(detected_malicious) = 0\n",
    "    # n_neighbors = 10, len(detected_malicious) = 0\n",
    "    # n_neighbors = 11, len(detected_malicious) = 0\n",
    "    # n_neighbors = 12, len(detected_malicious) = 0\n",
    "    # n_neighbors = 13, len(detected_malicious) = 0\n",
    "    # n_neighbors = 14, len(detected_malicious) = 0\n",
    "    # n_neighbors = 15, len(detected_malicious) = 15\n",
    "    # n_neighbors = 16, len(detected_malicious) = 15\n",
    "    # n_neighbors = 17, len(detected_malicious) = 15\n",
    "    # n_neighbors = 18, len(detected_malicious) = 15\n",
    "    # n_neighbors = 19, len(detected_malicious) = 15\n",
    "    # n_neighbors = 20, len(detected_malicious) = 15\n",
    "    # n_neighbors = 21, len(detected_malicious) = 15\n",
    "    # n_neighbors = 22, len(detected_malicious) = 15\n",
    "    # n_neighbors = 23, len(detected_malicious) = 15\n",
    "    # n_neighbors = 24, len(detected_malicious) = 15\n",
    "    # n_neighbors = 25, len(detected_malicious) = 15\n",
    "    # n_neighbors = 26, len(detected_malicious) = 15\n",
    "    # n_neighbors = 27, len(detected_malicious) = 15\n",
    "    # n_neighbors = 28, len(detected_malicious) = 15\n",
    "    # n_neighbors = 29, len(detected_malicious) = 15\n",
    "    # n_neighbors = 30, len(detected_malicious) = 15\n",
    "    # n_neighbors = 31, len(detected_malicious) = 15\n",
    "    # n_neighbors = 32, len(detected_malicious) = 15\n",
    "    # n_neighbors = 33, len(detected_malicious) = 15\n",
    "    # n_neighbors = 34, len(detected_malicious) = 15\n",
    "    # n_neighbors = 35, len(detected_malicious) = 0\n",
    "    # n_neighbors = 36, len(detected_malicious) = 0\n",
    "    # n_neighbors = 37, len(detected_malicious) = 0\n",
    "    # n_neighbors = 38, len(detected_malicious) = 0\n",
    "    # n_neighbors = 39, len(detected_malicious) = 0\n",
    "    # n_neighbors = 40, len(detected_malicious) = 0\n",
    "    # n_neighbors = 41, len(detected_malicious) = 0\n",
    "    # n_neighbors = 42, len(detected_malicious) = 0\n",
    "    # n_neighbors = 43, len(detected_malicious) = 0\n",
    "    # n_neighbors = 44, len(detected_malicious) = 0\n",
    "    # n_neighbors = 45, len(detected_malicious) = 0\n",
    "    # n_neighbors = 46, len(detected_malicious) = 0\n",
    "    # n_neighbors = 47, len(detected_malicious) = 0\n",
    "    # n_neighbors = 48, len(detected_malicious) = 0\n",
    "    # n_neighbors = 49, len(detected_malicious) = 0\n",
    "    # n_neighbors = 50, len(detected_malicious) = 0\n",
    "    # WC!!!!识别效果还真不错！！！\n",
    "    lof = LocalOutlierFactor(n_neighbors=int(50 * 0.4), metric='euclidean')\n",
    "    lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    print(detected_malicious)\n",
    "    cs = cosine_similarity(intentions)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return detected_malicious, cs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_attack_size(gradients, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    限制前 20 个恶意客户端的梯度更新大小。\n",
    "    \n",
    "    参数:\n",
    "    - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "    - scaling_factor: 用于限制恶意客户端梯度大小的缩放因子。默认值为 0.1。\n",
    "    \n",
    "    返回:\n",
    "    - new_gradients: 经过处理后的梯度更新列表，前 20 个恶意客户端的更新被限制大小。\n",
    "    \"\"\"\n",
    "    # 确保输入是一个包含50个客户端梯度的列表\n",
    "    assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "    # 复制原始梯度列表以避免修改原始数据\n",
    "    new_gradients = gradients.copy()\n",
    "    \n",
    "    # 限制前20个恶意客户端的梯度更新大小\n",
    "    for i in range(20):  # 前20个是恶意客户端\n",
    "        # 获取当前客户端的梯度更新\n",
    "        original_grad = new_gradients[i]\n",
    "        # 使用缩放因子限制梯度大小\n",
    "        limited_grad = original_grad * scaling_factor\n",
    "        # 更新新的梯度\n",
    "        new_gradients[i] = limited_grad\n",
    "    \n",
    "    return new_gradients\n",
    "\n",
    "# def limit_attack_direction(gradients, mixing_factor=0.1):\n",
    "#     \"\"\"\n",
    "#     限制前 15 个恶意客户端的梯度方向，使其与正常客户端的梯度方向更相似。\n",
    "    \n",
    "#     参数:\n",
    "#     - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "#     - mixing_factor: 用于混合恶意客户端梯度方向和正常客户端平均梯度方向的因子。默认值为 0.9。\n",
    "    \n",
    "#     返回:\n",
    "#     - new_gradients: 经过处理后的梯度更新列表，前 15 个恶意客户端的更新被调整方向。\n",
    "#     \"\"\"\n",
    "#     # 确保输入是一个包含50个客户端梯度的列表\n",
    "#     assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "#     # 复制原始梯度列表以避免修改原始数据\n",
    "#     new_gradients = gradients.copy()\n",
    "    \n",
    "#     # 计算正常客户端的平均梯度方向（客户端 16 到 50）\n",
    "#     normal_gradients = np.array(new_gradients[15:])  # 获取正常客户端的梯度\n",
    "#     average_normal_gradient = np.mean(normal_gradients, axis=0)  # 计算平均梯度方向\n",
    "    \n",
    "#     # 对平均梯度进行归一化\n",
    "#     average_normal_gradient /= np.linalg.norm(average_normal_gradient)\n",
    "    \n",
    "#     # 调整前 15 个恶意客户端的梯度方向\n",
    "#     for i in range(15):  # 前15个是恶意客户端\n",
    "#         # 获取当前恶意客户端的梯度更新\n",
    "#         original_grad = new_gradients[i]\n",
    "        \n",
    "#         # 对原始梯度进行归一化\n",
    "#         original_grad /= np.linalg.norm(original_grad)\n",
    "        \n",
    "#         # 将恶意客户端的梯度方向调整为与正常客户端的平均梯度方向更相似\n",
    "#         adjusted_grad = mixing_factor * average_normal_gradient + (1 - mixing_factor) * original_grad\n",
    "        \n",
    "#         # 重新调整梯度的大小为原始大小\n",
    "#         adjusted_grad *= np.linalg.norm(gradients[i])\n",
    "        \n",
    "#         # 更新新的梯度\n",
    "#         new_gradients[i] = adjusted_grad\n",
    "    \n",
    "#     return new_gradients\n",
    "\n",
    "def limit_attack_direction(gradients, mixing_factor=0.4):\n",
    "    \"\"\"\n",
    "    限制前 15 个恶意客户端的梯度方向，使其随机向一个良性客户端的梯度方向偏移。\n",
    "    \n",
    "    参数:\n",
    "    - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "    - mixing_factor: 用于混合恶意客户端梯度方向和随机选择的良性客户端梯度方向的因子。默认值为 0.9。\n",
    "    \n",
    "    返回:\n",
    "    - new_gradients: 经过处理后的梯度更新列表，前 15 个恶意客户端的更新被调整方向。\n",
    "    \"\"\"\n",
    "    # 确保输入是一个包含50个客户端梯度的列表\n",
    "    assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "    # 复制原始梯度列表以避免修改原始数据\n",
    "    new_gradients = gradients.copy()\n",
    "    \n",
    "    # 对前 20 个恶意客户端进行处理\n",
    "    for i in range(20):  # 前20个是恶意客户端\n",
    "        # 随机选择一个良性客户端（20到50的索引是20到49）\n",
    "        random_benign_index = np.random.randint(20, 50)\n",
    "        benign_grad = new_gradients[random_benign_index]\n",
    "        \n",
    "        # 获取当前恶意客户端的梯度更新\n",
    "        original_grad = new_gradients[i]\n",
    "        \n",
    "        # 对恶意客户端和选中的良性客户端的梯度进行归一化\n",
    "        original_grad_normalized = original_grad / np.linalg.norm(original_grad)\n",
    "        benign_grad_normalized = benign_grad / np.linalg.norm(benign_grad)\n",
    "        \n",
    "        # 将恶意客户端的梯度方向调整为向良性客户端方向偏移\n",
    "        adjusted_grad = mixing_factor * benign_grad_normalized + (1 - mixing_factor) * original_grad_normalized\n",
    "        \n",
    "        # 重新调整梯度的大小为原始大小\n",
    "        adjusted_grad *= np.linalg.norm(gradients[i])\n",
    "        \n",
    "        # 更新新的梯度\n",
    "        new_gradients[i] = adjusted_grad\n",
    "    \n",
    "    return new_gradients\n",
    "\n",
    "def identify_malicious_clients(cosine_similarity_tensor, threshold=5):\n",
    "    \"\"\"\n",
    "    识别余弦相似度矩阵中的恶意客户端。\n",
    "    \n",
    "    参数:\n",
    "    cosine_similarity_tensor (torch.Tensor): 50x50的余弦相似度张量\n",
    "    threshold (float): 用于层次聚类的距离阈值\n",
    "    \n",
    "    返回:\n",
    "    List[int]: 恶意客户端的下标\n",
    "    \"\"\"\n",
    "    # 将 PyTorch 张量转换为 NumPy 数组\n",
    "    data = cosine_similarity_tensor.numpy()\n",
    "\n",
    "    # 对称化矩阵（确保余弦相似度矩阵是对称的）\n",
    "    data = (data + data.T) / 2\n",
    "\n",
    "    # 数据标准化\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    # 计算层次聚类的链接矩阵\n",
    "    Z = linkage(data_scaled, method='ward')\n",
    "\n",
    "    # 根据距离阈值对客户端进行聚类\n",
    "    clusters = fcluster(Z, t=threshold, criterion='distance')\n",
    "\n",
    "    # 找出每个簇的大小\n",
    "    cluster_counts = np.bincount(clusters)\n",
    "\n",
    "    # 识别恶意客户端所在的簇（假设簇中客户端数量较少的为恶意客户端）\n",
    "    malicious_clusters = np.where(cluster_counts <= 2)[0]  # 这里我们假设小于等于2个客户端的簇为恶意簇\n",
    "\n",
    "    # 找出恶意客户端的下标\n",
    "    malicious_clients = [index for index, cluster_label in enumerate(clusters) if cluster_label in malicious_clusters]\n",
    "\n",
    "    return malicious_clients\n",
    "\n",
    "# 通过历史记录的梯度计算恶意客户端 | 0是限制大小，1是限制大小和角度\n",
    "def calc_maliciousAndCos_justByGrads_limited(roundsNum: List[int], dirPath: str, limistedMethod=0):  # limistedMethod: 0-限制大小，1-限制方向\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    if limistedMethod == 0:\n",
    "        gradients_limited = limit_attack_size(gradients_shuffled)\n",
    "    else:\n",
    "        gradients_limited = limit_attack_direction(gradients_shuffled)\n",
    "    cs = smp.cosine_similarity(gradients_limited)\n",
    "    malicious = identify_malicious_clients(torch.from_numpy(cs)) \n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious, cs_tensor\n",
    "\n",
    "def calc_maliciousAndCos_justByGrads_limited_SecFFT(roundsNum: List[int], dirPath: str, limistedMethod=0, zeta=0.8, eta_prime=0.1, max_iter=100, lambda_thresh=1e-4):\n",
    "    clientPerRound = 50  # 这里就先写死了  再不写死就写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    # malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    if limistedMethod == 0:\n",
    "        gradients_limited = limit_attack_size(gradients_shuffled)\n",
    "    else:\n",
    "        gradients_limited = limit_attack_direction(gradients_shuffled)\n",
    "    intentions = []\n",
    "    for grad in gradients_limited:\n",
    "        grad = np.array(grad)\n",
    "        # 使用最小覆盖球算法计算意图点\n",
    "        center, radius = min_enclosing_ball(grad, zeta, eta_prime, max_iter, lambda_thresh)\n",
    "        intentions.append(center)  # 意图点是球心\n",
    "    # lof = LocalOutlierFactor(n_neighbors=int(50 * 0.4), metric='euclidean')\n",
    "    # lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    # detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    # print(detected_malicious)\n",
    "    cs = cosine_similarity(intentions)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return cs_tensor\n",
    "\n",
    "\"\"\"\n",
    "这是一段屎山代码，建议读者别看了还是。。。\n",
    "对于攻击方式：0是限制大小，1是限制大小和角度，其他值是不做限制\n",
    "\"\"\"\n",
    "def fltrust_R1(roundNum: int, dirPath: str, limistedMethod: int=-1):\n",
    "    clientPerRound = 50  # 这里就先写死了\n",
    "    maliciousPerRound = 20\n",
    "    gradients = [0] * clientPerRound\n",
    "    participants = getParticipants(roundNum, dirPath)\n",
    "    print('participants:', participants)\n",
    "    model_updates = loadPkl(roundNum, dirPath)\n",
    "    keys = list(model_updates.keys())\n",
    "    # last_layer_updates = model_updates[keys[-2]]\n",
    "    # K = len(last_layer_updates)\n",
    "    # print(K)  # 50\n",
    "    K = len(model_updates[keys[0]])\n",
    "    # print(type(model_updates))  # dict\n",
    "    # print(keys[-2])  # base_model.model.visual_projection.lora_A.default.weight  # 当时为什么要这么做来着\n",
    "    # print(K)  # 50\n",
    "    for i in range(K):\n",
    "        # original # gradients[i] = last_layer_updates[i].cpu().numpy()\n",
    "        # debug = list(model_updates[key][i] for key in keys)\n",
    "        # print(len(debug), len(debug) == len(keys))  # 146 True\n",
    "        # print(torch.cat((torch.tensor([0]), torch.tensor([]), torch.tensor([1, 2]), torch.tensor([3, 4]), torch.tensor([5, 6])), dim=0))  # tensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "        gradients[i] = torch.cat(list(model_updates[key][i] for key in keys), dim=0)\n",
    "    # print(len(gradients[0]))  # 2674688\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[maliciousPerRound:50])\n",
    "    gradients_shuffled: List[np.ndarray] = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    if limistedMethod == 0:\n",
    "        gradients_shuffled = limit_attack_size([thisGradient.cpu() for thisGradient in gradients_shuffled])\n",
    "    else:\n",
    "        gradients_shuffled = limit_attack_direction([thisGradient.cpu() for thisGradient in gradients_shuffled])\n",
    "    gradients_shuffled = [thisGradient.to('cuda:0') for thisGradient in gradients_shuffled]\n",
    "\n",
    "    # https://github.com/LetMeFly666/SecFFT/blob/0f829a07a55b66336fccd33fb9dedacb1f8103b0/NormalRun/FL_Backdoor_CV/roles/aggregation_rules.py#L301-L340\n",
    "    # 从这里开始融合fltrust的代码\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    clean_param_update = loadPkl_clean(roundNum, dirPath)\n",
    "    g0_norm = torch.norm(clean_param_update)\n",
    "    weights = []\n",
    "    # for param_update in param_updates:\n",
    "    for param_update in gradients_shuffled:\n",
    "        # print(type(param_update))  # <class 'numpy.ndarray'>\n",
    "        # param_update = np.ndarray(param_update)\n",
    "        param_update = torch.tensor(param_update)\n",
    "        weights.append(\n",
    "            F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1)))\n",
    "            # F.relu(cos(param_update.reshape(-1, 1), clean_param_update.reshape(-1, 1)))\n",
    "        )\n",
    "    weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "    weights = weights / weights.sum()\n",
    "    weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "    nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "    nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "    # print(type(weights))  # <class 'torch.Tensor'>\n",
    "    # print(weights.type())  # torch.cuda.FloatTensor\n",
    "    # print(weights.shape)  # torch.Size([1, 50])\n",
    "    weights = weights.squeeze()\n",
    "    print(weights.shape)  # torch.Size([50])\n",
    "    # 扩展 weights 的维度\n",
    "    weights_i = weights.unsqueeze(0)  # 变成 [1, 50]\n",
    "    weights_j = weights.unsqueeze(1)  # 变成 [50, 1]\n",
    "    # 计算差的绝对值\n",
    "    cs = torch.abs(weights_i - weights_j)\n",
    "    # print(cs.shape)  # 输出: torch.Size([50, 50])\n",
    "    # print(cs)\n",
    "    return list(range(20)), cs  # TODO: 计算真正的恶意客户端的下标\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(identified_malicious: List[int]) -> Tuple:\n",
    "    total_clients = 50\n",
    "    malicious_clients = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}  # 实际恶意客户端的索引\n",
    "\n",
    "    # 计算TP, FP, TN, FN\n",
    "    TP = len(malicious_clients.intersection(identified_malicious))\n",
    "    FP = len(set(identified_malicious) - malicious_clients)\n",
    "    FN = len(malicious_clients - set(identified_malicious))\n",
    "    TN = total_clients - TP - FP - FN\n",
    "\n",
    "    # 准确率（Accuracy）\n",
    "    accuracy = (TP + TN) / total_clients\n",
    "\n",
    "    # 精确率（Precision）\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    # 召回率（Recall）\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # 特异度（Specificity）\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "    # 误报率（False Positive Rate, FPR）\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "    # 假阴率（False Negative Rate, FNR）\n",
    "    fnr = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # 计算AUC（此处假设预测的概率值，以便计算AUC）\n",
    "    y_true = [1 if i in malicious_clients else 0 for i in range(total_clients)]\n",
    "    y_scores = [1 if i in identified_malicious else 0 for i in range(total_clients)]\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    # 计算MCC（Matthews Correlation Coefficient）\n",
    "    mcc = matthews_corrcoef(y_true, y_scores)\n",
    "\n",
    "    return TP, FP, TN, FN, accuracy, precision, recall, specificity, fpr, fnr, auc, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmnist_EDGE_CASE 0\n",
      "fmnist_EDGE_CASE 0\n",
      "识别出的恶意客户端索引: [ 0  2  3  4  5  6  7  8 10 11 13 14 15 19 20 22 25 30 31 39 41 44 49]\n",
      "[0.51783742 0.77617793 0.05523994 0.         0.05652815 0.20296554\n",
      " 0.2665428  0.10373496 0.38173459 0.88522624 0.23830896 0.28134212\n",
      " 1.         0.         0.03112494 0.10554161 0.7590076  1.\n",
      " 1.         0.05523994 0.48196315 1.         0.35145769 1.\n",
      " 0.98500309 0.57594935 1.         0.861408   1.         0.66079973\n",
      " 0.33602985 0.47051524 1.         0.90201588 0.68015209 1.\n",
      " 0.86280357 1.         0.94510256 0.35145769 0.87676408 0.33602985\n",
      " 1.         1.         0.47051524 0.75068461 1.         1.\n",
      " 1.         0.54801338]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 0\n",
      "fmnist_EDGE_CASE 0\n",
      "识别出的恶意客户端索引: [ 0  2  3  4  5  6  7  8 10 11 13 14 15 19 20 22 25 30 31 39 41 44 49]\n",
      "[0.51783742 0.77617793 0.05523994 0.         0.05652815 0.20296554\n",
      " 0.2665428  0.10373496 0.38173459 0.88522624 0.23830896 0.28134212\n",
      " 1.         0.         0.03112494 0.10554161 0.7590076  1.\n",
      " 1.         0.05523994 0.48196315 1.         0.35145769 1.\n",
      " 0.98500309 0.57594935 1.         0.861408   1.         0.66079973\n",
      " 0.33602985 0.47051524 1.         0.90201588 0.68015209 1.\n",
      " 0.86280357 1.         0.94510256 0.35145769 0.87676408 0.33602985\n",
      " 1.         1.         0.47051524 0.75068461 1.         1.\n",
      " 1.         0.54801338]\n",
      "fmnist_EDGE_CASE 0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "fmnist_EDGE_CASE 0\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 0\n",
      "fmnist_EDGE_CASE 0\n",
      "fmnist_EDGE_CASE 0\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 0\n",
      "fmnist_EDGE_CASE 0\n",
      "[0, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 18, 19, 26, 29, 34, 35, 37, 38, 40, 42, 45]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 18, 19, 26, 29, 34, 35, 37, 38, 40, 42, 45]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "----------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(14, 9, 21, 6, 0.7, 0.6086956521739131, 0.7, 0.7, 0.3, 0.3, np.float64(0.7), np.float64(0.3931785497463923))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(14, 9, 21, 6, 0.7, 0.6086956521739131, 0.7, 0.7, 0.3, 0.3, np.float64(0.7), np.float64(0.3931785497463923))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "fmnist_EDGE_CASE 1\n",
      "fmnist_EDGE_CASE 1\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         0.91243812 0.7775562  1.         1.\n",
      " 1.         1.         1.         1.         1.         0.7775562\n",
      " 1.         1.         1.         0.91243812 1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.10948533 0.10948533 0.         0.13613208 0.20774958 0.\n",
      " 0.05617114 0.         0.         0.         0.02016872 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.08183235 0.         0.03546699\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 1\n",
      "fmnist_EDGE_CASE 1\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         0.89121419 1.         1.         0.88575325\n",
      " 1.         1.         1.         1.         0.99752836 1.\n",
      " 1.         1.         0.88575325 0.89121419 1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.28828143 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "fmnist_EDGE_CASE 1\n",
      "[]\n",
      "fmnist_EDGE_CASE 1\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 1\n",
      "fmnist_EDGE_CASE 1\n",
      "fmnist_EDGE_CASE 1\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 1\n",
      "fmnist_EDGE_CASE 1\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 2\n",
      "fmnist_EDGE_CASE 2\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 19]\n",
      "[0.75594684 1.         0.7336034  1.         0.75594684 1.\n",
      " 1.         0.87462786 0.63954918 1.         1.         0.7336034\n",
      " 1.         1.         0.63954918 1.         0.29655426 0.29655426\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 2\n",
      "fmnist_EDGE_CASE 2\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.68176651 0.68176651 0.58318271 1.         1.         0.97540729\n",
      " 1.         0.4962368  1.         0.83142191 0.69224466 0.58318271\n",
      " 1.         0.651489   0.58777081 0.88707773 0.61351764 0.4962368\n",
      " 0.87415585 0.73697245 0.         0.         0.03116634 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04513003 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.23633613 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "fmnist_EDGE_CASE 2\n",
      "[]\n",
      "fmnist_EDGE_CASE 2\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 2\n",
      "fmnist_EDGE_CASE 2\n",
      "fmnist_EDGE_CASE 2\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 2\n",
      "fmnist_EDGE_CASE 2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[3, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19, 34, 36]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[3, 5, 9, 14, 15, 21, 33, 36, 44, 46]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 3\n",
      "fmnist_EDGE_CASE 3\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         0.779484   0.91350095 0.71860293 1.         0.779484\n",
      " 0.71860293 1.         1.         1.         1.         1.\n",
      " 1.         0.91350095 0.         0.         0.         0.\n",
      " 0.01171448 0.         0.         0.         0.         0.\n",
      " 0.         0.16062245 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 3\n",
      "fmnist_EDGE_CASE 3\n",
      "识别出的恶意客户端索引: [20 21 22 24 25 26 28 30 31 32 33 35 37 38 39 40 41 42 44 46 47 48 49]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.46538231 0.41979728 0.52738503 0.73664307\n",
      " 0.66990845 0.5738497  0.42751457 0.94015632 0.54796353 0.83004345\n",
      " 0.31302784 0.56577728 0.5323808  0.41351652 0.8704328  0.37233849\n",
      " 0.80175875 0.29937275 0.31302784 0.45147867 0.68938195 0.61383718\n",
      " 0.52150209 1.         0.29937275 0.9010081  0.48318313 0.58440767\n",
      " 0.45300243 0.37233849]\n",
      "fmnist_EDGE_CASE 3\n",
      "[]\n",
      "fmnist_EDGE_CASE 3\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 3\n",
      "fmnist_EDGE_CASE 3\n",
      "fmnist_EDGE_CASE 3\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 3\n",
      "fmnist_EDGE_CASE 3\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 4\n",
      "fmnist_EDGE_CASE 4\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11468597\n",
      " 0.         0.         0.         0.04223619 0.         0.\n",
      " 0.         0.         0.08349031 0.1140564  0.28634374 0.00310075\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 4\n",
      "fmnist_EDGE_CASE 4\n",
      "识别出的恶意客户端索引: [20 21 22 24 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 47 48]\n",
      "[1.         1.         0.94473323 1.         0.72037091 0.72037091\n",
      " 0.86094881 1.         0.89671657 1.         1.         1.\n",
      " 0.83696552 1.         1.         1.         1.         0.86094881\n",
      " 1.         0.83696552 0.53924215 0.2033983  0.44098919 1.\n",
      " 0.5524433  0.78880712 0.54873728 0.51650916 0.75901686 0.30463185\n",
      " 0.51863805 0.40328454 0.52114105 0.5831148  0.51438029 0.63565222\n",
      " 0.22921444 0.26926924 0.42483506 0.29419123 0.49448694 0.22921444\n",
      " 0.40328454 0.61083542 0.2033983  0.87895532 0.71953778 0.64745753\n",
      " 0.59500917 0.82726472]\n",
      "fmnist_EDGE_CASE 4\n",
      "[]\n",
      "fmnist_EDGE_CASE 4\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 4\n",
      "fmnist_EDGE_CASE 4\n",
      "fmnist_EDGE_CASE 4\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 4\n",
      "fmnist_EDGE_CASE 4\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 3, 4, 5, 7, 8, 11, 12, 14, 15, 16, 17, 18, 34]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 5\n",
      "fmnist_EDGE_CASE 5\n",
      "识别出的恶意客户端索引: [ 0  1  2  4  8 11 12 14 15 17 18 19]\n",
      "[1.         0.70710473 0.6360611  0.2291898  1.         0.45710702\n",
      " 0.40805494 0.2291898  1.         0.47449919 0.34074674 1.\n",
      " 0.95549807 0.45868642 1.         1.         0.4356366  1.\n",
      " 0.59754138 0.88044956 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 5\n",
      "fmnist_EDGE_CASE 5\n",
      "识别出的恶意客户端索引: [41 44]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.89464148 1.         1.         1.         0.89464148\n",
      " 1.         1.         1.         0.98565756 1.         0.72145666\n",
      " 1.         1.         0.72145666 1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 5\n",
      "[]\n",
      "fmnist_EDGE_CASE 5\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 5\n",
      "fmnist_EDGE_CASE 5\n",
      "fmnist_EDGE_CASE 5\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 5\n",
      "fmnist_EDGE_CASE 5\n",
      "[0, 3, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 3, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(12, 0, 30, 8, 0.84, 1.0, 0.6, 1.0, 0.0, 0.4, np.float64(0.8), np.float64(0.6882472016116853))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(12, 0, 30, 8, 0.84, 1.0, 0.6, 1.0, 0.0, 0.4, np.float64(0.8), np.float64(0.6882472016116853))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 6\n",
      "fmnist_EDGE_CASE 6\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 0.83906707 1.         1.         1.         1.         0.81425196\n",
      " 1.         1.         1.         1.         1.         0.83906707\n",
      " 0.81425196 1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00853065 0.         0.         0.         0.\n",
      " 0.         0.03703612 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 6\n",
      "fmnist_EDGE_CASE 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: []\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 6\n",
      "[]\n",
      "fmnist_EDGE_CASE 6\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 6\n",
      "fmnist_EDGE_CASE 6\n",
      "fmnist_EDGE_CASE 6\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 6\n",
      "fmnist_EDGE_CASE 6\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 30, 43]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 7\n",
      "fmnist_EDGE_CASE 7\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         0.66715063 1.         1.         1.\n",
      " 1.         0.9673291  0.78181647 1.         1.         1.\n",
      " 1.         1.         0.9673291  1.         1.         1.\n",
      " 1.         0.66715063 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 7\n",
      "fmnist_EDGE_CASE 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: []\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 7\n",
      "[]\n",
      "fmnist_EDGE_CASE 7\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 7\n",
      "fmnist_EDGE_CASE 7\n",
      "fmnist_EDGE_CASE 7\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 7\n",
      "fmnist_EDGE_CASE 7\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 34]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 8\n",
      "fmnist_EDGE_CASE 8\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 19]\n",
      "[0.98421465 0.7727477  1.         1.         0.84161388 0.86008391\n",
      " 1.         0.26505464 0.72744008 1.         1.         1.\n",
      " 0.74087572 0.7996712  0.69458663 0.6213958  0.48848793 1.\n",
      " 0.26505464 0.48848793 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 8\n",
      "fmnist_EDGE_CASE 8\n",
      "识别出的恶意客户端索引: [ 2  3  5  7  8 10 16 17 18 19]\n",
      "[1.         0.91234569 0.79131288 0.68386922 1.         0.65229796\n",
      " 1.         0.72734635 0.79131288 1.         0.81618717 1.\n",
      " 1.         1.         1.         1.         0.68386922 0.65229796\n",
      " 0.71244594 0.70634718 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 8\n",
      "[]\n",
      "fmnist_EDGE_CASE 8\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 8\n",
      "fmnist_EDGE_CASE 8\n",
      "fmnist_EDGE_CASE 8\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 8\n",
      "fmnist_EDGE_CASE 8\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 9\n",
      "fmnist_EDGE_CASE 9\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         0.58864032 1.         0.58864032 1.         0.84488503\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.87467418 0.84321198 0.84321198 1.         1.\n",
      " 0.65019728 1.         0.         0.         0.         0.\n",
      " 0.0596421  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13990297 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 9\n",
      "fmnist_EDGE_CASE 9\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  5  6  7  8  9 11 12 13 14 15 17 18 19]\n",
      "[0.31164613 0.4500142  0.35831338 0.51936193 0.75591505 0.35831338\n",
      " 0.31164613 0.35232816 0.62961469 0.69701976 1.         0.4500142\n",
      " 0.39887676 0.39887676 0.64600565 0.51779933 1.         0.72310488\n",
      " 0.68518068 0.35232816 0.99542842 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99542842 1.        ]\n",
      "fmnist_EDGE_CASE 9\n",
      "[]\n",
      "fmnist_EDGE_CASE 9\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 9\n",
      "fmnist_EDGE_CASE 9\n",
      "fmnist_EDGE_CASE 9\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 9\n",
      "fmnist_EDGE_CASE 9\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 10\n",
      "fmnist_EDGE_CASE 10\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         0.66388061 0.86611616 1.         0.61514146\n",
      " 1.         0.87661699 1.         1.         0.94990481 1.\n",
      " 1.         1.         1.         0.86469529 0.9878666  1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28809302 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 10\n",
      "fmnist_EDGE_CASE 10\n",
      "识别出的恶意客户端索引: [ 0  1  3  6  8 10 14 16 17 19]\n",
      "[0.61072453 0.70906106 0.92193791 0.70906106 1.         0.97211215\n",
      " 0.7579144  0.98066668 0.78982049 0.92193791 0.4552495  1.\n",
      " 0.98066668 1.         0.4552495  0.99028332 0.61072453 0.61404473\n",
      " 1.         0.61404473 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 10\n",
      "[]\n",
      "fmnist_EDGE_CASE 10\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 10\n",
      "fmnist_EDGE_CASE 10\n",
      "fmnist_EDGE_CASE 10\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 10\n",
      "fmnist_EDGE_CASE 10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 31, 47]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 11\n",
      "fmnist_EDGE_CASE 11\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         0.74124931 0.75398743 0.46114575 0.60978942 0.54819308\n",
      " 1.         0.90888891 0.6647462  0.58629671 1.         0.41526134\n",
      " 0.46114575 0.73714594 1.         0.84375875 1.         0.60023748\n",
      " 0.41526134 0.89614281 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 11\n",
      "fmnist_EDGE_CASE 11\n",
      "识别出的恶意客户端索引: [ 1  2  4  5  6  7  8  9 11 13 14 16 17 18 19]\n",
      "[0.84143862 0.81231312 0.72531621 1.         0.56844354 0.81231312\n",
      " 0.66407482 0.65743012 0.56844354 0.54126637 1.         0.61274158\n",
      " 1.         0.65743012 0.59279939 1.         0.73321406 0.73851552\n",
      " 0.59279939 0.54126637 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 11\n",
      "[]\n",
      "fmnist_EDGE_CASE 11\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 11\n",
      "fmnist_EDGE_CASE 11\n",
      "fmnist_EDGE_CASE 11\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 11\n",
      "fmnist_EDGE_CASE 11\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 12\n",
      "fmnist_EDGE_CASE 12\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 18 19]\n",
      "[0.8671531  0.97712955 0.96560158 1.         0.45096896 1.\n",
      " 1.         1.         1.         1.         1.         0.92356162\n",
      " 1.         1.         1.         0.99871057 1.         0.45096896\n",
      " 0.81240503 0.95986369 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 12\n",
      "fmnist_EDGE_CASE 12\n",
      "识别出的恶意客户端索引: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.27357901 0.34834918 0.         0.68189668 0.3481392  0.\n",
      " 0.54840038 0.3481392  0.25514287 0.33183161 0.60810939 0.35466613\n",
      " 0.38347157 0.58881873 0.62947587 0.3038073  0.49173986 0.11299405\n",
      " 0.28489819 0.11299405 1.         1.         1.         1.\n",
      " 1.         0.95237046 1.         1.         1.         1.\n",
      " 0.9443484  1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.92770278 0.95237046 1.         1.         1.\n",
      " 0.92770278 0.9443484 ]\n",
      "fmnist_EDGE_CASE 12\n",
      "[]\n",
      "fmnist_EDGE_CASE 12\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 12\n",
      "fmnist_EDGE_CASE 12\n",
      "fmnist_EDGE_CASE 12\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 12\n",
      "fmnist_EDGE_CASE 12\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(18, 0, 30, 2, 0.96, 1.0, 0.9, 1.0, 0.0, 0.1, np.float64(0.95), np.float64(0.9185586535436917))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 13\n",
      "fmnist_EDGE_CASE 13\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.0855616  0.10327801 0.         0.\n",
      " 0.17408245 0.02639658 0.         0.         0.         0.\n",
      " 0.         0.         0.23705145 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2149009  0.23705145\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 13\n",
      "fmnist_EDGE_CASE 13\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  8 10 11 12 14 17 18 19]\n",
      "[0.03173528 0.07837126 0.03173528 0.47535062 0.47933712 0.40361707\n",
      " 0.4059274  0.8690521  0.23134813 1.         0.07837126 0.06498951\n",
      " 0.58851849 0.95657947 0.45639004 0.71362388 1.         0.06906636\n",
      " 0.29718897 0.48211049 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 13\n",
      "[]\n",
      "fmnist_EDGE_CASE 13\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 13\n",
      "fmnist_EDGE_CASE 13\n",
      "fmnist_EDGE_CASE 13\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 13\n",
      "fmnist_EDGE_CASE 13\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 48]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 14\n",
      "fmnist_EDGE_CASE 14\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.07382873 0.         0.         0.138835   0.         0.064656\n",
      " 0.         0.         0.         0.         0.04522469 0.\n",
      " 0.         0.         0.         0.09438065 0.         0.\n",
      " 0.         0.         0.         0.07311445 0.17803784 0.\n",
      " 0.         0.04332549]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 14\n",
      "fmnist_EDGE_CASE 14\n",
      "识别出的恶意客户端索引: [ 0  2  4  5  6  7  9 11 12 13 15 16 17 18 19]\n",
      "[0.32489225 1.         0.33602233 0.71255631 0.3064368  0.31423997\n",
      " 0.33602233 0.38987264 0.95148966 0.47541016 0.7506601  0.34532577\n",
      " 0.3064368  0.58274718 0.84351511 0.34532577 0.4682843  0.64169531\n",
      " 0.3706364  0.31423997 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 14\n",
      "[]\n",
      "fmnist_EDGE_CASE 14\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 14\n",
      "fmnist_EDGE_CASE 14\n",
      "fmnist_EDGE_CASE 14\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 14\n",
      "fmnist_EDGE_CASE 14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 15\n",
      "fmnist_EDGE_CASE 15\n",
      "识别出的恶意客户端索引: [ 1  2  3  4  5  6  7  9 10 11 13 14 15 16 17 19]\n",
      "[0.36826809 0.91704061 0.97934072 0.62221567 1.         0.71464255\n",
      " 0.79379472 1.         0.38973801 0.79621858 0.64391591 0.61407207\n",
      " 0.39530243 0.79164644 0.64106493 1.         0.96156234 1.\n",
      " 0.36826809 0.83382668 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 15\n",
      "fmnist_EDGE_CASE 15\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.         0.0055569  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.16674184 0.1193153  0.03184927\n",
      " 0.         0.         0.45464783 0.03995365 0.         0.18814132\n",
      " 0.         0.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 15\n",
      "[]\n",
      "fmnist_EDGE_CASE 15\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 15\n",
      "fmnist_EDGE_CASE 15\n",
      "fmnist_EDGE_CASE 15\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 15\n",
      "fmnist_EDGE_CASE 15\n",
      "[0, 1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 30]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(16, 0, 30, 4, 0.92, 1.0, 0.8, 1.0, 0.0, 0.2, np.float64(0.9), np.float64(0.840168050416806))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(16, 0, 30, 4, 0.92, 1.0, 0.8, 1.0, 0.0, 0.2, np.float64(0.9), np.float64(0.840168050416806))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 16\n",
      "fmnist_EDGE_CASE 16\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.08889006 0.\n",
      " 0.35993619 0.         0.         0.17488087 0.         0.\n",
      " 0.10714534 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3441434  0.         0.10092399 0.\n",
      " 0.39534262 0.         0.         0.08374625 0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 16\n",
      "fmnist_EDGE_CASE 16\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  6  7  8  9 11 12 13 14 15 17 18 19]\n",
      "[0.06215188 0.23652785 0.43006722 0.50466136 0.21213587 0.71832676\n",
      " 0.55926119 0.46315759 0.23652785 0.38229781 0.71552897 0.59848719\n",
      " 0.21213587 0.28335232 0.06215188 0.21984129 1.         0.46386298\n",
      " 0.47231453 0.21984129 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 16\n",
      "[]\n",
      "fmnist_EDGE_CASE 16\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 16\n",
      "fmnist_EDGE_CASE 16\n",
      "fmnist_EDGE_CASE 16\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 16\n",
      "fmnist_EDGE_CASE 16\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 28, 30, 41, 47]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 17\n",
      "fmnist_EDGE_CASE 17\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.08898322 0.05046182 0.         0.\n",
      " 0.1122514  0.12286118 0.14676458 0.20042391 0.03989435 0.0069873\n",
      " 0.06427665 0.         0.05046182 0.15719248 0.         0.12482213\n",
      " 0.18592093 0.         0.         0.         0.16031986 0.02271411\n",
      " 0.03381598 0.23631729 0.         0.16031986 0.         0.32144641\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 17\n",
      "fmnist_EDGE_CASE 17\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  6  7  8 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.03077878 0.07125973 0.00561415 0.         0.         0.66460511\n",
      " 0.07842012 0.         0.21238588 0.69656602 0.07842012 0.\n",
      " 0.20086584 0.43375936 0.         0.46604814 0.02688778 0.\n",
      " 0.         0.02688778 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 17\n",
      "[]\n",
      "fmnist_EDGE_CASE 17\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 17\n",
      "fmnist_EDGE_CASE 17\n",
      "fmnist_EDGE_CASE 17\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 17\n",
      "fmnist_EDGE_CASE 17\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 18\n",
      "fmnist_EDGE_CASE 18\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.00849865 0.18032549 0.\n",
      " 0.21812067 0.         0.21964132 0.38097315 0.         0.03384729\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.03506248 0.         0.33636814 0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 18\n",
      "fmnist_EDGE_CASE 18\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[0.         0.15661183 0.         0.         0.         0.\n",
      " 0.09988648 0.15661183 0.         0.         0.         0.\n",
      " 0.         0.01716594 0.         0.37489935 0.         0.09988648\n",
      " 0.         0.74776544 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 18\n",
      "[]\n",
      "fmnist_EDGE_CASE 18\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 18\n",
      "fmnist_EDGE_CASE 18\n",
      "fmnist_EDGE_CASE 18\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 18\n",
      "fmnist_EDGE_CASE 18\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 19\n",
      "fmnist_EDGE_CASE 19\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.02804302 0.         0.01541803 0.\n",
      " 0.10258012 0.         0.         0.09656156 0.         0.\n",
      " 0.         0.         0.         0.08012134 0.         0.\n",
      " 0.         0.         0.         0.         0.07240358 0.\n",
      " 0.         0.         0.06304839 0.42900691 0.         0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 19\n",
      "fmnist_EDGE_CASE 19\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.05092969 0.         0.         0.         0.         0.\n",
      " 0.0417681  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 19\n",
      "[]\n",
      "fmnist_EDGE_CASE 19\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 19\n",
      "fmnist_EDGE_CASE 19\n",
      "fmnist_EDGE_CASE 19\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 19\n",
      "fmnist_EDGE_CASE 19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 20\n",
      "fmnist_EDGE_CASE 20\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 24]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.55889631 0.0214148  0.         0.         0.         0.\n",
      " 0.17569106 0.         0.         0.05447874 0.         0.\n",
      " 0.         0.         0.         0.03921893 0.         0.\n",
      " 0.09071758 0.         0.12202154 0.         0.         0.\n",
      " 0.         0.18568051]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 20\n",
      "fmnist_EDGE_CASE 20\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0.         0.         0.         0.         0.15764935 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "fmnist_EDGE_CASE 20\n",
      "[]\n",
      "fmnist_EDGE_CASE 20\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 20\n",
      "fmnist_EDGE_CASE 20\n",
      "fmnist_EDGE_CASE 20\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 20\n",
      "fmnist_EDGE_CASE 20\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 47]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 47]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 1, 29, 0, 0.98, 0.9523809523809523, 1.0, 0.9666666666666667, 0.03333333333333333, 0.0, np.float64(0.9833333333333334), np.float64(0.959497222838566))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 1, 29, 0, 0.98, 0.9523809523809523, 1.0, 0.9666666666666667, 0.03333333333333333, 0.0, np.float64(0.9833333333333334), np.float64(0.959497222838566))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\LLM\\wb2\\Codes\\getResult\\genReLiTu.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20, 15))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmnist_EDGE_CASE 21\n",
      "fmnist_EDGE_CASE 21\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.35212178 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29678009 0.\n",
      " 0.         0.         0.         0.34417707 0.35022645 0.\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 21\n",
      "fmnist_EDGE_CASE 21\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 21\n",
      "[]\n",
      "fmnist_EDGE_CASE 21\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 21\n",
      "fmnist_EDGE_CASE 21\n",
      "fmnist_EDGE_CASE 21\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 21\n",
      "fmnist_EDGE_CASE 21\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 22\n",
      "fmnist_EDGE_CASE 22\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 0.1146057  0.         0.         0.0156991  0.         0.12900321\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.10995024 0.         0.09249801 0.         0.\n",
      " 0.         0.00613955 0.02843612 0.30996091 0.39869071 0.07466606\n",
      " 0.         0.        ]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 22\n",
      "fmnist_EDGE_CASE 22\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 22\n",
      "[]\n",
      "fmnist_EDGE_CASE 22\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 22\n",
      "fmnist_EDGE_CASE 22\n",
      "fmnist_EDGE_CASE 22\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 22\n",
      "fmnist_EDGE_CASE 22\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 23\n",
      "fmnist_EDGE_CASE 23\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.18648559 0.         0.         0.\n",
      " 0.25593979 0.01063764 0.02756497 0.42411693 0.         0.20608168\n",
      " 0.08941245 0.11119769 0.10553378 0.08452871 0.10553378 0.20010355\n",
      " 0.07850745 0.         0.12877812 0.00979874 0.33665919 0.00652627\n",
      " 0.17032194 0.01981181 0.35092023 0.19778817 0.34101565 0.48120829\n",
      " 0.         0.11070851]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 23\n",
      "fmnist_EDGE_CASE 23\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 23\n",
      "[]\n",
      "fmnist_EDGE_CASE 23\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 23\n",
      "fmnist_EDGE_CASE 23\n",
      "fmnist_EDGE_CASE 23\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 23\n",
      "fmnist_EDGE_CASE 23\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 44]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "fmnist_EDGE_CASE 24\n",
      "fmnist_EDGE_CASE 24\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 24]\n",
      "[1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 4.52658475e-02 1.80684381e-01 3.45936386e-02 1.19844176e-01\n",
      " 5.40893064e-01 4.26971887e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.67863229e-02 1.40788029e-01 0.00000000e+00\n",
      " 4.52658475e-02 7.87693178e-02 2.56488464e-02 3.36749248e-04\n",
      " 2.83955301e-01 0.00000000e+00 0.00000000e+00 8.17699391e-02\n",
      " 2.38289129e-01 0.00000000e+00 4.76115749e-01 1.96846857e-01\n",
      " 3.02725440e-01 2.59306230e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 24\n",
      "fmnist_EDGE_CASE 24\n",
      "识别出的恶意客户端索引: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "fmnist_EDGE_CASE 24\n",
      "[]\n",
      "fmnist_EDGE_CASE 24\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 24\n",
      "fmnist_EDGE_CASE 24\n",
      "fmnist_EDGE_CASE 24\n",
      "participants: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "fmnist_EDGE_CASE 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9512\\442957337.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param_update = torch.tensor(param_update)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "fmnist_EDGE_CASE 24\n",
      "fmnist_EDGE_CASE 24\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[]\n",
      "----------------\n",
      "(20, 1, 29, 0, 0.98, 0.9523809523809523, 1.0, 0.9666666666666667, 0.03333333333333333, 0.0, np.float64(0.9833333333333334), np.float64(0.959497222838566))\n",
      "(20, 0, 30, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n",
      "(20, 1, 29, 0, 0.98, 0.9523809523809523, 1.0, 0.9666666666666667, 0.03333333333333333, 0.0, np.float64(0.9833333333333334), np.float64(0.959497222838566))\n",
      "(0, 0, 30, 20, 0.6, 0, 0.0, 1.0, 0.0, 1.0, np.float64(0.5), 0.0)\n",
      "合并完成，输出文件: merged_output.pdf\n"
     ]
    },
    {
        "data": {
         "image/svg+xml": [
           "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" width=\"800\" height=\"20\">",
           "<a xlink:href=\"https://github.com/LetMeFly666/SecFFT/releases/download/v0.0.0/result.25x3x4.R1-fmnist_EDGE_CASE.002.measureFLTrustByScore.pdf\" xlink:title=\"JUMP to Release\" target=\"_blank\">",
           "<text x=\"0\" y=\"15\" fill=\"red\">https://github.com/LetMeFly666/SecFFT/releases/download/v0.0.0/result.25x3x4.R1-fmnist_EDGE_CASE.002.measureFLTrustByScore.pdf</text>",
           "</a>",
           "</svg>"
         ],
         "text/plain": [
          "<Figure size 2000x1500 with 24 Axes>"
         ]
        },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ATTACK_METHOD = 'NEUROTOXIN'\n",
    "# ATTACK_METHOD = 'EDGE_CASE'\n",
    "ATTACK_METHOD = 'EDGE_CASE'\n",
    "def plotOnce(plotRound: int=24):\n",
    "    if ATTACK_METHOD == 'NEUROTOXIN':\n",
    "        # malicious_clients, cosine_similarity_matrix = fltrust([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', '../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist')\n",
    "        foolsgoldMaliciousIndex, foolsgoldScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-28_05-59-22-foolsgold-fmnist_NEUROTOXIN')\n",
    "        fltrustMaliciousIndex, fltrustScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-03_06-48-00-fltrust-fmnist_NEUROTOXIN')  # 未修改 - 应与EDGE_CASE一致\n",
    "        # flameMaliciousIndex, flameMaliciousIndex = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-30-57-flame-fmnist_NEUROTOXIN')\n",
    "        flameMaliciousIndex, flameScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-02_12-55-32-flame-fmnist_NEUROTOXIN')\n",
    "        secfftMaliciousIndex, secfftScore2 = calc_maliciousAndCos_justByGrads_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_08-40-55-secfft-fmnist_NEUROTOXIN')\n",
    "\n",
    "        foolsMalicious, foolsLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-28_05-59-22-foolsgold-fmnist_NEUROTOXIN')\n",
    "        fltrustMalicious, fltrustLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-03_06-48-00-fltrust-fmnist_NEUROTOXIN')\n",
    "        flameMalicious, flameLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_12-55-32-flame-fmnist_NEUROTOXIN')\n",
    "        secfftLimited = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_08-40-55-secfft-fmnist_NEUROTOXIN')\n",
    "\n",
    "        foolsMalicious2, foolsDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-28_05-59-22-foolsgold-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "        fltrustMalicious2, fltrustDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-03_06-48-00-fltrust-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "        flameMalicious2, flameDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_12-55-32-flame-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "        secffDirection = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_08-40-55-secfft-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "\n",
    "        # foolsgoldScore2 = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\n",
    "        # 不错的有：9\n",
    "    elif ATTACK_METHOD == 'EDGE_CASE':\n",
    "        foolsgoldMaliciousIndex, foolsgoldScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-28_00-55-46-foolsgold-fmnist_EDGE_CASE')\n",
    "        fltrustMaliciousIndex, fltrustScore2 = fltrust_R1(plotRound, 'D:/Data-R1/2024-10-03_03-09-36-fltrust-fmnist_EDGE_CASE')\n",
    "        flameMaliciousIndex, flameScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-02_09-11-28-flame-fmnist_EDGE_CASE')\n",
    "        secfftMaliciousIndex, secfftScore2 = calc_maliciousAndCos_justByGrads_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_04-48-52-secfft-fmnist_EDGE_CASE')\n",
    "\n",
    "        foolsMalicious, foolsLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-28_00-55-46-foolsgold-fmnist_EDGE_CASE')\n",
    "        fltrustMalicious, fltrustLimited = fltrust_R1(plotRound, 'D:/Data-R1/2024-10-03_03-09-36-fltrust-fmnist_EDGE_CASE', limistedMethod=0)\n",
    "        flameMalicious, flameLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_09-11-28-flame-fmnist_EDGE_CASE')\n",
    "        secfftLimited = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_04-48-52-secfft-fmnist_EDGE_CASE')\n",
    "\n",
    "        foolsMalicious2, foolsDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-28_00-55-46-foolsgold-fmnist_EDGE_CASE', limistedMethod=1)\n",
    "        fltrustMalicious2, fltrustDirection = fltrust_R1(plotRound, 'D:/Data-R1/2024-10-03_03-09-36-fltrust-fmnist_EDGE_CASE', limistedMethod=1)\n",
    "        flameMalicious2, flameDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_09-11-28-flame-fmnist_EDGE_CASE', limistedMethod=1)\n",
    "        secffDirection = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-30_04-48-52-secfft-fmnist_EDGE_CASE', limistedMethod=1)\n",
    "        # 不错的有：6、8、(10)、13、15、16、18、19、21、22、24\n",
    "    elif ATTACK_METHOD == 'MR':\n",
    "        foolsgoldMaliciousIndex, foolsgoldScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-27_16-25-41-foolsgold-fmnist_MR')\n",
    "        fltrustMaliciousIndex, fltrustScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-02_21-40-11-fltrust-fmnist_MR')\n",
    "        flameMaliciousIndex, flameScore2 = calc_maliciousAndCos_justByGrads([plotRound], 'D:/Data-R1/2024-10-02_03-37-50-flame-fmnist_MR')\n",
    "        secfftMaliciousIndex, secfftScore2 = calc_maliciousAndCos_justByGrads_SecFFT([plotRound], 'D:/Data-R1/2024-10-29_22-41-06-secfft-fmnist_MR')\n",
    "\n",
    "        foolsMalicious, foolsLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-27_16-25-41-foolsgold-fmnist_MR')\n",
    "        fltrustMalicious, fltrustLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_21-40-11-fltrust-fmnist_MR')\n",
    "        flameMalicious, flameLimited = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_03-37-50-flame-fmnist_MR')\n",
    "        secfftLimited = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-29_22-41-06-secfft-fmnist_MR')\n",
    "\n",
    "        foolsMalicious2, foolsDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-27_16-25-41-foolsgold-fmnist_MR', limistedMethod=1)\n",
    "        fltrustMalicious2, fltrustDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_21-40-11-fltrust-fmnist_MR', limistedMethod=1)\n",
    "        flameMalicious2, flameDirection = calc_maliciousAndCos_justByGrads_limited([plotRound], 'D:/Data-R1/2024-10-02_03-37-50-flame-fmnist_MR', limistedMethod=1)\n",
    "        secffDirection = calc_maliciousAndCos_justByGrads_limited_SecFFT([plotRound], 'D:/Data-R1/2024-10-29_22-41-06-secfft-fmnist_MR', limistedMethod=1)\n",
    "        # （总体上都能识别出来，其中）不错的有：7、9、11\n",
    "    else:\n",
    "        print('嘭！沙卡拉卡')\n",
    "    # print(foolsgoldMaliciousIndex)\n",
    "    # print(foolsgoldScore2)\n",
    "    # datas = [foolsgoldScore2] * 12\n",
    "    # datas = [secfftScore2] * 12\n",
    "    # fltrustScore2 -= np.eye(50)\n",
    "    # fltrustLimited -= np.eye(50)\n",
    "    # fltrustDirection -= np.eye(50)\n",
    "    # fltrustScore2 -= np.eye(50) * fltrustScore2.min()\n",
    "    # m = fltrustScore2.min()\n",
    "    # fltrustScore2 = fltrustScore2.cpu().numpy()\n",
    "    # np.fill_diagonal(fltrustScore2, m)\n",
    "    # m = fltrustLimited.min()\n",
    "    # fltrustLimited = fltrustLimited.cpu().numpy()\n",
    "    # np.fill_diagonal(fltrustLimited, m)\n",
    "    # m = fltrustDirection.min()\n",
    "    # fltrustDirection = fltrustDirection.cpu().numpy()\n",
    "    # np.fill_diagonal(fltrustDirection, m)\n",
    "    datas = [foolsgoldScore2, fltrustScore2, flameScore2, secfftScore2,\n",
    "            foolsLimited, fltrustLimited, flameLimited, secfftLimited,\n",
    "            foolsDirection, fltrustDirection, flameDirection, secffDirection,]\n",
    "    foolsgoldMaliciousIndex = [int(x) for x in foolsgoldMaliciousIndex]\n",
    "    fltrustMaliciousIndex = [int(x) for x in fltrustMaliciousIndex]\n",
    "    flameMaliciousIndex = [int(x) for x in foolsgoldMaliciousIndex]\n",
    "    foolsgoldMaliciousIndex.sort()\n",
    "    fltrustMaliciousIndex.sort()\n",
    "    flameMaliciousIndex.sort()\n",
    "    print(foolsgoldMaliciousIndex)\n",
    "    print(fltrustMaliciousIndex)\n",
    "    print(flameMaliciousIndex)\n",
    "    print(secfftMaliciousIndex)\n",
    "\n",
    "    print('----------------')\n",
    "    print(foolsMalicious)\n",
    "    print(fltrustMalicious)\n",
    "    print(flameMalicious)\n",
    "\n",
    "    print('----------------')\n",
    "    print(foolsMalicious2)\n",
    "    print(fltrustMalicious2)\n",
    "    print(flameMalicious2)\n",
    "    print('----------------')\n",
    "\n",
    "    foolsgoldScores = getScores(foolsgoldMaliciousIndex)\n",
    "    fltrustScores = getScores(fltrustMaliciousIndex)\n",
    "    flameScores = getScores(flameMaliciousIndex)\n",
    "    secfftScores = getScores(secfftMaliciousIndex)\n",
    "    print(foolsgoldScores)\n",
    "    print(fltrustScores)\n",
    "    print(flameScores)\n",
    "    print(secfftScores)\n",
    "\n",
    "    plot_detection_heatmaps_3x4(*datas)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "我在jupyter里有一个plotOnce函数，这个函数会执行`plt.savefig`并保存一张图\n",
    "我想调用这个函数25次，如何将25张图拼接到一块并显示到jupyter上？\n",
    "```\n",
    "for i in range(25):\n",
    "    plotOnce(i)\n",
    "```\n",
    "这样的话只会显示最后一张，并且后面的图片会覆盖前面的图片\n",
    "\n",
    "\n",
    "\n",
    "注意，我的plotOnce函数会执行`plt.savefig`并保存一张图到文件中，我不能修改这个函数。\n",
    "\n",
    "\n",
    "进行如下修改：\n",
    "1. 不要绘制成5x5的图像，而绘制成25x1的图像（每张图像都很长，一行只放置一个原始图像）\n",
    "2. 每次调用plotOnce函数都会生成`detection_comparison_results_3x4.pdf`，第二次生成的文件会覆盖第一次的文件\n",
    "\"\"\"\n",
    "# save_dir = 'temp_saved_plots'  # 自定义保存路径\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# for i in range(25):\n",
    "#     plotOnce(i)\n",
    "#     os.rename('detection_comparison_results_3x4.png', os.path.join(save_dir, f'detection_comparison_results_3x4_{i}.png'))\n",
    "#     fig, axs = plt.subplots(25, 1, figsize=(10, 40))  # 25x1 的布局\n",
    "# for i in range(25):\n",
    "#     ax = axs[i]  # 确定当前子图的轴\n",
    "#     img_path = os.path.join(save_dir, f'detection_comparison_results_3x4_{i}.png')\n",
    "#     # images = convert_from_path(img_path)\n",
    "#     # img = images[0]\n",
    "#     img = Image.open(img_path)\n",
    "#     ax.imshow(img)\n",
    "#     ax.axis('off')  # 不显示坐标轴\n",
    "\n",
    "# # 调整布局\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "save_dir = 'temp_saved_plots'  # 自定义保存路径\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for i in range(25):\n",
    "    plotOnce(i)\n",
    "    os.rename('detection_comparison_results_3x4.pdf', os.path.join(save_dir, f'detection_comparison_results_3x4_{i}.pdf'))\n",
    "\n",
    "# 我决定不这么拼接了。我已经有了25个PDF，请将其拼接成一个PDF的25页\n",
    "from PyPDF2 import PdfMerger\n",
    "save_dir = 'temp_saved_plots'  # 假设所有 PDF 文件都在这个目录下\n",
    "output_pdf_path = 'merged_output.pdf'  # 输出合并后的 PDF 文件名\n",
    "\n",
    "# 创建 PdfMerger 对象\n",
    "merger = PdfMerger()\n",
    "\n",
    "# 遍历目录中的所有 PDF 文件\n",
    "for i in range(25):\n",
    "    pdf_path = os.path.join(save_dir, f'detection_comparison_results_3x4_{i}.pdf')\n",
    "    merger.append(pdf_path)  # 将 PDF 文件添加到合并器中\n",
    "\n",
    "# 合并并保存最终的 PDF 文件\n",
    "merger.write(output_pdf_path)\n",
    "merger.close()\n",
    "\n",
    "print(f\"合并完成，输出文件: {output_pdf_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
