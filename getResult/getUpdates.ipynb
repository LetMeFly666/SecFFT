{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from genReLiTu import plot_detection_heatmaps_3x4, generate_data_1dimension\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fmnist\"\n",
    "attack_defense_data = {\n",
    "    \"NEUROTOXIN\": {\n",
    "        \"AVG\": \"../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg_NEUROTOXIN-fmnist/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_01-57-26/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_12-39-47/\",\n",
    "    },\n",
    "    \"MR\": {\n",
    "        \"AVG\": \"FL_Backdoor_CV/2024-09-11_16-29-41/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_05-15-58/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_06-21-04/\",\n",
    "    },\n",
    "    \"EDGE_CASE\": {\n",
    "        \"AVG\": \"FL_Backdoor_CV/2024-09-11_17-32-14/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_10-44-13/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_13-45-18/\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for attack, attack2data in attack_defense_data.items():\n",
    "#     true_labels = []\n",
    "#     labels_get_by_Euclid = []\n",
    "#     labels_get_by_manhattan = []\n",
    "#     labels_get_by_cosine = []\n",
    "#     labels_get_by_chi_square = []\n",
    "#     for denfense, data_folder in attack2data.items():\n",
    "#         if denfense != \"AVG\":\n",
    "#             continue\n",
    "#         participant_file_name = f\"{data_folder}participants/participants.csv\"\n",
    "#         participants = np.genfromtxt(\n",
    "#             participant_file_name, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "#         )\n",
    "#         participants = participants[1:].T\n",
    "#         for i in range(len(participants) - 1):\n",
    "#             file_name = f\"{data_folder}model_updates/{dataset}_{attack}_{i}.pkl\"\n",
    "#             if not os.path.exists(file_name):\n",
    "#                 print(f\"File {file_name} not found\")\n",
    "#                 continue\n",
    "#             with open(file_name, \"rb\") as file:\n",
    "#                 model_updates = pickle.load(file)\n",
    "\n",
    "\n",
    "# roundNum = 10\n",
    "# dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg_NEUROTOXIN-fmnist/'\n",
    "# pklName = os.path.join(dirPath, f'model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl')\n",
    "# participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "# # participantFileDF = pd.read_csv(participantFilePath)\n",
    "# # # 提取参与者数组（第一列）和轮次（从第二列开始的部分）\n",
    "# # clients = participantFileDF.iloc[1:, 0].tolist()  # 客户端列表\n",
    "# # roundsArray = participantFileDF.iloc[1:, 1:].to_numpy()  # 轮次数据（50行x30列）\n",
    "# # print(roundsArray)\n",
    "# participants = np.genfromtxt(\n",
    "#     participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "# )\n",
    "# participants = participants[1:].T\n",
    "# participants_thisRound = participants[roundNum]\n",
    "# print(participants_thisRound)\n",
    "\n",
    "# with open(pklName, 'rb') as f:\n",
    "#     update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "# # print(update)\n",
    "# # weight0 = update['base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight']\n",
    "# # weight0.shape  # torch.Size([50, 12288])\n",
    "# userUpdates = [torch.empty(0) for _ in range(50)]\n",
    "# for layerKey, values in update.items():\n",
    "#     # print(layerKey)\n",
    "#     # print(values)\n",
    "#     # print(values.shape)  # torch.Size([50, 12288])\n",
    "#     for i in range(values.shape[0]):\n",
    "#         trueUser = participants_thisRound[i]\n",
    "#         userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i].cpu()), 0)\n",
    "# print(userUpdates[0].shape)\n",
    "\n",
    "def loadPkl(roundNum: int, dirPath: str) -> Dict[str, torch.Tensor]:  # 把pkl变成{'key1': [[user3], [user5]]}\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "    pklName = os.path.join(dirPath, f'model_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "    return update\n",
    "\n",
    "def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:  # 获取参与者列表\n",
    "    participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "\n",
    "    # 读取参与者数组\n",
    "    participants = np.genfromtxt(\n",
    "        participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "    )\n",
    "    participants = participants[1:].T\n",
    "    participants_thisRound = participants[roundNum]  # 获取当前轮次的参与者\n",
    "    return participants_thisRound\n",
    "\n",
    "def get_all_user_updates(roundNum: int, dirPath: str) -> torch.Tensor:  # 把pkl变成[[user1展平(拼接)后的结果], [user2], ...]\n",
    "    # 设置轮次编号和文件路径\n",
    "    # roundNum = 10\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    # print(participants_thisRound)\n",
    "\n",
    "    # 加载 .pkl 文件\n",
    "    update = loadPkl(roundNum, dirPath)\n",
    "\n",
    "    # 初始化一个列表来存储每个客户端的更新，使用 GPU 张量\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    userUpdates = [torch.empty((0,), device=device) for _ in range(50)]  # 假设50个客户端\n",
    "\n",
    "    # 遍历每个层的更新\n",
    "    for layerKey, values in update.items():\n",
    "        # 将每个值移到 GPU 上\n",
    "        values = values.to(device)\n",
    "        for i in range(values.shape[0]):  # 遍历每个客户端的梯度\n",
    "            trueUser = participants_thisRound[i]  # 获取当前轮次的客户端ID\n",
    "            # 如果为空张量\n",
    "            if userUpdates[trueUser].numel() == 0:\n",
    "                userUpdates[trueUser] = values[i]  # 直接赋值\n",
    "            else:\n",
    "                userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i]), 0)  # 在GPU上拼接\n",
    "\n",
    "    userUpdates = torch.stack(userUpdates)  # 转换为张量\n",
    "    # # 打印第一个用户的更新形状来检查结果\n",
    "    # print(userUpdates[0].shape)\n",
    "    return userUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算一个二维 tensor 中每两个向量之间的余弦相似度矩阵。\n",
    "\n",
    "    参数:\n",
    "    - tensor (torch.Tensor): 形状为 (N, D) 的二维张量，N 是客户端数量，D 是特征维度。\n",
    "\n",
    "    返回:\n",
    "    - similarity_matrix (torch.Tensor): 形状为 (N, N) 的张量，每个元素表示两个向量之间的余弦相似度。\n",
    "    \"\"\"\n",
    "    # 归一化每个向量\n",
    "    normalized_tensor = F.normalize(tensor, p=2, dim=1)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    similarity_matrix = torch.mm(normalized_tensor, normalized_tensor.T)\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userUpdates_avg_NEUR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/')\n",
    "# print(userUpdates_avg_NEUR.shape)\n",
    "# print(userUpdates_avg_NEUR)\n",
    "# userUpdates_avg_MR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_12-02-44-avg-fmnist_MR/')\n",
    "\n",
    "# similarity_matrix_avg_NEUR = cosine_similarity_matrix(userUpdates_avg_NEUR)\n",
    "# print(similarity_matrix_avg_NEUR.shape)\n",
    "# similarity_matrix_avg_MR = cosine_similarity_matrix(userUpdates_avg_MR)\n",
    "# # print(similarity_matrix_avg_MR.shape)\n",
    "# plot_detection_heatmaps(similarity_matrix_avg_NEUR, similarity_matrix_avg_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foolsgold\n",
    "# ChangeFrom https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L203C1-L241C25\n",
    "# foolsgold自身并没有确认哪些是恶意客户端，而是根据权重聚合\n",
    "# def foolsgold_identify_malicious_clients(wv: np.ndarray, threshold: float = 0.25) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     根据权重向量识别潜在的恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - wv (np.ndarray): 客户端的权重向量。\n",
    "#     - threshold (float): 判断恶意客户端的阈值，权重低于此值的客户端将被视为恶意客户端。\n",
    "    \n",
    "#     返回:\n",
    "#     - malicious_clients (np.ndarray): 被识别为恶意的客户端索引。\n",
    "#     \"\"\"\n",
    "#     return np.where(wv < threshold)[0]\n",
    "def foolsgold_identify_malicious_clients(wv: np.ndarray) -> np.ndarray:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(wv.reshape(-1, 1))\n",
    "    clusters = kmeans.labels_\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    max_cluster = unique[np.argmax(counts)]\n",
    "    user_labels = np.zeros(len(clusters), dtype=int)\n",
    "    user_labels[clusters == max_cluster] = 1\n",
    "    return np.where(user_labels == 0)[0]\n",
    "\n",
    "# 返回 聚合后的全局模型、恶意客户端索引、余弦相似度矩阵\n",
    "# def foolsgold(model_updates: Dict[str, torch.Tensor]) -> Tuple[Dict[str, torch.Tensor], np.ndarray, np.ndarray]:\n",
    "def foolsgold_oneRound(roundNum: int, dirPath: str) -> Tuple[Dict[str, torch.Tensor], np.ndarray, torch.Tensor]:\n",
    "    model_updates = loadPkl(roundNum, dirPath)\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    \n",
    "    keys = list(model_updates.keys())\n",
    "    last_layer_updates = model_updates[keys[-2]]\n",
    "    K = len(last_layer_updates)\n",
    "    cs = smp.cosine_similarity(last_layer_updates.cpu().numpy()) - np.eye(K)  # 减去对角线为1的单位矩阵，使得自身与自身的相似度为0\n",
    "    maxcs = np.max(cs, axis=1)\n",
    "    # === pardoning(赦免) ===\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if maxcs[i] < maxcs[j]:\n",
    "                cs[i][j] = cs[i][j] * maxcs[i] / maxcs[j]\n",
    "\n",
    "    alpha = np.max(cs, axis=1)\n",
    "    wv = 1 - alpha\n",
    "    wv[wv > 1] = 1\n",
    "    wv[wv < 0] = 0\n",
    "\n",
    "    # === Rescale so that max value is wv ===\n",
    "    wv = wv / np.max(wv)\n",
    "    wv[(wv == 1)] = .99\n",
    "\n",
    "    # === Logit function ===\n",
    "    wv = (np.log(wv / (1 - wv)) + 0.5)\n",
    "    wv[(np.isinf(wv) + wv > 1)] = 1\n",
    "    wv[(wv < 0)] = 0\n",
    "\n",
    "    malicious_clients = foolsgold_identify_malicious_clients(wv)\n",
    "    malicious_clients = participants_thisRound[malicious_clients]\n",
    "    print(f\"识别出的恶意客户端索引: {malicious_clients}\")\n",
    "\n",
    "    # === calculate global update ===\n",
    "    global_update = defaultdict()\n",
    "    for name in keys:\n",
    "        tmp = None\n",
    "        for i, j in enumerate(range(len(wv))):\n",
    "            if i == 0:\n",
    "                tmp = model_updates[name][j] * wv[j]\n",
    "            else:\n",
    "                tmp += model_updates[name][j] * wv[j]\n",
    "        global_update[name] = 1 / len(wv) * tmp\n",
    "    print(wv)\n",
    "    if True:  # 使用余弦相似度作为热力图依据\n",
    "        cs = smp.cosine_similarity(last_layer_updates.cpu().numpy())  # 这里就不再减去自身了\n",
    "        cs_rearranged = np.zeros((len(participants_thisRound), len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            for j, user_j in enumerate(participants_thisRound):\n",
    "                cs_rearranged[user_i][user_j] = cs[i][j]\n",
    "        cs_tensor = torch.from_numpy(cs_rearranged)\n",
    "    else:  # 使用聚合参数wv作为热力图依据。这样直接很多1，太明显了\n",
    "        cs_tensor = torch.zeros((len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            cs_tensor[user_i] = wv[i]  # tensor([0.2348, 0.2348, 0.8740, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
    "\n",
    "    return global_update, malicious_clients, cs_tensor\n",
    "\n",
    "# 组合多轮，返回恶意客户端索引、余弦相似度矩阵\n",
    "def foolsgold(roundsNum: List[int], dirPath: str) -> Tuple[np.ndarray, torch.Tensor]:\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "            if thisMaliciousIndex < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "            maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    cs = smp.cosine_similarity(gradients_shuffled)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious_shuffled, cs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByGPT - 还是不太行啊看来\n",
    "# import os\n",
    "# import pickle\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "# def fltrust_original(model_updates: Dict[str, torch.Tensor], param_updates: List[torch.Tensor], clean_param_update: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "#     \"\"\"\n",
    "#     使用 FLTrust 方法进行聚合计算。\n",
    "    \n",
    "#     参数:\n",
    "#     - model_updates: 客户端模型更新的字典，键为参数名，值为模型更新的 Tensor。\n",
    "#     - param_updates: 客户端的参数更新列表，包含每个客户端的更新 Tensor。\n",
    "#     - clean_param_update: 干净模型的参数更新，用于计算客户端更新的权重。\n",
    "\n",
    "#     返回:\n",
    "#     - global_update: 聚合后的全局模型更新。\n",
    "#     \"\"\"\n",
    "#     cos = torch.nn.CosineSimilarity(dim=0)\n",
    "#     g0_norm = torch.norm(clean_param_update)\n",
    "#     weights = []\n",
    "    \n",
    "#     # 计算每个客户端更新与 clean_param_update 的余弦相似度\n",
    "#     for param_update in param_updates:\n",
    "#         weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    \n",
    "#     weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "#     weights = weights / weights.sum()\n",
    "#     weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "#     nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "#     nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "#     print(f'g0_norm: {g0_norm}, '\n",
    "#           f'weights_sum: {weights.sum()}, '\n",
    "#           f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "#     normalize_weights = []\n",
    "#     for param_update in param_updates:\n",
    "#         normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "#     global_update = dict()\n",
    "#     for name, params in model_updates.items():\n",
    "#         if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "#             global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "#         else:\n",
    "#             global_update[name] = torch.matmul(\n",
    "#                 weights,\n",
    "#                 params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "#     return global_update\n",
    "\n",
    "\n",
    "# def fltrust(roundsNum: List[int], dirPath: str, modelPath: str) -> Tuple[List[int], np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     根据指定的轮次和目录路径，使用 FLTrust 聚合和识别恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - roundsNum: 需要处理的轮次列表。\n",
    "#     - dirPath: 数据文件所在的目录路径。\n",
    "#     - modelPath: 模型路径（目前没有用到）。\n",
    "\n",
    "#     返回:\n",
    "#     - 恶意客户端的编号列表。\n",
    "#     - 50 个客户端的评分（1x50 数组或 50x50 数组）。\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 加载pkl文件数据\n",
    "#     def loadPkl(roundNum: int, subfolder: str, dirPath: str) -> Dict[str, torch.Tensor]:\n",
    "#         pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "#         pklName = os.path.join(dirPath, f'{subfolder}/{pklPrefix}_{roundNum}.pkl')\n",
    "#         with open(pklName, 'rb') as f:\n",
    "#             update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "#         return update\n",
    "    \n",
    "#     # 合并指定轮次的数据\n",
    "#     all_model_updates = {}\n",
    "#     all_param_updates = []\n",
    "#     for roundNum in roundsNum:\n",
    "#         participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "#         model_updates = loadPkl(roundNum, 'model_updates', dirPath)  # 修正为正确的子文件夹\n",
    "#         clean_param_update = loadPkl(roundNum, 'clean_param_updates', dirPath)[participants_thisRound[0]]  # 修正为正确的子文件夹\n",
    "\n",
    "#         # 拼接恶意客户端（0-2号）和良性客户端（3-9号）\n",
    "#         for key, value in model_updates.items():\n",
    "#             if key not in all_model_updates:\n",
    "#                 all_model_updates[key] = torch.zeros((50, value.shape[1])).to('cuda:0')\n",
    "#             all_model_updates[key][:15] = torch.cat([value[i].unsqueeze(0) for i in range(3)], dim=0).to('cuda:0')  # 恶意客户端\n",
    "#             all_model_updates[key][15:] = torch.cat([value[i].unsqueeze(0) for i in range(3, 10)], dim=0).to('cuda:0')  # 良性客户端\n",
    "\n",
    "#         # 提取参数更新，拼接恶意和良性客户端\n",
    "#         for i in range(3):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "#         for i in range(3, 10):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "    \n",
    "#     # 使用 FLTrust 进行聚合\n",
    "#     global_update = fltrust_original(all_model_updates, all_param_updates, clean_param_update)\n",
    "    \n",
    "#     # 使用 KMeans 聚类来识别恶意客户端\n",
    "#     scores = torch.stack(all_param_updates).cpu().numpy()  # 使用参数更新作为聚类的输入\n",
    "#     kmeans = KMeans(n_clusters=2, random_state=0).fit(scores)\n",
    "#     cluster_labels = kmeans.labels_\n",
    "    \n",
    "#     # 识别恶意客户端\n",
    "#     malicious_clients = [i for i in range(50) if cluster_labels[i] == cluster_labels[:15].max()]\n",
    "\n",
    "#     # 计算 50x50 的余弦相似度矩阵\n",
    "#     cosine_similarity_matrix = np.zeros((50, 50))\n",
    "#     for i in range(50):\n",
    "#         for j in range(50):\n",
    "#             cosine_similarity_matrix[i, j] = F.cosine_similarity(all_param_updates[i].view(-1, 1), all_param_updates[j].view(-1, 1)).item()\n",
    "\n",
    "#     return malicious_clients, cosine_similarity_matrix\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参数更新的向量\n",
    "# def parameters_to_vector(params):\n",
    "#     return torch.cat([p.view(-1) for p in params])\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参与者列表\n",
    "# def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:\n",
    "#     # 实现略\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fltrust\n",
    "# https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L301-L340\n",
    "\n",
    "def fltrust_original(model_updates, param_updates, clean_param_update):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    g0_norm = torch.norm(clean_param_update)\n",
    "    weights = []\n",
    "    for param_update in param_updates:\n",
    "        weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "    weights = weights / weights.sum()\n",
    "    weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "    nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "    nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "    print(f'g0_norm: {g0_norm}, '\n",
    "          f'weights_sum: {weights.sum()}, '\n",
    "          f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "    normalize_weights = []\n",
    "    for param_update in param_updates:\n",
    "        normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "    global_update = dict()\n",
    "    for name, params in model_updates.items():\n",
    "        if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "            global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "        else:\n",
    "            global_update[name] = torch.matmul(\n",
    "                weights,\n",
    "                params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "    return global_update\n",
    "\n",
    "def fltrust(roundsNum: List[int], dirPath: str, modelPath: str):\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    # gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    # maliciouses = []\n",
    "    gradientsList = []  # 里面存放每一轮的梯度，最后再聚合\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        # get model updates\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist/fltrust_{roundNum}.pth'\n",
    "        # print(pklName)\n",
    "        with open(pklName, 'rb') as f:\n",
    "            model_updates: Dict[str, torch.Tensor] = torch.load(f)\n",
    "        print(model_updates)\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            param_updates: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "        param_updates = torch.cat(list(param_updates.values()), dim=1)\n",
    "        # print(param_updates[list(param_updates.keys())[0]].shape)  # torch.Size([10, 12288])\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/clean_param_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            clean_param_update: torch.Tensor = pickle.load(f)\n",
    "        \n",
    "        # global_update = fltrust_original(model_updates, [param_updates[key] for key in param_updates.keys()], clean_param_update)\n",
    "        global_update = fltrust_original(model_updates, param_updates, clean_param_update)\n",
    "\n",
    "        # print(clean_param_update.shape)  # torch.Size([2674688])\n",
    "        thisGradients = [0] * clientPerRound\n",
    "\n",
    "\n",
    "        gradientsList.append(thisGradients)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26036\\1983248510.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_updates: Dict[str, torch.Tensor] = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): CLIPModel(\n",
      "      (text_model): CLIPTextTransformer(\n",
      "        (embeddings): CLIPTextEmbeddings(\n",
      "          (token_embedding): Embedding(49408, 512)\n",
      "          (position_embedding): Embedding(77, 512)\n",
      "        )\n",
      "        (encoder): CLIPEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-11): 12 x CLIPEncoderLayer(\n",
      "              (self_attn): CLIPSdpaAttention(\n",
      "                (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): CLIPMLP(\n",
      "                (activation_fn): QuickGELUActivation()\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              )\n",
      "              (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (vision_model): CLIPVisionTransformer(\n",
      "        (embeddings): CLIPVisionEmbeddings(\n",
      "          (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "          (position_embedding): Embedding(50, 768)\n",
      "        )\n",
      "        (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder): CLIPEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-11): 12 x CLIPEncoderLayer(\n",
      "              (self_attn): CLIPSdpaAttention(\n",
      "                (k_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (v_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (q_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (out_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): CLIPMLP(\n",
      "                (activation_fn): QuickGELUActivation()\n",
      "                (fc1): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=3072, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (fc2): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=3072, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (visual_projection): lora.Linear(\n",
      "        (base_layer): Linear(in_features=768, out_features=512, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=16, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "      (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "g0_norm: 0.1616002470254898, weights_sum: 0.9999999403953552, *** 10 *** model updates are considered to be aggregated !\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CLIPModel' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\peft\\peft_model.py:737\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PeftModel' object has no attribute 'items'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\peft\\tuners\\lora\\model.py:356\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'items'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\Desktop\\LLM\\wb2\\Codes\\getResult\\getUpdates.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m malicious_clients, cosine_similarity_matrix \u001b[39m=\u001b[39m fltrust([\u001b[39m15\u001b[39;49m, \u001b[39m16\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m18\u001b[39;49m, \u001b[39m19\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39m../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# foolsgoldMaliciousIndex, foolsgoldScore2 = foolsgold([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# print(foolsgoldMaliciousIndex)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(foolsgoldScore2)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# datas = [foolsgoldScore2] * 12\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# plot_detection_heatmaps_3x4(*datas)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\admin\\Desktop\\LLM\\wb2\\Codes\\getResult\\getUpdates.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     clean_param_update: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# global_update = fltrust_original(model_updates, [param_updates[key] for key in param_updates.keys()], clean_param_update)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m global_update \u001b[39m=\u001b[39m fltrust_original(model_updates, param_updates, clean_param_update)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# print(clean_param_update.shape)  # torch.Size([2674688])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m thisGradients \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m clientPerRound\n",
      "\u001b[1;32mc:\\Users\\admin\\Desktop\\LLM\\wb2\\Codes\\getResult\\getUpdates.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     normalize_weights\u001b[39m.\u001b[39mappend(g0_norm \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mnorm(param_update))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m global_update \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, params \u001b[39min\u001b[39;00m model_updates\u001b[39m.\u001b[39;49mitems():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mnum_batches_tracked\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m name \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrunning_mean\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m name \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrunning_var\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m name:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Desktop/LLM/wb2/Codes/getResult/getUpdates.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         global_update[name] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m nonzero_weights \u001b[39m*\u001b[39m params[nonzero_indices]\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\peft\\peft_model.py:741\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbase_model\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# see #1892: prevent infinite recursion if class is not initialized\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model, name)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\peft\\tuners\\lora\\model.py:360\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# see #1892: prevent infinite recursion if class is not initialized\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, name)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CLIPModel' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "malicious_clients, cosine_similarity_matrix = fltrust([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', '../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist')\n",
    "\n",
    "# foolsgoldMaliciousIndex, foolsgoldScore2 = foolsgold([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\n",
    "# print(foolsgoldMaliciousIndex)\n",
    "# print(foolsgoldScore2)\n",
    "# datas = [foolsgoldScore2] * 12\n",
    "# plot_detection_heatmaps_3x4(*datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
