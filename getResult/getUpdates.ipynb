{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from genReLiTu import plot_detection_heatmaps_3x4, generate_data_1dimension\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fmnist\"\n",
    "attack_defense_data = {\n",
    "    \"NEUROTOXIN\": {\n",
    "        \"AVG\": \"../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg_NEUROTOXIN-fmnist/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_01-57-26/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_12-39-47/\",\n",
    "    },\n",
    "    \"MR\": {\n",
    "        \"AVG\": \"FL_Backdoor_CV/2024-09-11_16-29-41/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_05-15-58/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_06-21-04/\",\n",
    "    },\n",
    "    \"EDGE_CASE\": {\n",
    "        \"AVG\": \"FL_Backdoor_CV/2024-09-11_17-32-14/\",\n",
    "        # \"FLAME\": \"FL_Backdoor_CV/2024-09-11_10-44-13/\",\n",
    "        \"FLTRUST\": \"FL_Backdoor_CV/2024-09-11_13-45-18/\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for attack, attack2data in attack_defense_data.items():\n",
    "#     true_labels = []\n",
    "#     labels_get_by_Euclid = []\n",
    "#     labels_get_by_manhattan = []\n",
    "#     labels_get_by_cosine = []\n",
    "#     labels_get_by_chi_square = []\n",
    "#     for denfense, data_folder in attack2data.items():\n",
    "#         if denfense != \"AVG\":\n",
    "#             continue\n",
    "#         participant_file_name = f\"{data_folder}participants/participants.csv\"\n",
    "#         participants = np.genfromtxt(\n",
    "#             participant_file_name, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "#         )\n",
    "#         participants = participants[1:].T\n",
    "#         for i in range(len(participants) - 1):\n",
    "#             file_name = f\"{data_folder}model_updates/{dataset}_{attack}_{i}.pkl\"\n",
    "#             if not os.path.exists(file_name):\n",
    "#                 print(f\"File {file_name} not found\")\n",
    "#                 continue\n",
    "#             with open(file_name, \"rb\") as file:\n",
    "#                 model_updates = pickle.load(file)\n",
    "\n",
    "\n",
    "# roundNum = 10\n",
    "# dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg_NEUROTOXIN-fmnist/'\n",
    "# pklName = os.path.join(dirPath, f'model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl')\n",
    "# participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "# # participantFileDF = pd.read_csv(participantFilePath)\n",
    "# # # 提取参与者数组（第一列）和轮次（从第二列开始的部分）\n",
    "# # clients = participantFileDF.iloc[1:, 0].tolist()  # 客户端列表\n",
    "# # roundsArray = participantFileDF.iloc[1:, 1:].to_numpy()  # 轮次数据（50行x30列）\n",
    "# # print(roundsArray)\n",
    "# participants = np.genfromtxt(\n",
    "#     participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "# )\n",
    "# participants = participants[1:].T\n",
    "# participants_thisRound = participants[roundNum]\n",
    "# print(participants_thisRound)\n",
    "\n",
    "# with open(pklName, 'rb') as f:\n",
    "#     update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "# # print(update)\n",
    "# # weight0 = update['base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight']\n",
    "# # weight0.shape  # torch.Size([50, 12288])\n",
    "# userUpdates = [torch.empty(0) for _ in range(50)]\n",
    "# for layerKey, values in update.items():\n",
    "#     # print(layerKey)\n",
    "#     # print(values)\n",
    "#     # print(values.shape)  # torch.Size([50, 12288])\n",
    "#     for i in range(values.shape[0]):\n",
    "#         trueUser = participants_thisRound[i]\n",
    "#         userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i].cpu()), 0)\n",
    "# print(userUpdates[0].shape)\n",
    "\n",
    "def loadPkl(roundNum: int, dirPath: str) -> Dict[str, torch.Tensor]:  # 把pkl变成{'key1': [[user3], [user5]]}\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "    pklName = os.path.join(dirPath, f'model_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "    return update\n",
    "\n",
    "def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:  # 获取参与者列表\n",
    "    participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "\n",
    "    # 读取参与者数组\n",
    "    participants = np.genfromtxt(\n",
    "        participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "    )\n",
    "    participants = participants[1:].T\n",
    "    participants_thisRound = participants[roundNum]  # 获取当前轮次的参与者\n",
    "    return participants_thisRound\n",
    "\n",
    "def get_all_user_updates(roundNum: int, dirPath: str) -> torch.Tensor:  # 把pkl变成[[user1展平(拼接)后的结果], [user2], ...]\n",
    "    # 设置轮次编号和文件路径\n",
    "    # roundNum = 10\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    # print(participants_thisRound)\n",
    "\n",
    "    # 加载 .pkl 文件\n",
    "    update = loadPkl(roundNum, dirPath)\n",
    "\n",
    "    # 初始化一个列表来存储每个客户端的更新，使用 GPU 张量\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    userUpdates = [torch.empty((0,), device=device) for _ in range(50)]  # 假设50个客户端\n",
    "\n",
    "    # 遍历每个层的更新\n",
    "    for layerKey, values in update.items():\n",
    "        # 将每个值移到 GPU 上\n",
    "        values = values.to(device)\n",
    "        for i in range(values.shape[0]):  # 遍历每个客户端的梯度\n",
    "            trueUser = participants_thisRound[i]  # 获取当前轮次的客户端ID\n",
    "            # 如果为空张量\n",
    "            if userUpdates[trueUser].numel() == 0:\n",
    "                userUpdates[trueUser] = values[i]  # 直接赋值\n",
    "            else:\n",
    "                userUpdates[trueUser] = torch.cat((userUpdates[trueUser], values[i]), 0)  # 在GPU上拼接\n",
    "\n",
    "    userUpdates = torch.stack(userUpdates)  # 转换为张量\n",
    "    # # 打印第一个用户的更新形状来检查结果\n",
    "    # print(userUpdates[0].shape)\n",
    "    return userUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算一个二维 tensor 中每两个向量之间的余弦相似度矩阵。\n",
    "\n",
    "    参数:\n",
    "    - tensor (torch.Tensor): 形状为 (N, D) 的二维张量，N 是客户端数量，D 是特征维度。\n",
    "\n",
    "    返回:\n",
    "    - similarity_matrix (torch.Tensor): 形状为 (N, N) 的张量，每个元素表示两个向量之间的余弦相似度。\n",
    "    \"\"\"\n",
    "    # 归一化每个向量\n",
    "    normalized_tensor = F.normalize(tensor, p=2, dim=1)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    similarity_matrix = torch.mm(normalized_tensor, normalized_tensor.T)\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userUpdates_avg_NEUR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/')\n",
    "# print(userUpdates_avg_NEUR.shape)\n",
    "# print(userUpdates_avg_NEUR)\n",
    "# userUpdates_avg_MR = get_all_user_updates(10, '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_12-02-44-avg-fmnist_MR/')\n",
    "\n",
    "# similarity_matrix_avg_NEUR = cosine_similarity_matrix(userUpdates_avg_NEUR)\n",
    "# print(similarity_matrix_avg_NEUR.shape)\n",
    "# similarity_matrix_avg_MR = cosine_similarity_matrix(userUpdates_avg_MR)\n",
    "# # print(similarity_matrix_avg_MR.shape)\n",
    "# plot_detection_heatmaps(similarity_matrix_avg_NEUR, similarity_matrix_avg_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foolsgold\n",
    "# ChangeFrom https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L203C1-L241C25\n",
    "# foolsgold自身并没有确认哪些是恶意客户端，而是根据权重聚合\n",
    "# def foolsgold_identify_malicious_clients(wv: np.ndarray, threshold: float = 0.25) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     根据权重向量识别潜在的恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - wv (np.ndarray): 客户端的权重向量。\n",
    "#     - threshold (float): 判断恶意客户端的阈值，权重低于此值的客户端将被视为恶意客户端。\n",
    "    \n",
    "#     返回:\n",
    "#     - malicious_clients (np.ndarray): 被识别为恶意的客户端索引。\n",
    "#     \"\"\"\n",
    "#     return np.where(wv < threshold)[0]\n",
    "def foolsgold_identify_malicious_clients(wv: np.ndarray) -> np.ndarray:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(wv.reshape(-1, 1))\n",
    "    clusters = kmeans.labels_\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    max_cluster = unique[np.argmax(counts)]\n",
    "    user_labels = np.zeros(len(clusters), dtype=int)\n",
    "    user_labels[clusters == max_cluster] = 1\n",
    "    return np.where(user_labels == 0)[0]\n",
    "\n",
    "# 返回 聚合后的全局模型、恶意客户端索引、余弦相似度矩阵\n",
    "# def foolsgold(model_updates: Dict[str, torch.Tensor]) -> Tuple[Dict[str, torch.Tensor], np.ndarray, np.ndarray]:\n",
    "def foolsgold_oneRound(roundNum: int, dirPath: str) -> Tuple[Dict[str, torch.Tensor], np.ndarray, torch.Tensor]:\n",
    "    model_updates = loadPkl(roundNum, dirPath)\n",
    "    participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "    \n",
    "    keys = list(model_updates.keys())\n",
    "    last_layer_updates = model_updates[keys[-2]]\n",
    "    K = len(last_layer_updates)\n",
    "    cs = smp.cosine_similarity(last_layer_updates.cpu().numpy()) - np.eye(K)  # 减去对角线为1的单位矩阵，使得自身与自身的相似度为0\n",
    "    maxcs = np.max(cs, axis=1)\n",
    "    # === pardoning(赦免) ===\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if maxcs[i] < maxcs[j]:\n",
    "                cs[i][j] = cs[i][j] * maxcs[i] / maxcs[j]\n",
    "\n",
    "    alpha = np.max(cs, axis=1)\n",
    "    wv = 1 - alpha\n",
    "    wv[wv > 1] = 1\n",
    "    wv[wv < 0] = 0\n",
    "\n",
    "    # === Rescale so that max value is wv ===\n",
    "    wv = wv / np.max(wv)\n",
    "    wv[(wv == 1)] = .99\n",
    "\n",
    "    # === Logit function ===\n",
    "    wv = (np.log(wv / (1 - wv)) + 0.5)\n",
    "    wv[(np.isinf(wv) + wv > 1)] = 1\n",
    "    wv[(wv < 0)] = 0\n",
    "\n",
    "    malicious_clients = foolsgold_identify_malicious_clients(wv)\n",
    "    malicious_clients = participants_thisRound[malicious_clients]\n",
    "    print(f\"识别出的恶意客户端索引: {malicious_clients}\")\n",
    "\n",
    "    # === calculate global update ===\n",
    "    global_update = defaultdict()\n",
    "    for name in keys:\n",
    "        tmp = None\n",
    "        for i, j in enumerate(range(len(wv))):\n",
    "            if i == 0:\n",
    "                tmp = model_updates[name][j] * wv[j]\n",
    "            else:\n",
    "                tmp += model_updates[name][j] * wv[j]\n",
    "        global_update[name] = 1 / len(wv) * tmp\n",
    "    print(wv)\n",
    "    if True:  # 使用余弦相似度作为热力图依据\n",
    "        cs = smp.cosine_similarity(last_layer_updates.cpu().numpy())  # 这里就不再减去自身了\n",
    "        cs_rearranged = np.zeros((len(participants_thisRound), len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            for j, user_j in enumerate(participants_thisRound):\n",
    "                cs_rearranged[user_i][user_j] = cs[i][j]\n",
    "        cs_tensor = torch.from_numpy(cs_rearranged)\n",
    "    else:  # 使用聚合参数wv作为热力图依据。这样直接很多1，太明显了\n",
    "        cs_tensor = torch.zeros((len(participants_thisRound)))\n",
    "        for i, user_i in enumerate(participants_thisRound):\n",
    "            cs_tensor[user_i] = wv[i]  # tensor([0.2348, 0.2348, 0.8740, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
    "\n",
    "    return global_update, malicious_clients, cs_tensor\n",
    "\n",
    "# 组合多轮，返回恶意客户端索引、余弦相似度矩阵\n",
    "def foolsgold(roundsNum: List[int], dirPath: str) -> Tuple[np.ndarray, torch.Tensor]:\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "            if thisMaliciousIndex < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "            maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    cs = smp.cosine_similarity(gradients_shuffled)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious_shuffled, cs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByGPT - 还是不太行啊看来\n",
    "# import os\n",
    "# import pickle\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "# def fltrust_original(model_updates: Dict[str, torch.Tensor], param_updates: List[torch.Tensor], clean_param_update: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "#     \"\"\"\n",
    "#     使用 FLTrust 方法进行聚合计算。\n",
    "    \n",
    "#     参数:\n",
    "#     - model_updates: 客户端模型更新的字典，键为参数名，值为模型更新的 Tensor。\n",
    "#     - param_updates: 客户端的参数更新列表，包含每个客户端的更新 Tensor。\n",
    "#     - clean_param_update: 干净模型的参数更新，用于计算客户端更新的权重。\n",
    "\n",
    "#     返回:\n",
    "#     - global_update: 聚合后的全局模型更新。\n",
    "#     \"\"\"\n",
    "#     cos = torch.nn.CosineSimilarity(dim=0)\n",
    "#     g0_norm = torch.norm(clean_param_update)\n",
    "#     weights = []\n",
    "    \n",
    "#     # 计算每个客户端更新与 clean_param_update 的余弦相似度\n",
    "#     for param_update in param_updates:\n",
    "#         weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    \n",
    "#     weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "#     weights = weights / weights.sum()\n",
    "#     weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "#     nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "#     nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "#     print(f'g0_norm: {g0_norm}, '\n",
    "#           f'weights_sum: {weights.sum()}, '\n",
    "#           f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "#     normalize_weights = []\n",
    "#     for param_update in param_updates:\n",
    "#         normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "#     global_update = dict()\n",
    "#     for name, params in model_updates.items():\n",
    "#         if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "#             global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "#         else:\n",
    "#             global_update[name] = torch.matmul(\n",
    "#                 weights,\n",
    "#                 params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "#     return global_update\n",
    "\n",
    "\n",
    "# def fltrust(roundsNum: List[int], dirPath: str, modelPath: str) -> Tuple[List[int], np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     根据指定的轮次和目录路径，使用 FLTrust 聚合和识别恶意客户端。\n",
    "\n",
    "#     参数:\n",
    "#     - roundsNum: 需要处理的轮次列表。\n",
    "#     - dirPath: 数据文件所在的目录路径。\n",
    "#     - modelPath: 模型路径（目前没有用到）。\n",
    "\n",
    "#     返回:\n",
    "#     - 恶意客户端的编号列表。\n",
    "#     - 50 个客户端的评分（1x50 数组或 50x50 数组）。\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 加载pkl文件数据\n",
    "#     def loadPkl(roundNum: int, subfolder: str, dirPath: str) -> Dict[str, torch.Tensor]:\n",
    "#         pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "#         pklName = os.path.join(dirPath, f'{subfolder}/{pklPrefix}_{roundNum}.pkl')\n",
    "#         with open(pklName, 'rb') as f:\n",
    "#             update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "#         return update\n",
    "    \n",
    "#     # 合并指定轮次的数据\n",
    "#     all_model_updates = {}\n",
    "#     all_param_updates = []\n",
    "#     for roundNum in roundsNum:\n",
    "#         participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "#         model_updates = loadPkl(roundNum, 'model_updates', dirPath)  # 修正为正确的子文件夹\n",
    "#         clean_param_update = loadPkl(roundNum, 'clean_param_updates', dirPath)[participants_thisRound[0]]  # 修正为正确的子文件夹\n",
    "\n",
    "#         # 拼接恶意客户端（0-2号）和良性客户端（3-9号）\n",
    "#         for key, value in model_updates.items():\n",
    "#             if key not in all_model_updates:\n",
    "#                 all_model_updates[key] = torch.zeros((50, value.shape[1])).to('cuda:0')\n",
    "#             all_model_updates[key][:15] = torch.cat([value[i].unsqueeze(0) for i in range(3)], dim=0).to('cuda:0')  # 恶意客户端\n",
    "#             all_model_updates[key][15:] = torch.cat([value[i].unsqueeze(0) for i in range(3, 10)], dim=0).to('cuda:0')  # 良性客户端\n",
    "\n",
    "#         # 提取参数更新，拼接恶意和良性客户端\n",
    "#         for i in range(3):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "#         for i in range(3, 10):\n",
    "#             all_param_updates.append(parameters_to_vector([model_updates[key][i] for key in model_updates.keys()]).to('cuda:0'))\n",
    "    \n",
    "#     # 使用 FLTrust 进行聚合\n",
    "#     global_update = fltrust_original(all_model_updates, all_param_updates, clean_param_update)\n",
    "    \n",
    "#     # 使用 KMeans 聚类来识别恶意客户端\n",
    "#     scores = torch.stack(all_param_updates).cpu().numpy()  # 使用参数更新作为聚类的输入\n",
    "#     kmeans = KMeans(n_clusters=2, random_state=0).fit(scores)\n",
    "#     cluster_labels = kmeans.labels_\n",
    "    \n",
    "#     # 识别恶意客户端\n",
    "#     malicious_clients = [i for i in range(50) if cluster_labels[i] == cluster_labels[:15].max()]\n",
    "\n",
    "#     # 计算 50x50 的余弦相似度矩阵\n",
    "#     cosine_similarity_matrix = np.zeros((50, 50))\n",
    "#     for i in range(50):\n",
    "#         for j in range(50):\n",
    "#             cosine_similarity_matrix[i, j] = F.cosine_similarity(all_param_updates[i].view(-1, 1), all_param_updates[j].view(-1, 1)).item()\n",
    "\n",
    "#     return malicious_clients, cosine_similarity_matrix\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参数更新的向量\n",
    "# def parameters_to_vector(params):\n",
    "#     return torch.cat([p.view(-1) for p in params])\n",
    "\n",
    "\n",
    "# # 辅助函数：获取参与者列表\n",
    "# def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:\n",
    "#     # 实现略\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fltrust\n",
    "# https://github.com/LetMeFly666/SecFFT/blob/706bb287c3b00f6143e2190edc74714ed88f3532/getResult/FL_Backdoor_CV/roles/aggregation_rules.py#L301-L340\n",
    "\n",
    "def fltrust_original(model_updates, param_updates, clean_param_update):\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    g0_norm = torch.norm(clean_param_update)\n",
    "    weights = []\n",
    "    for param_update in param_updates:\n",
    "        weights.append(F.relu(cos(param_update.view(-1, 1), clean_param_update.view(-1, 1))))\n",
    "    weights = torch.tensor(weights).to('cuda:0').view(1, -1)\n",
    "    weights = weights / weights.sum()\n",
    "    weights = torch.where(weights[0].isnan(), torch.zeros_like(weights), weights)\n",
    "    nonzero_weights = torch.count_nonzero(weights.flatten())\n",
    "    nonzero_indices = torch.nonzero(weights.flatten()).flatten()\n",
    "\n",
    "    print(f'g0_norm: {g0_norm}, '\n",
    "          f'weights_sum: {weights.sum()}, '\n",
    "          f'*** {nonzero_weights} *** model updates are considered to be aggregated !')\n",
    "\n",
    "    normalize_weights = []\n",
    "    for param_update in param_updates:\n",
    "        normalize_weights.append(g0_norm / torch.norm(param_update))\n",
    "\n",
    "    global_update = dict()\n",
    "    for name, params in model_updates.items():\n",
    "        if 'num_batches_tracked' in name or 'running_mean' in name or 'running_var' in name:\n",
    "            global_update[name] = 1 / nonzero_weights * params[nonzero_indices].sum(dim=0, keepdim=True)\n",
    "        else:\n",
    "            global_update[name] = torch.matmul(\n",
    "                weights,\n",
    "                params * torch.tensor(normalize_weights).to('cuda:0').view(-1, 1))\n",
    "    return global_update\n",
    "\n",
    "def fltrust(roundsNum: List[int], dirPath: str, modelPath: str):\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    # gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    # maliciouses = []\n",
    "    gradientsList = []  # 里面存放每一轮的梯度，最后再聚合\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        # get model updates\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist/fltrust_{roundNum}.pth'\n",
    "        # print(pklName)\n",
    "        with open(pklName, 'rb') as f:\n",
    "            model_updates: Dict[str, torch.Tensor] = torch.load(f)\n",
    "        print(model_updates)\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/model_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            param_updates: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "        param_updates = torch.cat(list(param_updates.values()), dim=1)\n",
    "        # print(param_updates[list(param_updates.keys())[0]].shape)  # torch.Size([10, 12288])\n",
    "        pklName = f'../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN/clean_param_updates/fmnist_NEUROTOXIN_{roundNum}.pkl'\n",
    "        with open(pklName, 'rb') as f:\n",
    "            clean_param_update: torch.Tensor = pickle.load(f)\n",
    "        \n",
    "        # global_update = fltrust_original(model_updates, [param_updates[key] for key in param_updates.keys()], clean_param_update)\n",
    "        global_update = fltrust_original(model_updates, param_updates, clean_param_update)\n",
    "\n",
    "        # print(clean_param_update.shape)  # torch.Size([2674688])\n",
    "        thisGradients = [0] * clientPerRound\n",
    "\n",
    "\n",
    "        gradientsList.append(thisGradients)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPkl(roundNum: int, dirPath: str) -> Dict[str, torch.Tensor]:  # 把pkl变成{'key1': [[user3], [user5]]}\n",
    "    # dirPath = '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-26-43-avg-fmnist_NEUROTOXIN/'\n",
    "    pklPrefix = os.path.basename(os.path.normpath(dirPath)).split('-')[-1]\n",
    "    pklName = os.path.join(dirPath, f'model_updates/{pklPrefix}_{roundNum}.pkl')\n",
    "    with open(pklName, 'rb') as f:\n",
    "        update: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "    return update\n",
    "\n",
    "def getParticipants(roundNum: int, dirPath: str) -> np.ndarray:  # 获取参与者列表\n",
    "    participantFilePath = os.path.join(dirPath, 'participants/participants.csv')\n",
    "    participants = np.genfromtxt(\n",
    "        participantFilePath, delimiter=\",\", dtype=None, encoding=\"utf-8\"\n",
    "    )\n",
    "    participants = participants[1:].T\n",
    "    participants_thisRound = participants[roundNum]  # 获取当前轮次的参与者\n",
    "    return participants_thisRound\n",
    "\n",
    "# # 通过历史记录的梯度计算恶意客户端\n",
    "# def calc_maliciousAndCos_justByGrads(roundsNum: List[int], dirPath: str):\n",
    "#     maliciousUpdates = []\n",
    "#     benignUpdates = []\n",
    "#     for th, roundNum in enumerate(roundsNum):\n",
    "#         update = loadPkl(roundNum, dirPath)\n",
    "#         update = torch.cat(list(update.values()), dim=1)\n",
    "#         participants = getParticipants(roundNum, dirPath)\n",
    "#         temp = torch.zeros(update.shape)\n",
    "#         # print(update.shape)  # torch.Size([10, 2674688])\n",
    "#         # print(temp.shape)\n",
    "#         for i in range(10):\n",
    "#             if participants[i] < 3:\n",
    "#                 maliciousUpdates.append(update[i].cpu().numpy())\n",
    "#             else:\n",
    "#                 benignUpdates.append(update[i].cpu().numpy())\n",
    "#     all = maliciousUpdates + benignUpdates\n",
    "#     cs = cosine_similarity(all)\n",
    "#     return cs\n",
    "\n",
    "def kmeans_clustering(updates_np, n_clusters=2):\n",
    "    return 0, [], 0\n",
    "    # 使用KMeans算法进行聚类\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(updates_np)\n",
    "\n",
    "    # 获取聚类标签\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # 识别被认为是恶意客户端的索引（假设第一个聚类为恶意客户端）\n",
    "    malicious_indices = np.where(labels == 0)[0] if n_clusters == 2 else []\n",
    "\n",
    "    return labels, malicious_indices, kmeans\n",
    "\n",
    "# 通过历史记录的梯度计算恶意客户端\n",
    "def calc_maliciousAndCos_justByGrads(roundsNum: List[int], dirPath: str):\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        # _, foolsgoldMaliciousIndex, _ = kmeans_clustering(gradients)\n",
    "        _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "            if thisMaliciousIndex < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "            maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    cs = smp.cosine_similarity(gradients_shuffled)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return malicious_shuffled, cs_tensor\n",
    "\n",
    "def min_enclosing_ball(points, zeta, eta_prime, max_iter, lambda_thresh):\n",
    "    \"\"\"\n",
    "    使用迭代方法计算最小覆盖超球的球心和半径。\n",
    "    \n",
    "    参数:\n",
    "    - points: 客户端的历史梯度更新，形状为 (T, d)\n",
    "    - zeta: 覆盖比例\n",
    "    - eta_prime: 学习率\n",
    "    - max_iter: 最大迭代次数\n",
    "    - lambda_thresh: 收敛阈值\n",
    "    \n",
    "    返回:\n",
    "    - center: 球心（意图点）\n",
    "    - radius: 球半径\n",
    "    \"\"\"\n",
    "    # 确保 points 是二维数组\n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points.reshape(1, -1)\n",
    "    \n",
    "    # 初始化球心为所有点的均值\n",
    "    O_i = np.mean(points, axis=0)\n",
    "    # 初始化球半径为当前球心到所有点的最大距离\n",
    "    r_i = max(np.linalg.norm(O_i - points, axis=1))\n",
    "    \n",
    "    # 迭代优化球心和半径\n",
    "    for k in range(max_iter):\n",
    "        # 计算球心到每个点的方向向量\n",
    "        projection_points = []\n",
    "        for point in points:\n",
    "            direction = O_i - point\n",
    "            norm_direction = np.linalg.norm(direction)\n",
    "            if norm_direction == 0:\n",
    "                proj_point = point  # 如果球心和点重合，直接使用点作为投影点\n",
    "            else:\n",
    "                # 投影点的计算\n",
    "                proj_point = O_i + eta_prime * (point - O_i) / norm_direction\n",
    "            projection_points.append(proj_point)\n",
    "        \n",
    "        # 确保 projection_points 不为空\n",
    "        if len(projection_points) == 0:\n",
    "            break\n",
    "        \n",
    "        # 计算投影点到球心的距离\n",
    "        projection_points = np.array(projection_points)\n",
    "        distances = np.linalg.norm(O_i - projection_points, axis=1)\n",
    "\n",
    "        # 如果 selected_indices 为空，使用最大距离的点作为替代\n",
    "        if len(distances) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 选择前 zeta*T 个投影点\n",
    "        select_count = max(1, int(zeta * len(projection_points)))  # 确保至少选择一个点\n",
    "        selected_indices = np.argsort(distances)[:select_count]\n",
    "        \n",
    "        if len(selected_indices) == 0:\n",
    "            max_proj_point = projection_points[np.argmax(distances)]  # 使用最大距离的点\n",
    "        else:\n",
    "            max_proj_point = projection_points[selected_indices[-1]]  # 最远的投影点\n",
    "        \n",
    "        # 更新球心\n",
    "        O_i = O_i + eta_prime * (max_proj_point - O_i)\n",
    "        # 计算新的半径\n",
    "        r_new = max(np.linalg.norm(O_i - projection_points[selected_indices], axis=1))\n",
    "        \n",
    "        # 检查收敛条件\n",
    "        if abs(r_new - r_i) < lambda_thresh:\n",
    "            break\n",
    "        \n",
    "        r_i = r_new\n",
    "    \n",
    "    return O_i, r_i\n",
    "\n",
    "def calc_maliciousAndCos_justByGrads_SecFFT(roundsNum: List[int], dirPath: str, zeta=0.8, eta_prime=0.1, max_iter=100, lambda_thresh=1e-4):\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    # maliciouses = []\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "        # _, foolsgoldMaliciousIndex, _ = kmeans_clustering(gradients)\n",
    "        # _, foolsgoldMaliciousIndex, _ = foolsgold_oneRound(roundNum, dirPath)\n",
    "        # for thisMaliciousIndex in foolsgoldMaliciousIndex:\n",
    "        #     if thisMaliciousIndex < maliciousPerRound:\n",
    "        #         thisIndex = th * maliciousPerRound + thisMaliciousIndex\n",
    "        #     else:\n",
    "        #         thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisMaliciousIndex - maliciousPerRound\n",
    "        #     maliciouses.append(thisIndex)\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    # malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    intentions = []\n",
    "    for grad in gradients_shuffled:\n",
    "        grad = np.array(grad)\n",
    "        # 使用最小覆盖球算法计算意图点\n",
    "        center, radius = min_enclosing_ball(grad, zeta, eta_prime, max_iter, lambda_thresh)\n",
    "        intentions.append(center)  # 意图点是球心\n",
    "    # print(intentions)\n",
    "    # print(len(intentions))\n",
    "    # for n_neighbors in range(1, 52):\n",
    "    #     lof = LocalOutlierFactor(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    #     lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    #     detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    #     print(f'n_neighbors = {n_neighbors}, len(detected_malicious) = {len(detected_malicious)}')\n",
    "    # n_neighbors = 1, len(detected_malicious) = 0\n",
    "    # n_neighbors = 2, len(detected_malicious) = 0\n",
    "    # n_neighbors = 3, len(detected_malicious) = 0\n",
    "    # n_neighbors = 4, len(detected_malicious) = 0\n",
    "    # n_neighbors = 5, len(detected_malicious) = 0\n",
    "    # n_neighbors = 6, len(detected_malicious) = 0\n",
    "    # n_neighbors = 7, len(detected_malicious) = 0\n",
    "    # n_neighbors = 8, len(detected_malicious) = 0\n",
    "    # n_neighbors = 9, len(detected_malicious) = 0\n",
    "    # n_neighbors = 10, len(detected_malicious) = 0\n",
    "    # n_neighbors = 11, len(detected_malicious) = 0\n",
    "    # n_neighbors = 12, len(detected_malicious) = 0\n",
    "    # n_neighbors = 13, len(detected_malicious) = 0\n",
    "    # n_neighbors = 14, len(detected_malicious) = 0\n",
    "    # n_neighbors = 15, len(detected_malicious) = 15\n",
    "    # n_neighbors = 16, len(detected_malicious) = 15\n",
    "    # n_neighbors = 17, len(detected_malicious) = 15\n",
    "    # n_neighbors = 18, len(detected_malicious) = 15\n",
    "    # n_neighbors = 19, len(detected_malicious) = 15\n",
    "    # n_neighbors = 20, len(detected_malicious) = 15\n",
    "    # n_neighbors = 21, len(detected_malicious) = 15\n",
    "    # n_neighbors = 22, len(detected_malicious) = 15\n",
    "    # n_neighbors = 23, len(detected_malicious) = 15\n",
    "    # n_neighbors = 24, len(detected_malicious) = 15\n",
    "    # n_neighbors = 25, len(detected_malicious) = 15\n",
    "    # n_neighbors = 26, len(detected_malicious) = 15\n",
    "    # n_neighbors = 27, len(detected_malicious) = 15\n",
    "    # n_neighbors = 28, len(detected_malicious) = 15\n",
    "    # n_neighbors = 29, len(detected_malicious) = 15\n",
    "    # n_neighbors = 30, len(detected_malicious) = 15\n",
    "    # n_neighbors = 31, len(detected_malicious) = 15\n",
    "    # n_neighbors = 32, len(detected_malicious) = 15\n",
    "    # n_neighbors = 33, len(detected_malicious) = 15\n",
    "    # n_neighbors = 34, len(detected_malicious) = 15\n",
    "    # n_neighbors = 35, len(detected_malicious) = 0\n",
    "    # n_neighbors = 36, len(detected_malicious) = 0\n",
    "    # n_neighbors = 37, len(detected_malicious) = 0\n",
    "    # n_neighbors = 38, len(detected_malicious) = 0\n",
    "    # n_neighbors = 39, len(detected_malicious) = 0\n",
    "    # n_neighbors = 40, len(detected_malicious) = 0\n",
    "    # n_neighbors = 41, len(detected_malicious) = 0\n",
    "    # n_neighbors = 42, len(detected_malicious) = 0\n",
    "    # n_neighbors = 43, len(detected_malicious) = 0\n",
    "    # n_neighbors = 44, len(detected_malicious) = 0\n",
    "    # n_neighbors = 45, len(detected_malicious) = 0\n",
    "    # n_neighbors = 46, len(detected_malicious) = 0\n",
    "    # n_neighbors = 47, len(detected_malicious) = 0\n",
    "    # n_neighbors = 48, len(detected_malicious) = 0\n",
    "    # n_neighbors = 49, len(detected_malicious) = 0\n",
    "    # n_neighbors = 50, len(detected_malicious) = 0\n",
    "    # WC!!!!识别效果还真不错！！！\n",
    "    lof = LocalOutlierFactor(n_neighbors=int(50 * 0.4), metric='euclidean')\n",
    "    lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    print(detected_malicious)\n",
    "    cs = cosine_similarity(intentions)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return detected_malicious, cs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_attack_size(gradients, scaling_factor=0.1):\n",
    "    \"\"\"\n",
    "    限制前 15 个恶意客户端的梯度更新大小。\n",
    "    \n",
    "    参数:\n",
    "    - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "    - scaling_factor: 用于限制恶意客户端梯度大小的缩放因子。默认值为 0.1。\n",
    "    \n",
    "    返回:\n",
    "    - new_gradients: 经过处理后的梯度更新列表，前 15 个恶意客户端的更新被限制大小。\n",
    "    \"\"\"\n",
    "    # 确保输入是一个包含50个客户端梯度的列表\n",
    "    assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "    # 复制原始梯度列表以避免修改原始数据\n",
    "    new_gradients = gradients.copy()\n",
    "    \n",
    "    # 限制前15个恶意客户端的梯度更新大小\n",
    "    for i in range(15):  # 前15个是恶意客户端\n",
    "        # 获取当前客户端的梯度更新\n",
    "        original_grad = new_gradients[i]\n",
    "        # 使用缩放因子限制梯度大小\n",
    "        limited_grad = original_grad * scaling_factor\n",
    "        # 更新新的梯度\n",
    "        new_gradients[i] = limited_grad\n",
    "    \n",
    "    return new_gradients\n",
    "\n",
    "# def limit_attack_direction(gradients, mixing_factor=0.1):\n",
    "#     \"\"\"\n",
    "#     限制前 15 个恶意客户端的梯度方向，使其与正常客户端的梯度方向更相似。\n",
    "    \n",
    "#     参数:\n",
    "#     - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "#     - mixing_factor: 用于混合恶意客户端梯度方向和正常客户端平均梯度方向的因子。默认值为 0.9。\n",
    "    \n",
    "#     返回:\n",
    "#     - new_gradients: 经过处理后的梯度更新列表，前 15 个恶意客户端的更新被调整方向。\n",
    "#     \"\"\"\n",
    "#     # 确保输入是一个包含50个客户端梯度的列表\n",
    "#     assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "#     # 复制原始梯度列表以避免修改原始数据\n",
    "#     new_gradients = gradients.copy()\n",
    "    \n",
    "#     # 计算正常客户端的平均梯度方向（客户端 16 到 50）\n",
    "#     normal_gradients = np.array(new_gradients[15:])  # 获取正常客户端的梯度\n",
    "#     average_normal_gradient = np.mean(normal_gradients, axis=0)  # 计算平均梯度方向\n",
    "    \n",
    "#     # 对平均梯度进行归一化\n",
    "#     average_normal_gradient /= np.linalg.norm(average_normal_gradient)\n",
    "    \n",
    "#     # 调整前 15 个恶意客户端的梯度方向\n",
    "#     for i in range(15):  # 前15个是恶意客户端\n",
    "#         # 获取当前恶意客户端的梯度更新\n",
    "#         original_grad = new_gradients[i]\n",
    "        \n",
    "#         # 对原始梯度进行归一化\n",
    "#         original_grad /= np.linalg.norm(original_grad)\n",
    "        \n",
    "#         # 将恶意客户端的梯度方向调整为与正常客户端的平均梯度方向更相似\n",
    "#         adjusted_grad = mixing_factor * average_normal_gradient + (1 - mixing_factor) * original_grad\n",
    "        \n",
    "#         # 重新调整梯度的大小为原始大小\n",
    "#         adjusted_grad *= np.linalg.norm(gradients[i])\n",
    "        \n",
    "#         # 更新新的梯度\n",
    "#         new_gradients[i] = adjusted_grad\n",
    "    \n",
    "#     return new_gradients\n",
    "\n",
    "def limit_attack_direction(gradients, mixing_factor=0.7):\n",
    "    \"\"\"\n",
    "    限制前 15 个恶意客户端的梯度方向，使其随机向一个良性客户端的梯度方向偏移。\n",
    "    \n",
    "    参数:\n",
    "    - gradients: 包含 50 个客户端的梯度更新列表，每个元素是一个 NumPy 数组，表示一个客户端的梯度更新。\n",
    "    - mixing_factor: 用于混合恶意客户端梯度方向和随机选择的良性客户端梯度方向的因子。默认值为 0.9。\n",
    "    \n",
    "    返回:\n",
    "    - new_gradients: 经过处理后的梯度更新列表，前 15 个恶意客户端的更新被调整方向。\n",
    "    \"\"\"\n",
    "    # 确保输入是一个包含50个客户端梯度的列表\n",
    "    assert len(gradients) == 50, \"梯度列表的长度应该为 50\"\n",
    "    \n",
    "    # 复制原始梯度列表以避免修改原始数据\n",
    "    new_gradients = gradients.copy()\n",
    "    \n",
    "    # 对前 15 个恶意客户端进行处理\n",
    "    for i in range(15):  # 前15个是恶意客户端\n",
    "        # 随机选择一个良性客户端（16到50的索引是15到49）\n",
    "        random_benign_index = np.random.randint(15, 50)\n",
    "        benign_grad = new_gradients[random_benign_index]\n",
    "        \n",
    "        # 获取当前恶意客户端的梯度更新\n",
    "        original_grad = new_gradients[i]\n",
    "        \n",
    "        # 对恶意客户端和选中的良性客户端的梯度进行归一化\n",
    "        original_grad_normalized = original_grad / np.linalg.norm(original_grad)\n",
    "        benign_grad_normalized = benign_grad / np.linalg.norm(benign_grad)\n",
    "        \n",
    "        # 将恶意客户端的梯度方向调整为向良性客户端方向偏移\n",
    "        adjusted_grad = mixing_factor * benign_grad_normalized + (1 - mixing_factor) * original_grad_normalized\n",
    "        \n",
    "        # 重新调整梯度的大小为原始大小\n",
    "        adjusted_grad *= np.linalg.norm(gradients[i])\n",
    "        \n",
    "        # 更新新的梯度\n",
    "        new_gradients[i] = adjusted_grad\n",
    "    \n",
    "    return new_gradients\n",
    "\n",
    "# 通过历史记录的梯度计算恶意客户端\n",
    "def calc_maliciousAndCos_justByGrads_limited(roundsNum: List[int], dirPath: str, limistedMethod=0):  # limistedMethod: 0-限制大小，1-限制方向\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    if limistedMethod == 0:\n",
    "        gradients_limited = limit_attack_size(gradients_shuffled)\n",
    "    else:\n",
    "        gradients_limited = limit_attack_direction(gradients_shuffled)\n",
    "    cs = smp.cosine_similarity(gradients_limited)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return cs_tensor\n",
    "\n",
    "def calc_maliciousAndCos_justByGrads_limited_SecFFT(roundsNum: List[int], dirPath: str, limistedMethod=0, zeta=0.8, eta_prime=0.1, max_iter=100, lambda_thresh=1e-4):\n",
    "    clientPerRound = 10  # 这里就先写死了\n",
    "    maliciousPerRound = 3\n",
    "    gradients = [0] * len(roundsNum) * clientPerRound\n",
    "    for th, roundNum in enumerate(roundsNum):\n",
    "        participants_thisRound = getParticipants(roundNum, dirPath)\n",
    "        model_updates = loadPkl(roundNum, dirPath)\n",
    "        keys = list(model_updates.keys())\n",
    "        last_layer_updates = model_updates[keys[-2]]\n",
    "        K = len(last_layer_updates)\n",
    "        for i in range(K):\n",
    "            thisParticipant = participants_thisRound[i]\n",
    "            if thisParticipant < maliciousPerRound:\n",
    "                thisIndex = th * maliciousPerRound + thisParticipant\n",
    "            else:\n",
    "                thisIndex = maliciousPerRound * len(roundsNum) + (clientPerRound - maliciousPerRound) * th + thisParticipant - maliciousPerRound\n",
    "            gradients[thisIndex] = last_layer_updates[i].cpu().numpy()\n",
    "    shuffleArray = np.arange(50)\n",
    "    np.random.shuffle(shuffleArray[0:len(roundsNum) * maliciousPerRound])\n",
    "    np.random.shuffle(shuffleArray[len(roundsNum) * maliciousPerRound:50])\n",
    "    # malicious_shuffled = [shuffleArray[i] for i in maliciouses]\n",
    "    gradients_shuffled = [gradients[shuffleArray[i]] for i in range(50)]\n",
    "    if limistedMethod == 0:\n",
    "        gradients_limited = limit_attack_size(gradients_shuffled)\n",
    "    else:\n",
    "        gradients_limited = limit_attack_direction(gradients_shuffled)\n",
    "    intentions = []\n",
    "    for grad in gradients_limited:\n",
    "        grad = np.array(grad)\n",
    "        # 使用最小覆盖球算法计算意图点\n",
    "        center, radius = min_enclosing_ball(grad, zeta, eta_prime, max_iter, lambda_thresh)\n",
    "        intentions.append(center)  # 意图点是球心\n",
    "    # lof = LocalOutlierFactor(n_neighbors=int(50 * 0.4), metric='euclidean')\n",
    "    # lof_scores = lof.fit_predict(intentions)  # 使用LOF检测异常客户端\n",
    "    # detected_malicious = [i for i, score in enumerate(lof_scores) if score == -1]\n",
    "    # print(detected_malicious)\n",
    "    cs = cosine_similarity(intentions)\n",
    "    cs_tensor = torch.from_numpy(cs)\n",
    "    return cs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(identified_malicious: List[int]) -> Tuple:\n",
    "    total_clients = 50\n",
    "    malicious_clients = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}  # 实际恶意客户端的索引\n",
    "\n",
    "    # 计算TP, FP, TN, FN\n",
    "    TP = len(malicious_clients.intersection(identified_malicious))\n",
    "    FP = len(set(identified_malicious) - malicious_clients)\n",
    "    FN = len(malicious_clients - set(identified_malicious))\n",
    "    TN = total_clients - TP - FP - FN\n",
    "\n",
    "    # 准确率（Accuracy）\n",
    "    accuracy = (TP + TN) / total_clients\n",
    "\n",
    "    # 精确率（Precision）\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    # 召回率（Recall）\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # 特异度（Specificity）\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "    # 误报率（False Positive Rate, FPR）\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "    # 假阴率（False Negative Rate, FNR）\n",
    "    fnr = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # 计算AUC（此处假设预测的概率值，以便计算AUC）\n",
    "    y_true = [1 if i in malicious_clients else 0 for i in range(total_clients)]\n",
    "    y_scores = [1 if i in identified_malicious else 0 for i in range(total_clients)]\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    # 计算MCC（Matthews Correlation Coefficient）\n",
    "    mcc = matthews_corrcoef(y_true, y_scores)\n",
    "\n",
    "    return TP, FP, TN, FN, accuracy, precision, recall, specificity, fpr, fnr, auc, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: [2 0]\n",
      "[0.57699608 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.57699608 1.        ]\n",
      "识别出的恶意客户端索引: [1 2]\n",
      "[0.32903382 1.         1.         1.         1.         0.32903382\n",
      " 1.         1.         1.         0.80057505]\n",
      "识别出的恶意客户端索引: [1 2]\n",
      "[1.         0.65426351 1.         1.         1.         1.\n",
      " 1.         1.         1.         0.65426351]\n",
      "识别出的恶意客户端索引: [0 2]\n",
      "[1.         1.         1.         1.         0.89737964 0.73550898\n",
      " 0.73550898 1.         1.         1.        ]\n",
      "识别出的恶意客户端索引: [0 1]\n",
      "[1.         1.         1.         1.         0.23480443 1.\n",
      " 1.         1.         0.23480443 0.87404559]\n",
      "识别出的恶意客户端索引: [0 1]\n",
      "[1.         0.96332155 1.         1.         0.50892362 1.\n",
      " 1.         0.50892362 1.         0.96332155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: []\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: []\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "识别出的恶意客户端索引: [1 2]\n",
      "[1.         1.         0.95210941 0.0808696  0.0808696  1.\n",
      " 0.95210941 1.         1.         1.        ]\n",
      "识别出的恶意客户端索引: [2 0]\n",
      "[1.         1.         0.57792795 1.         1.         1.\n",
      " 0.57792795 1.         1.         1.        ]\n",
      "识别出的恶意客户端索引: [1 0]\n",
      "[1.         0.75999693 1.         0.75999693 1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "识别出的恶意客户端索引: [1 0 2]\n",
      "[1.         1.         1.         1.         0.50472006 0.50472006\n",
      " 1.         0.60638168 1.         1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\clip_lora\\lib\\site-packages\\sklearn\\base.py:1473: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别出的恶意客户端索引: []\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "识别出的恶意客户端索引: [2 0]\n",
      "[0.4379527 1.        1.        1.        1.        1.        1.\n",
      " 1.        0.4379527 1.       ]\n",
      "识别出的恶意客户端索引: [1 2]\n",
      "[1.         1.         1.         0.57772774 1.         1.\n",
      " 1.         1.         0.57772774 1.        ]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0, 1, 2, 3, 4, 5, 6, 8, 12, 13]\n",
      "[0, 2, 3, 4, 9, 10]\n",
      "[0, 1, 2, 3, 4, 5, 6, 8, 12, 13]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "(10, 0, 35, 5, 0.9, 1.0, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, np.float64(0.8333333333333333), np.float64(0.7637626158259734))\n",
      "(6, 0, 35, 9, 0.82, 1.0, 0.4, 1.0, 0.0, 0.6, np.float64(0.7), np.float64(0.5640760748177662))\n",
      "(10, 0, 35, 5, 0.9, 1.0, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, np.float64(0.8333333333333333), np.float64(0.7637626158259734))\n",
      "(15, 0, 35, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, np.float64(1.0), np.float64(1.0))\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
            "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" width=\"800\" height=\"20\">",
            "<text x=\"0\" y=\"15\" fill=\"red\">https://github.com/LetMeFly666/SecFFT/releases/download/v0.0.0/result.3x4.003.all.jpg</text>",
            "</svg>"
        ],
      "text/plain": [
       "<Figure size 2000x1500 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# malicious_clients, cosine_similarity_matrix = fltrust([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', '../NormalRun/FL_Backdoor_CV/saved_models/Revision_1/fltrust_NEUROTOXIN_09141511-fmnist')\n",
    "foolsgoldMaliciousIndex, foolsgoldScore2 = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\n",
    "fltrustMaliciousIndex, fltrustScore2 = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')\n",
    "# flameMaliciousIndex, flameMaliciousIndex = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-12_23-30-57-flame-fmnist_NEUROTOXIN')\n",
    "flameMaliciousIndex, flameScore2 = calc_maliciousAndCos_justByGrads([10, 11, 12, 13, 14], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')\n",
    "secfftMaliciousIndex, secfftScore2 = calc_maliciousAndCos_justByGrads_SecFFT([0, 1, 2, 3, 4], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')  # 随便找个历史保存的数据进行识别\n",
    "\n",
    "foolsLimited = calc_maliciousAndCos_justByGrads_limited([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\n",
    "fltrustLimited = calc_maliciousAndCos_justByGrads_limited([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')\n",
    "flameLimited = calc_maliciousAndCos_justByGrads_limited([10, 11, 12, 13, 14], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')\n",
    "secfftLimited = calc_maliciousAndCos_justByGrads_limited_SecFFT([0, 1, 2, 3, 4], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN')\n",
    "\n",
    "\n",
    "foolsDirection = calc_maliciousAndCos_justByGrads_limited([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "fltrustDirection = calc_maliciousAndCos_justByGrads_limited([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "flameDirection = calc_maliciousAndCos_justByGrads_limited([10, 11, 12, 13, 14], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "secffDirection = calc_maliciousAndCos_justByGrads_limited_SecFFT([0, 1, 2, 3, 4], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-14_15-11-15-fltrust-fmnist_NEUROTOXIN', limistedMethod=1)\n",
    "\n",
    "# foolsgoldScore2 = calc_maliciousAndCos_justByGrads([15, 16, 17, 18, 19], '../NormalRun/FL_Backdoor_CV/resultWithTime/2024-09-13_23-15-48-foolsgold-fmnist_NEUROTOXIN')\n",
    "\n",
    "# print(foolsgoldMaliciousIndex)\n",
    "# print(foolsgoldScore2)\n",
    "# datas = [foolsgoldScore2] * 12\n",
    "# datas = [secfftScore2] * 12\n",
    "datas = [foolsgoldScore2, fltrustScore2, flameScore2, secfftScore2,\n",
    "         foolsLimited, fltrustLimited, flameLimited, secfftLimited,\n",
    "         foolsDirection, fltrustDirection, flameDirection, secffDirection,]\n",
    "foolsgoldMaliciousIndex = [int(x) for x in foolsgoldMaliciousIndex]\n",
    "fltrustMaliciousIndex = [int(x) for x in fltrustMaliciousIndex]\n",
    "flameMaliciousIndex = [int(x) for x in foolsgoldMaliciousIndex]\n",
    "foolsgoldMaliciousIndex.sort()\n",
    "fltrustMaliciousIndex.sort()\n",
    "flameMaliciousIndex.sort()\n",
    "print(foolsgoldMaliciousIndex)\n",
    "print(fltrustMaliciousIndex)\n",
    "print(flameMaliciousIndex)\n",
    "print(secfftMaliciousIndex)\n",
    "\n",
    "foolsgoldScores = getScores(foolsgoldMaliciousIndex)\n",
    "fltrustScores = getScores(fltrustMaliciousIndex)\n",
    "flameScores = getScores(flameMaliciousIndex)\n",
    "secfftScores = getScores(secfftMaliciousIndex)\n",
    "print(foolsgoldScores)\n",
    "print(fltrustScores)\n",
    "print(flameScores)\n",
    "print(secfftScores)\n",
    "\n",
    "plot_detection_heatmaps_3x4(*datas)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
